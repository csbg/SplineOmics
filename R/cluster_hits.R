#' cluster_hits()
#'
#' Performs clustering on hits from top tables generated by differential
#' expression analysis.
#' This function filters hits based on adjusted p-value thresholds, extracts
#' spline coefficients for
#' significant features, normalizes these coefficients, and applies hierarchical
#' clustering. The results,
#' including clustering assignments and normalized spline curves, are saved in a
#' specified directory and
#' compiled into an HTML report.
#'
#' @param splineomics An S3 object of class `SplineOmics` that contains all the
#' necessary data and parameters for the analysis, including:
#' \itemize{
#'   \item \code{data}: The original expression dataset used for differential
#'   expression analysis.
#'   \item \code{meta}: A dataframe containing metadata corresponding to the
#'   \code{data}, must include a 'Time' column and any columns specified by
#'   \code{conditions}.
#'   \item \code{annotation}: A dataframe that maps the rows of \code{data} to
#'   annotation info, such as the gene name or database identifiers.
#'   \item \code{report_info}: A named list describing the experiment.  
#'   Must include the following fields:  
#'     - \code{"omics_data_type"}  
#'     - \code{"data_description"}  
#'     - \code{"data_collection_date"}  
#'     - \code{"analyst_name"}  
#'     - \code{"contact_info"}  
#'     - \code{"project_name"}  
#'   
#'   May also include the following optional fields:  
#'     - \code{"method_description"}  
#'     - \code{"results_summary"}  
#'     - \code{"conclusions"}  
#'   \item \code{design}: A character of length 1 representing the limma
#'   design formula.
#'   \item \code{mode}: Specifies how the design formula is constructed: 
#'   either `"isolated"` or `"integrated"`. 
#'   
#'   - `"isolated"`: Each level is analyzed independently, using only the 
#'     subset of data corresponding to that level. The design formula does 
#'     not include the condition variable, since only one condition is 
#'     present in each subset.
#'   
#'   - `"integrated"`: All levels are analyzed together in a single model, 
#'     using the full dataset. The design formula includes the condition 
#'     variable (and optionally interaction terms with it) so that results 
#'     are estimated jointly across all levels.
#'   \item \code{condition}: Character vector of length 1 specifying the column
#'   name in \code{meta} used to define groups for analysis.
#'   \item \code{spline_params}: A list of spline parameters for the analysis.
#'   \item \code{meta_batch_column}: A character string specifying the column
#'   name in the metadata used for batch effect removal.
#'   \item \code{meta_batch2_column}: A character string specifying the second
#'   column name in the metadata used for batch effect removal.
#'   \item \code{limma_splines_result}: A list of data frames, each representing
#'    a top table from differential expression analysis, containing at least
#'    'adj.P.Val' and expression data columns.
#'   \item \code{feature_name_columns}: Character vector of strings that each
#'   specify a column of the original data dataframe which were used to 
#'   automatically build the feature names with the \code{extract_data}
#'   function.
#' }
#' @param nr_clusters A list whose length matches `top_tables`; each element is
#'   a numeric vector of positive integers (e.g. `1:1`, `2:8`) giving the
#'   candidate number(s) of clusters for the corresponding condition level.
#' @param adj_pthresholds Numeric vector of p-value thresholds for filtering
#' hits in each top table.
#' @param adj_pthresh_avrg_diff_conditions p-value threshold for the results
#' from the average difference of the condition limma result. Per default 0 (
#' turned off).
#' @param adj_pthresh_interaction_condition_time p-value threshold for the
#' results from the interaction of condition and time limma result. Per default
#' 0 (turned off).
#' @param min_effect_size A named list that specifies the minimum effect size
#'   thresholds to consider a feature as biologically meaningful, in addition
#'   to statistical significance. This allows users to filter out "trivial"
#'   hits that pass adjusted p-value cutoffs but show negligible effect sizes.
#'
#'   The list must contain the following elements:
#'   - `time_effect`: Minimum absolute effect size (e.g., log-fold change or
#'     model coefficient) for time effects. Features with a smaller effect size
#'     will be ignored even if they are statistically significant.
#'   - `avg_diff_cond`: Minimum absolute effect size for average differences
#'     between conditions. As above, this ensures that only condition
#'     contrasts with biologically relevant magnitude are reported.
#'
#'   Values should be numeric (typically >0). For example,
#'   `min_effect_size = list(time_effect = 1, avg_diff_cond = 1)` will only
#'   keep time effects and condition differences with an absolute effect size
#'   of at least 1 unit. Use smaller values (e.g., 0.1) for more permissive
#'   filtering, or larger values to be more conservative.
#'   
#'   The default is the value 0 for both `time_effect` and `avg_diff_cond`.
#' @param genes A character vector containing the gene names of the features to
#'  be analyzed. The entries should be in the same order as they appear in data.
#' @param plot_info List containing the elements y_axis_label (string),
#'                  time_unit (string), treatment_labels (character vector),
#'                  treatment_timepoints (integer vector). All can also be NA.
#'                  This list is used to add this info to the spline plots.
#'                  time_unit is used to label the x-axis, and treatment_labels
#'                  and -timepoints are used to create vertical dashed lines,
#'                  indicating the positions of the treatments (such as
#'                  feeding, temperature shift, etc.).
#' @param plot_options List with specific fields (cluster_heatmap_columns =
#' Bool) that allow for customization of plotting behavior.
#' @param raw_data Optional. Data matrix with the raw (unimputed) data, still 
#' containing NA values. When provided, it highlights the datapoints in the 
#' spline plots that originally where NA and that were imputed.
#' @param report_dir Character string specifying the directory path where the
#' HTML report and any other output files should be saved.
#' @param report Boolean TRUE or FALSE value specifing if a report should be
#' generated.
#' @param max_hit_number Maximum number of hits which are plotted within each
#' cluster. This can be used to limit the computation time and size of
#' the HTML report in the case of many hits. Default is 100.
#'
#' @return
#' A named list with two elements:
#' \describe{
#'   \item{\code{cluster_summary}}{
#'     A tibble containing one row per \code{feature_nr} with metadata and
#'     cluster assignments across the analysis categories. The structure is:
#'     \itemize{
#'       \item \code{feature_nr} – Numeric feature identifier.
#'       \item \code{feature_name} – Preferred feature name, prioritizing
#'         values from the limma tables, then from the cluster table row
#'         names, and falling back to the numeric feature ID.
#'       \item \code{gene} – Preferred gene symbol from the \code{annotation}
#'         table if available, otherwise taken from the cluster tables.
#'       \item \code{cluster_<cond1>} / \code{cluster_<cond2>} – Cluster
#'         assignments for each time-effect condition, named according to
#'         the elements of \code{clustered_hits_levels}.
#'       \item \code{cluster_cat2} – Present only if category 2 results are
#'         available; a combined cluster label in the form
#'         \code{"<cluster_<cond1>>_<cluster_<cond2>>"} for features that
#'         are significant in category 2. If this value is \code{NA}, the
#'         feature was not a category 2 hit.
#'       \item \code{cluster_cat3} – Present only if category 3 results are
#'         available; a combined cluster label in the form
#'         \code{"<cluster_<cond1>>_<cluster_<cond2>>"} for features that
#'         are significant in category 3. If this value is \code{NA}, the
#'         feature was not a category 3 hit.
#'     }
#'     For any category-specific cluster column (\code{cluster_<cond1>},
#'     \code{cluster_<cond2>}, \code{cluster_cat2}, \code{cluster_cat3}),
#'     a value of \code{NA} indicates that the feature was not significant
#'     (not a hit) in that category.
#'   }
#'   \item{\code{plots}}{
#'     A list of all plots generated during the run, corresponding to the
#'     visualizations shown in the HTML report produced by this function.
#'   }
#' }
#'
#' @export
#'
cluster_hits <- function(
    splineomics,
    nr_clusters,
    adj_pthresholds = c(0.05),
    adj_pthresh_avrg_diff_conditions = 0.05,
    adj_pthresh_interaction_condition_time = 0.05,
    min_effect_size = list(
      time_effect = 0,
      avg_diff_cond = 0
    ),
    genes = NULL, 
    plot_info = list(
      y_axis_label = "Value",
      time_unit = "min",
      treatment_labels = NA,
      treatment_timepoints = NA
    ),
    plot_options = list(
      cluster_heatmap_columns = FALSE,
      meta_replicate_column = NULL
    ),
    raw_data = NULL,
    report_dir = here::here(),
    report = TRUE,
    max_hit_number = 25
    ) {

  report_dir <- normalizePath(
    report_dir,
    mustWork = FALSE
  )

  check_splineomics_elements(
    splineomics = splineomics,
    func_type = "cluster_hits"
  )
  
  check_inputs_cluster_hits(
    min_effect_size = min_effect_size,
    max_hit_number = max_hit_number
    )

  args <- lapply(as.list(match.call()[-1]), eval, parent.frame())
  check_null_elements(args)
  input_control <- InputControl$new(args)
  input_control$auto_validate()

  top_tables <- splineomics[["limma_splines_result"]][["time_effect"]]
  data <- splineomics[["data"]]
  meta <- splineomics[["meta"]]
  annotation <- splineomics[["annotation"]]
  report_info <- splineomics[["report_info"]]
  design <- splineomics[["design"]]
  mode <- splineomics[["mode"]]
  condition <- splineomics[["condition"]]
  spline_params <- splineomics[["spline_params"]]
  meta_batch_column <- splineomics[["meta_batch_column"]]
  meta_batch2_column <- splineomics[["meta_batch2_column"]]
  feature_name_columns <- splineomics[["feature_name_columns"]]

  # To set the default p-value threshold for ALL levels.
  if (is.numeric(adj_pthresholds) &&
    length(adj_pthresholds) == 1 && adj_pthresholds[1] == 0.05) {
    levels <- unique(meta[[condition]])
    adj_pthresholds <- rep(adj_pthresholds[1], length(levels))
  }

  within_level_top_tables <- filter_top_tables(
    top_tables = top_tables,
    adj_pthresholds = adj_pthresholds,
    meta = meta,
    condition = condition
  )
  if (is.null(within_level_top_tables)) {   # when <2 hits for all levels
    return(NULL)
  }

  predicted_timecurves <- predict_timecurves(
    splineomics = splineomics,  
    data = data,
    meta = meta,
    condition = condition,
    spline_params = spline_params,
    mode = mode
  )
  
  predicted_timecurves <- add_curve_effectsizes(
    predicted_timecurves,
    threshold = min_effect_size[["time_effect"]]
    )

  all_levels_clustering <- perform_clustering(
    top_tables = within_level_top_tables,
    nr_clusters = nr_clusters,
    meta = meta,
    condition = condition,
    predicted_timecurves = predicted_timecurves
  )

  # Put them in there under those names, so that the report generation fun
  # can access them directly like this.
  effects <- extract_effects(design)
  report_info[["Fixed effects"]] <- effects[["fixed_effects"]] 
  report_info[["Random effects"]] <- effects[["random_effects"]] 
  report_info[["meta_condition"]] <- c(condition)
  report_info[["plot_data_batch_correction"]] <- paste(
    meta_batch_column,
    meta_batch2_column,
    sep = ", "
  )
  report_info[["homosc_violation_result"]] <-
    splineomics[["homosc_violation_result"]]

  if (!is.null(splineomics[["use_array_weights"]])) {
    report_info[["use_array_weights"]] <- splineomics[["use_array_weights"]]
    report_info[["heteroscedasticity"]] <- "not tested"
  } else {
    report_info[["use_array_weights"]] <- paste(
      "automatic (decided by Levene's test), array_weights only used when",
      "heteroscedasticity is detected (% violating features >= 10)"
    )
    report_info[["heteroscedasticity"]] <- sprintf(
      "Heteroscedasticity detected: %s (%.1f%% of features violated the
      assumption of homoscedasticity)",
      ifelse(
        splineomics[["homosc_violation_result"]][["violation"]], "Yes", "No"
        ),
      splineomics[["homosc_violation_result"]][["percent_violated"]]
    )
  }

  if (
    (mode != "isolated") &&
    (adj_pthresh_avrg_diff_conditions > 0 ||
    adj_pthresh_interaction_condition_time > 0)
    ) {
    category_2_and_3_hits <- get_category_2_and_3_hits(
      splineomics = splineomics,
      adj_pthresh_avrg_diff_conditions = adj_pthresh_avrg_diff_conditions,
      adj_pthresh_interaction = adj_pthresh_interaction_condition_time,
      min_effect_size = min_effect_size,
      predicted_timecurves = predicted_timecurves
    )
    
    spline_comp_plots <- generate_spline_comparisons(
      splineomics = splineomics,
      data = data,
      meta = meta,
      condition = condition,
      replicate_column = plot_options[["meta_replicate_column"]],
      plot_info = plot_info,
      category_2_and_3_hits = category_2_and_3_hits,
      adj_pthresh_avrg_diff_conditions = adj_pthresh_avrg_diff_conditions,
      adj_pthresh_interaction = adj_pthresh_interaction_condition_time,
      raw_data = raw_data,
      predicted_timecurves = predicted_timecurves,
      max_hit_number = max_hit_number
    )
  } else {
    category_2_and_3_hits <- NULL
    spline_comp_plots <- NULL
  }

  if (!is.null(genes)) {
    genes <- clean_gene_symbols(genes)
  }

  if (report) {
    plots <- make_clustering_report(
      all_levels_clustering = all_levels_clustering,
      condition = condition,
      data = data,
      meta = meta,
      annotation = annotation,
      genes = genes,
      spline_params = spline_params,
      adj_pthresholds = adj_pthresholds,
      adj_pthresh_avrg_diff_conditions = adj_pthresh_avrg_diff_conditions,
      adj_pthresh_interaction_condition_time =
        adj_pthresh_interaction_condition_time,
      category_2_and_3_hits = category_2_and_3_hits,
      report_dir = report_dir,
      mode = mode,
      report_info = report_info,
      predicted_timecurves = predicted_timecurves,
      design = design,
      meta_batch_column = meta_batch_column,
      meta_batch2_column = meta_batch2_column,
      plot_info = plot_info,
      plot_options = plot_options,
      feature_name_columns = feature_name_columns,
      spline_comp_plots = spline_comp_plots,
      raw_data = raw_data,
      max_hit_number = max_hit_number
    )
  } else {
    plots <- "no plots, because report arg of cluster_hits() was set to FALSE"
  }

  # Leave a message for the user instead of just NA.
  all_levels_clustering <- lapply(all_levels_clustering, function(x) {
    if (is.logical(x)) {
      return("No result for this level, because the top_table had < 2 hits")
    } else {
      return(x)
    }
  })

  clustered_hits_levels <- list()

  for (i in seq_along(all_levels_clustering)) {
    clustering_level <- all_levels_clustering[[i]]
    element_name <- names(all_levels_clustering)[i]

    if (any(is.character(clustering_level))) {
      clustered_hits_levels[[element_name]] <-
        clustering_level
    } else { # normal list result
      clustered_hits_levels[[element_name]] <-
        clustering_level$clustered_hits
    }
  }

  if (report) {
    print_info_message(
      message_prefix = "Clustering the hits",
      report_dir = report_dir
    )
  }

  cluster_summary <- construct_cluster_summary(
    limma_splines_results = splineomics[["limma_splines_result"]],
    clustered_hits_levels = clustered_hits_levels,
    category_2_and_3_hits = category_2_and_3_hits,
    genes = genes
  )

  list(
    cluster_summary = cluster_summary,
    plots = plots
  )
}


# Level 1 internal functions ---------------------------------------------------


#' Validate input arguments for clustering of significant hits
#'
#' @noRd
#'
#' @description
#' This helper function checks that the input control parameters for
#' clustering are well-formed. Specifically, it validates the structure
#' of \code{min_effect_size} and \code{max_hit_number}, and raises an
#' error if the requirements are not met.
#'
#' @param min_effect_size A list with exactly two named elements:
#'   \itemize{
#'     \item \code{time_effect}: A single numeric value (integer or float)
#'           specifying the minimum required time-dependent effect size.
#'     \item \code{avg_diff_cond}: A single numeric value (integer or float)
#'           specifying the minimum required average difference between
#'           conditions.
#'   }
#'   Both elements must be length-1 numeric scalars.
#'
#' @param max_hit_number A single positive integer (1, 2, …) or \code{Inf},
#'   giving the maximum number of hits to include in clustering.
#'
#' @return Returns \code{TRUE} invisibly if all checks pass.
#'   Otherwise, execution is stopped with an informative error message.
#'
#' @details
#' - \code{min_effect_size} must be a list of length 2, named exactly
#'   \code{"time_effect"} and \code{"avg_diff_cond"}.
#' - Both values must be single numeric scalars (e.g. \code{1}, \code{1.5}).
#' - \code{max_hit_number} must be a length-1 numeric that is either
#'   an integer ≥ 1 or \code{Inf}.
#'
#' This function is intended to be called at the beginning of
#' user-facing clustering routines to ensure consistent argument structure.
#'
check_inputs_cluster_hits <- function(
    min_effect_size,
    max_hit_number
    ) {

  if (!is.list(min_effect_size)) {
    stop_call_false("`min_effect_size` must be a list.")
  }
  
  # must have exactly two named elements: time_effect and avg_diff_cond
  required_names <- c("time_effect", "avg_diff_cond")
  nm <- names(min_effect_size)
  if (length(min_effect_size) != 2L || !setequal(nm, required_names)) {
    stop_call_false(paste(
      "`min_effect_size` must be a list with exactly two named elements:",
      "'time_effect' and 'avg_diff_cond'."
    ))
  }
  
  # each element must be numeric (integer or float) and length 1
  for (n in required_names) {
    val <- min_effect_size[[n]]
    if (!is.numeric(val) || length(val) != 1L) {
      stop_call_false(
        paste0(
          "`min_effect_size$",
          n,
          "` must be a single numeric (integer or float)."
          )
      )
    }
  }
  
  if (!is.numeric(max_hit_number) ||            # must be numeric
      length(max_hit_number) != 1L ||           # exactly one value
      !(is.infinite(max_hit_number) ||          # allow Inf
        (max_hit_number >= 1 &&                 # >= 1 ...
         max_hit_number == as.integer(max_hit_number)))) {  # ... and int-valued
    stop_call_false(
      "`max_hit_number` must be a single positive integer (1, 2, ...) or Inf."
    )
  }
  
  invisible(TRUE)
}


#' Filter Top Tables by Adjusted P-Values and Levels
#' 
#' @noRd
#'
#' @description
#' Filters a set of limma top tables based on adjusted p-value thresholds 
#' and metadata levels. This function supports both within-level and 
#' between-level analyses. It removes hits that do not meet the specified 
#' criteria and ensures that clustering can only proceed for levels with 
#' at least two hits.
#'
#' @param top_tables A list of limma top tables, where each top table 
#' corresponds to a specific level or comparison.
#' @param adj_pthresholds A numeric vector of adjusted p-value thresholds, 
#'   one for each level in the condition.
#' @param meta A dataframe containing metadata for the RNA-seq data, 
#'   including the condition column used to identify levels.
#' @param condition A character string specifying the name of the condition 
#'   column in the `meta` dataframe. Each level of this column corresponds 
#'   to a separate analysis.
#'
#' @details
#' If a between-level analysis is detected, the function identifies the 
#' appropriate indices for within-level and between-level top tables. 
#' It filters within-level top tables based on feature indices from the 
#' between-level results or adjusted p-value thresholds.
#'
#' For within-level analysis, only features with an adjusted p-value less 
#' than the specified thresholds are retained. If fewer than two hits are 
#' found for a level, clustering is skipped for that level, and an NA is 
#' returned for that level in the filtered top tables.
#'
#' If all levels have fewer than two hits, the function stops execution 
#' with an error message, as clustering cannot proceed.
#'
#' @return
#' A list of filtered top tables, where each entry corresponds to a level 
#' in the condition. Levels with fewer than two hits are assigned NA. 
#' If all levels are skipped, an error is thrown.
#'
filter_top_tables <- function(
    top_tables,
    adj_pthresholds,
    meta,
    condition
    ) {
  
  result <- check_between_level_pattern(top_tables)

  if (result$between_levels) { # between_level analysis
    if (result$index_with_pattern == 1) {
      within_level_top_tables_index <- 2
      between_level_top_tables_index <- 1
    } else { # between level top_tables are at index 2
      within_level_top_tables_index <- 1
      between_level_top_tables_index <- 2
    }

    within_level_top_tables <- top_tables[[within_level_top_tables_index]]
    between_level_top_tables <- top_tables[[between_level_top_tables_index]]
  } else { # no between level analysis
    within_level_top_tables <- top_tables
  }

  for (i in seq_along(within_level_top_tables)) {
    within_level_top_table <- within_level_top_tables[[i]]
    level <- unique(meta[[condition]])[i]

    if (result$between_levels) {
      hit_indices <- get_level_hit_indices(
        between_level_top_tables,
        level,
        adj_pthresholds
      )
    } else { # within level
      hit_indices <- within_level_top_table[["feature_nr"]][
        within_level_top_table[["adj.P.Val"]] < adj_pthresholds[i]
      ]
    }

    top_table_filtered <-
      within_level_top_table[within_level_top_table[["feature_nr"]]
      %in% hit_indices, ]

    if (nrow(top_table_filtered) < 2) {
      message(paste(
        "Level", level, "has < 2 hits. Skipping clustering for",
        "this level"
      ))
      within_level_top_tables[[i]] <- NA
    } else {
      within_level_top_tables[[i]] <- top_table_filtered
    }
  }

  if (all(is.na(within_level_top_tables))) {
    message("All levels have < 2 hits. Cannot run clustering. Stopping.")
    return(NULL)
  }

  within_level_top_tables
}


#' Predict smooth timecourses from spline-augmented limma model
#'
#' @noRd
#'
#' @description
#' Predicts smooth expression or abundance trajectories for all features in a
#' spline-based limma model across all condition levels. The model must use
#' natural cubic splines (`ns`) or B-splines (`bs`) to represent time, with or
#' without condition-specific interaction terms.
#'
#' The function builds design matrices over a smooth time grid and uses
#' fitted model coefficients to reconstruct fitted curves for each feature,
#' optionally handling different modeling modes ("isolated" or "integrated").
#'
#' This is typically used to visualize model-implied dynamics over time for
#' multiple biological conditions.
#' 
#' Note that this function does not use the random effects in case the linear
#' mixed model from the variancePartition::dream() was used. This is because 
#' they model subject-specific deviations, not the fixed-effect population trend
#'  that defines the curve shape.
#'
#' @param splineomics A list containing top tables and model results (not used
#'   internally, but passed for interface compatibility).
#' @param data A dataframe containg the data used for fitting the linear models.
#' @param meta A data.frame containing metadata, including time and condition
#'   annotations.
#' @param condition String specifying the column in `meta` with experimental
#'   condition levels.
#' @param spline_params A list with spline specification:
#'   - `spline_type`: "n" for natural spline, "b" for B-spline (per condition)
#'   - `dof`: degrees of freedom (per condition)
#'   - `degree`: spline degree (only used for B-spline)
#' @param mode Either `"isolated"` or `"integrated"` depending on model setup.
#'
#' @return A list with:
#'   \describe{
#'     \item{`time_grid`}{Numeric vector of 1000 time points for prediction.}
#'     \item{`predictions`}{Named list by condition level. Each entry is a 
#'     matrix of predicted values (features x time points).}
#'   }
#'   
predict_timecurves <- function(
    splineomics,
    data,
    meta,
    condition,                 
    spline_params,
    mode
) {

  # time grid (common to all levels)
  # number of unique sampling points
  fit <- splineomics[["fit"]]
  n_unique_time <- dplyr::n_distinct(meta[["Time"]])
  
  ## build a grid 10 x denser than the raw sampling
  smooth_timepoints <- seq(
    from = min(meta[["Time"]]),
    to   = max(meta[["Time"]]),
    length.out = 10 * n_unique_time
  )
  
  pred_list <- list()                    # results
  
  # iterate over each condition level
  for (level in unique(meta[[condition]])) {

    # pick the right fit object
    if (mode == "isolated") {
      fit_lv <- fit[[level]]                          
      if (is.null(fit_lv))                              
        fit_lv <- fit[[paste0(condition, "_", level)]]
    } else {
      fit_lv <- fit
    }
    if (is.null(fit_lv$coefficients))
      stop("missing coefficients for level: ", level)
    
    design_n <- colnames(fit_lv$coefficients)
    
    # spline columns X1, X2, ... 
    spline_cols <- grep(
      "^X[0-9]+$",
      design_n,
      value = TRUE
      )
    k <- length(spline_cols)
    
    # decide which row in spline_params to use
    idx <- if (mode == "isolated")
      match(level, unique(meta[[condition]])) %||% 1L else 1L
    
    # build spline basis
    B <- if (spline_params$spline_type[idx] == "n") {
      splines::ns(
        smooth_timepoints,
        df = spline_params$dof[idx] %||% k
        )
    } else {
      splines::bs(
        smooth_timepoints,
        df     = spline_params$dof[idx] %||% k,
        degree = spline_params$degree[idx]
        )
    }
    colnames(B) <- spline_cols

    if (mode == "isolated") {
      # only intercept and spline terms
      X_new <- cbind("(Intercept)" = 1, B)
      needed <- c("(Intercept)", spline_cols)
    } else {
      # integrated fit: must include interaction terms for non-reference levels
      cond_prefix <- condition
      all_levels <- unique(as.character(meta[[condition]]))
      design_cols <- colnames(fit_lv$coefficients)
      
      dummy_suffixes <- sub(
        paste0("^", cond_prefix),
        "",
        grep(
          paste0(
            "^",
            cond_prefix
            ),
          design_cols,
          value = TRUE
          )
      )
      reference_level <- setdiff(all_levels, dummy_suffixes)[1]
      
      if (identical(level, reference_level)) {
        X_new <- cbind(
          "(Intercept)" = 1,
          B
          )
        needed <- c(
          "(Intercept)",
          spline_cols
          )
      } else {
        dummy_col <- paste0(
          cond_prefix,
          level
          )
        # Find interaction columns dynamically
        int_cols <- vapply(spline_cols, function(spline_col) {
          possible_matches <- colnames(fit_lv$coefficients)[
            grepl(dummy_col, colnames(fit_lv$coefficients)) & 
              grepl(spline_col, colnames(fit_lv$coefficients))
          ]
          if (length(possible_matches) != 1) {
            stop("Could not uniquely identify interaction column for: ",
                 dummy_col, " and ", spline_col)
          }
          possible_matches
        }, character(1))
        
        # Add intercept for non-reference level if present
        has_group_intercept <- dummy_col %in% colnames(fit_lv$coefficients)
        if (has_group_intercept) {
          X_new <- cbind(
            "(Intercept)" = 1,
            B,
            group_effect = 1,
            B  # interaction terms
          )
          colnames(X_new) <- c(
            "(Intercept)",
            spline_cols,
            dummy_col,
            int_cols
          )
          needed <- c(
            "(Intercept)",
            spline_cols,
            dummy_col,
            int_cols
            )
        } else {
          X_new <- cbind(
            "(Intercept)" = 1,
            B,
            B  # interaction terms only
          )
          colnames(X_new) <- c(
            "(Intercept)",
            spline_cols,
            int_cols
          )
          needed <- c("(Intercept)", spline_cols, int_cols)
        }
      }
    }

    # coefficients matrix
    coef_full      <- as.matrix(fit_lv$coefficients)
    # ensure missing columns are handled
    missing_cols <- setdiff(needed, colnames(coef_full))
    if (length(missing_cols)) {
      for (col in missing_cols) {
        coef_full[, col] <- 0
      }
    }
    
    # subset in correct order
    coef_mat <- coef_full[, needed, drop = FALSE]
    
    # predictions
    pred_mat <- coef_mat %*% t(X_new)

    pred_mat <- adjust_intercept_least_squares(
      pred_mat = pred_mat,
      data = data,
      meta = meta,
      condition = condition,
      level = level,
      time_grid = smooth_timepoints
    )

    # propagate feature names
    rownames(pred_mat) <- rownames(coef_mat)

    pred_list[[level]] <- pred_mat
  }
  
  list(
    time_grid   = smooth_timepoints,
    predictions = pred_list          # named by condition level
  )
}


#' Add effect size estimates to predicted time curves
#'
#' @noRd
#'
#' @description
#' This function computes an absolute "cumulative travel" measure for each
#' feature’s predicted time course, defined as the sum of absolute successive
#' differences across timepoints. The values quantify how much a curve changes
#' over time in total (regardless of direction). Each feature is then labeled
#' as having passed a user-defined effect size threshold.
#'
#' @param predicted_timecurves A list-like object produced by
#'   \code{predict_timecurves()}, containing at least a
#'   \code{$predictions} element. Each element of \code{$predictions}
#'   is a numeric matrix with features in rows and timepoints in columns.
#' @param threshold A numeric scalar giving the minimum cumulative travel
#'   required for a feature to be considered as having passed the effect
#'   size cutoff.
#'
#' @return The input \code{predicted_timecurves} object with two additional
#'   list elements:
#'   \itemize{
#'     \item \code{$effect_size}: A list of named numeric vectors (one per
#'           condition level), giving the cumulative travel per feature.
#'     \item \code{$passed_threshold}: A list of named logical vectors
#'           (one per condition level), indicating whether each feature’s
#'           effect size is greater than or equal to \code{threshold}.
#'   }
#'
#' @details
#' The cumulative travel metric is computed per feature as:
#' \deqn{\sum_{j=1}^{T-1} |x_{j+1} - x_j|,}
#' where \eqn{x_j} are the predicted values at ordered timepoints
#' \eqn{j=1,\dots,T}. This is an absolute path length of the curve and
#' increases with the amount of fluctuation over time.
#'
add_curve_effectsizes <- function(
    predicted_timecurves,
    threshold
    ) {
  # compute absolute cumulative travel per feature
  cum_travel <- function(mat) {
    if (ncol(mat) < 2) {
      out <- rep(0, nrow(mat))
      names(out) <- rownames(mat)
      return(out)
    }
    # row-wise: sum |x_{j+1} - x_j|
    travel <- apply(mat, 1, function(x) sum(abs(diff(x))))
    if (!is.null(rownames(mat))) names(travel) <- rownames(mat)
    travel
  }
  
  results <- lapply(predicted_timecurves$predictions, function(mat) {
    travel <- cum_travel(mat)
    list(
      effect_size = travel,
      passed_threshold = travel >= threshold
    )
  })
  
  predicted_timecurves$effect_size <- lapply(
    results,
    `[[`,
    "effect_size"
    )
  predicted_timecurves$passed_threshold <- lapply(
    results,
    `[[`,
    "passed_threshold"
    )

  predicted_timecurves
}


#' Perform clustering on predicted timecourses
#'
#' @noRd
#'
#' @description
#' Performs clustering for each condition level using
#' precomputed predicted timecourses. For each level, only the features
#' present in the corresponding top table are clustered. The function
#' normalizes each curve to the [0, 1] range before clustering.
#'
#' @param top_tables A named list of data.frames, where each entry contains
#'   significant features (`feature_nr`) for a condition level. Names must be
#'   in the format `{condition}_{level}`.
#' @param nr_clusters A list whose length matches `top_tables`; each element is
#'   a numeric vector of positive integers (e.g. `1:1`, `2:8`) giving the
#'   candidate number(s) of clusters for the corresponding condition level.
#' @param meta A data.frame containing the metadata, including the condition
#'   and time columns.
#' @param condition A string specifying the column in `meta` that encodes
#'   condition levels (e.g., `"Phase"`).
#' @param predicted_timecurves A list returned by [predict_timecurves()],
#'   containing smoothed predictions for all features across all levels.
#'
#' @return A named list of clustering results (one per condition level). Each
#'   entry includes:
#'   \describe{
#'     \item{`clustered_hits`}{Feature-to-cluster assignments}
#'     \item{`hc`}{The full hclust object}
#'     \item{`curve_values`}{Normalized curves with cluster labels}
#'     \item{`top_table`}{Top table with added cluster column}
#'     \item{`clusters`}{Number of clusters used}
#'   }
#' 
perform_clustering <- function(
    top_tables,             
    nr_clusters,
    meta,
    condition,              
    predicted_timecurves
) {

  message("\n Performing the clustering...")
  
  # common dense time grid (same for every level)
  time_grid <- predicted_timecurves$time_grid
  
  # container for clustering results
  results <- vector("list", length = length(top_tables))
  names(results) <- names(top_tables)
  
  # loop over every condition level
  for (i in seq_along(top_tables)) {
    
    key    <- names(top_tables)[i]                       
    level  <- sub(paste0("^", condition, "_"), "", key)  
    message(paste("For the level: ", level))
    k_range <- nr_clusters[[i]]                  

    tbl <- top_tables[[key]]
    if (is.data.frame(tbl)) {
      feat_idx <- tbl$feature_nr
      feat_names <- tbl$feature_names
    } else if (length(tbl) == 0L || all(is.na(tbl))) {
      feat_idx <- integer(0)
      feat_names <- character(0)
    } else {
      feat_idx <- as.integer(tbl)
      feat_names <- rownames(
        predicted_timecurves$predictions[[level]]
        )[feat_idx]
    }
    
    passed <- predicted_timecurves$passed_threshold[[level]]
    feat_names <- feat_names[ feat_names %in% names(passed)[passed] ]
 
    if (length(feat_names) == 0L) {
      results[[key]] <- NA
      next
    }
    
    pred_mat <- predicted_timecurves$predictions[[level]]
    curves   <- pred_mat[ as.character(feat_names), , drop = FALSE ]
    norm_cur <- normalize_curves(curves)
    top_table <- tbl[tbl$feature_names %in% feat_names, , drop = FALSE]

    results[[key]] <- kmeans_clustering(
      curve_values      = norm_cur,
      k_range           = k_range,                   
      smooth_timepoints = time_grid,
      top_table         = top_table,
      condition         = level
    )
  }

  results       
}


#' Get Category 2 and 3 Hits
#'
#' @noRd
#'
#' @description
#' This function filters the `limma` top tables in the `splineomics` object to
#' identify significant features in two categories:
#' \itemize{
#'   \item \strong{Category 2}: Features with a significant average difference
#'   between conditions, based on both adjusted p-value and a minimum absolute
#'   effect size threshold.
#'   \item \strong{Category 3}: Features with a significant condition × time
#'   interaction, based on adjusted p-value, and that also exceed a minimum
#'   time-effect effect size in at least one condition (as provided in
#'   `predicted_timecurves$effect_size`).
#' }
#'
#' @param splineomics An S3 object containing the `limma` top tables. It must
#' include the elements \code{avrg_diff_conditions} and
#' \code{interaction_condition_time}, each a dataframe of results.
#' @param adj_pthresh_avrg_diff_conditions Numeric. Threshold for adjusted
#' p-value when testing average differences between conditions.
#' @param adj_pthresh_interaction Numeric. Threshold for adjusted p-value when
#' testing the interaction between condition and time.
#' @param min_effect_size A named list specifying effect size thresholds:
#' \itemize{
#'   \item \code{avg_diff_cond}: Minimum absolute effect size required for
#'   category 2 hits.
#'   \item \code{time_effect}: Minimum time-effect effect size required in at
#'   least one condition for category 3 hits.
#' }
#' @param predicted_timecurves A list of model predictions, which must contain
#' an element \code{effect_size}. This should be a named list of numeric 
#' vectors,
#' with one vector per condition and feature names as names, providing the
#' time-effect effect sizes.
#'
#' @return A list with two dataframes:
#' \itemize{
#'   \item \code{category_2_hits}: Filtered subset of
#'   \code{avrg_diff_conditions}.
#'   \item \code{category_3_hits}: Filtered subset of
#'   \code{interaction_condition_time}.
#' }
#' 
get_category_2_and_3_hits <- function(
    splineomics,
    adj_pthresh_avrg_diff_conditions,
    adj_pthresh_interaction,
    min_effect_size,
    predicted_timecurves   
) {
  # Extract top tables (already one df each)
  avrg_diff_conditions <- 
    splineomics[["limma_splines_result"]][["avrg_diff_conditions"]]
  interaction_condition_time <- 
    splineomics[["limma_splines_result"]][["interaction_condition_time"]]

  # Category 2: p-value + effect size (abs(col1)) 
  category_2_hits <- avrg_diff_conditions[
    avrg_diff_conditions$adj.P.Val < adj_pthresh_avrg_diff_conditions &
      abs(avrg_diff_conditions[[1]]) >= min_effect_size$avg_diff_cond,
  ]
  
  # Category 3: p-value + time-effect ES >= threshold in >=1 condition
  # p-value filter first
  category_3_hits <- interaction_condition_time[
    interaction_condition_time$adj.P.Val < adj_pthresh_interaction,
  ]
  
  # If nothing passed p-value, return early
  if (nrow(category_3_hits) == 0L) {
    return(list(
      category_2_hits = category_2_hits,
      category_3_hits = category_3_hits
      ))
  }
  
  # Pull time-effect effect sizes per condition 
  es_list <- predicted_timecurves$effect_size
  cond_names <- names(es_list)

  # For two-condition designs, this naturally checks both; for >2 it checks any
  time_es_keep <- vapply(category_3_hits$feature_names, function(fn) {
    any(vapply(cond_names, function(cn) {
      es <- es_list[[cn]][fn]
      !is.na(es) && es >= min_effect_size$time_effect
    }, logical(1)))
  }, logical(1))
  
  category_3_hits <- category_3_hits[time_es_keep, , drop = FALSE]
  
  list(
    category_2_hits = category_2_hits,
    category_3_hits = category_3_hits
  )
}


#' Make Clustering Report
#' 
#' @noRd
#'
#' @description
#' Generates a detailed clustering report including heatmaps, dendrograms,
#' curve plots, and consensus shapes for each level within a condition.
#'
#' @param splineomics A list containing the splineomics results, including
#' time effects, average difference between conditions, and interaction between
#' condition and time.
#' @param all_levels_clustering A list containing clustering results for each
#' level within a condition.
#' @param condition A character string specifying the condition.
#' @param data A matrix of data values.
#' @param meta A dataframe containing metadata.
#' @param annotation Dataframe containig the annotation info of the features,
#'                   such as gene and uniprotID, for example.
#' @param genes Character vector containing the genes of the features.
#' @param spline_params A list of spline parameters for the analysis.
#' @param adj_pthresholds Numeric vector, containing a float < 1 > 0 as each
#'                        value. There is one float for every level, and this is
#'                        the adj. p-value threshold.
#' @param adj_pthresh_avrg_diff_conditions Float
#' @param adj_pthresh_interaction_condition_time Float
#' @param category_2_and_3_hits List of dataframes, where each df is the part
#' of the toptable that contains the significant features of the respective 
#' limma result category (2 or 3).
#' @param report_dir A character string specifying the report directory.
#' @param mode A character string specifying the mode
#' ('isolated' or 'integrated').
#' @param report_info A named list containing report information such as analyst
#'                    name, fixed and random effects, etc.
#' @param predicted_timecurves A list returned by [predict_timecurves()],
#'   containing:
#'   \describe{
#'     \item{`time_grid`}{A numeric vector of dense time points used for
#'       evaluation.}
#'     \item{`predictions`}{A named list of matrices, one per condition level.
#'       Each matrix contains predicted values (rows = features, columns =
#'       timepoints).}
#'   }
#' @param fit Full fitted model returned by limma or variancePartition::dream.
#' @param design A string representing the limma design formula
#' @param meta_batch_column A character string specifying the meta batch column.
#' @param meta_batch2_column A character string specifying the second meta
#'                           batch column.
#' @param plot_info List containing the elements y_axis_label (string),
#'                  time_unit (string), treatment_labels (character vector),
#'                  treatment_timepoints (integer vector). All can also be NA.
#'                  This list is used to add this info to the spline plots.
#'                  time_unit is used to label the x-axis, and treatment_labels
#'                  and -timepoints are used to create vertical dashed lines,
#'                  indicating the positions of the treatments (such as
#'                  feeding, temperature shift, etc.).
#' @param plot_options List with specific fields (cluster_heatmap_columns =
#' Bool) that allow for customization of plotting behavior.
#' @param feature_name_columns Character vector containing the column names of
#'                             the annotation info that describe the features.
#'                             This argument is used to specify in the HTML
#'                             report how exactly the feature names displayed
#'                             above each individual spline plot have been
#'                             created. Use the same vector that was used to
#'                             create the row headers for the data matrix!
#' @param spline_comp_plots List containing the list of lists with all
#' the plots for all the pairwise comparisons of the condition in terms of
#' average spline diff and interaction condition time, and another list of lists
#' where the respective names of each plot are stored.
#' @param raw_data Optional. Data matrix with the raw (unimputed) data, still 
#' containing NA values. When provided, it highlights the datapoints in the 
#' spline plots that originally where NA and that were imputed.
#' @param max_hit_number Maximum number of hits which are plotted within each
#' cluster. This can be used to limit the computation time and size of
#' the HTML report in the case of many hits.
#'
#' @return No return value, called for side effects.
#'
#' @seealso
#' \code{\link{removeBatchEffect}}, \code{\link{plot_heatmap}},
#' \code{\link{plot_cluster_mean_splines}}, \code{\link{plot_splines}},
#' \code{\link{generate_report_html}}
#'
#' @importFrom limma removeBatchEffect
#' @importFrom dplyr filter
#' @importFrom stats na.omit
#' @importFrom rlang .data
#'
make_clustering_report <- function(
    all_levels_clustering,
    condition,
    data,
    meta,
    annotation,
    genes,
    spline_params,
    adj_pthresholds,
    adj_pthresh_avrg_diff_conditions,
    adj_pthresh_interaction_condition_time,
    category_2_and_3_hits,
    report_dir,
    mode,
    report_info,
    predicted_timecurves,
    design,
    meta_batch_column,
    meta_batch2_column,
    plot_info,
    plot_options,
    feature_name_columns,
    spline_comp_plots,
    raw_data,
    max_hit_number
    ) {

  design <- gsub("Time", "X", design)  
  effects <- extract_effects(design)

  datas <- split_data_by_condition(
    data = data,
    meta = meta,
    condition = condition,
    mode = mode
    )

  # To extract the stored value for the potential auto cluster decision.
  clusters <- c()
  for (i in seq_along(all_levels_clustering)) {
    if (is.null(all_levels_clustering[[i]]) ||
      all(is.na(all_levels_clustering[[i]]))) {
      next
    }

    clusters <- c(clusters, as.integer(all_levels_clustering[[i]]$clusters))
    all_levels_clustering[[i]]$clusters <- NULL
  }

  if (!dir.exists(report_dir)) {
    dir.create(report_dir)
  }

  time_unit_label <- paste0("[", plot_info$time_unit, "]")
  
  message("Generating heatmap...")
  heatmaps <- plot_heatmap(
    datas = datas,
    meta = meta,
    mode = mode,
    condition = condition,
    all_levels_clustering = all_levels_clustering,
    time_unit_label = time_unit_label,
    cluster_heatmap_columns = plot_options[["cluster_heatmap_columns"]],
    max_hit_number = max_hit_number
  )

  level_headers_info <- list()
  plots <- list()
  plots_sizes <- list()
  q <- 0
  
  
  for (i in seq_along(all_levels_clustering)) {
    # When a level has < 2 hits
    if (is.null(all_levels_clustering[[i]]) ||
      all(is.na(all_levels_clustering[[i]]))) {
      next
    } else {
      q <- q + 1
    }

    level_clustering <- all_levels_clustering[[i]]

    levels <- unique(meta[[condition]])

    if (length(levels) >= i) {
      level <- levels[i]
      
      # Get indices of columns in meta that match the given level (condition)
      condition_indices <- which(meta[["condition"]] == level)
      
      # Subset raw_data to only include these columns (keeping all rows)
      raw_data_level <- raw_data[, condition_indices, drop = FALSE]

      # Construct header name
      header_name <- level

      nr_hits <- nrow(level_clustering$clustered_hits)

      header_info <- list(
        header_name = header_name,
        nr_hits = nr_hits,
        adj_pvalue_threshold = adj_pthresholds[i]
      )

      level_headers_info[[i]] <- header_info
    }

    curve_values <- level_clustering$curve_values

    p_curves <- plot_all_mean_splines(
      curve_values = curve_values,
      plot_info = plot_info,
      level = level
    )
    
    message(paste("Generating cluster mean splines for level: ", level))
    cluster_mean_splines <- plot_cluster_mean_splines( # Plot for each cluster
      curve_values = curve_values,
      plot_info = plot_info,
      level = level,
      max_hit_number = max_hit_number
    )

    top_table <- level_clustering$top_table
    levels <- as.character(unique(meta[[condition]]))

    col_indices <- which(meta[[condition]] == levels[i])

    if (mode == "integrated") {
      data_level <- datas[[i]][, col_indices]
    } else { # mode == "isolated"
      data_level <- datas[[i]]
    }

    meta_level <- meta |> dplyr::filter(.data[[condition]] == levels[i])

    clusters_spline_plots <- list()
    
    message("Generating spline plots...")
    for (nr_cluster in sort(unique(stats::na.omit(top_table$cluster)))) {
      nr_of_hits <- sum(
        level_clustering$clustered_hits$cluster == nr_cluster,
        na.rm = TRUE
      )
      main_title <- paste(
        "Cluster",
        nr_cluster,
        " | Hits:",
        nr_of_hits,
        sep = " "
      )

      top_table_cluster <- top_table |>
        dplyr::filter(!!rlang::sym("cluster") == nr_cluster)

      X <- level_clustering$X

      spline_plots <- plot_splines(
        top_table = top_table_cluster,
        data = data_level,
        meta = meta_level,
        predicted_timecurves = predicted_timecurves,
        time_unit_label = time_unit_label,
        plot_info = plot_info,
        adj_pthreshold = adj_pthresholds[i],
        replicate_column = plot_options[["meta_replicate_column"]],
        level = level,
        raw_data = raw_data_level,
        report_info = report_info,
        max_hit_number = max_hit_number
      )

      clusters_spline_plots[[length(clusters_spline_plots) + 1]] <- list(
        spline_plots = spline_plots,
        cluster_main_title = main_title
      )
    }

    plots <- c(
      plots,
      new_level = "level_header", # is the signal for the plotting code
      p_curves = list(p_curves),
      cluster_mean_splines = list(cluster_mean_splines),
      heatmap = heatmaps[[i]],
      individual_spline_plots = clusters_spline_plots # gets expanded like this
    )

    # For every plot in plots, this determines the size in the HTML
    plots_sizes <- c(
      plots_sizes,
      999, # dummy size for "next_level" signal
      1.5,
      1,
      1.5,
      rep(1, length(clusters_spline_plots))
    )
  }

  topTables <- list()

  # Loop over each element in all_levels_clustering
  for (i in seq_along(all_levels_clustering)) {
    if (is.logical(all_levels_clustering[[i]])) next

    # Get the current element, which is a list
    current_element <- all_levels_clustering[[i]]

    # Extract the top_table element
    top_table_element <- current_element$top_table

    # Get the name of the outer list element
    element_name <- names(all_levels_clustering)[i]

    # Trim the name to 30 characters if necessary
    if (nchar(element_name) > 30) {
      element_name <- substr(element_name, 1, 30)
    }

    topTables[[element_name]] <- top_table_element
  }

  if (!is.null(genes)) {
    enrichr_format <- prepare_gene_lists_for_enrichr(
      all_levels_clustering,
      genes
    )
  } else {
    enrichr_format <- NA
  }

  all_levels_clustering <- merge_annotation_all_levels_clustering(
    all_levels_clustering = all_levels_clustering,
    annotation = annotation
  )

  message("Generating report. This takes a few seconds.")
  report_info[["max_hit_number"]] <- max_hit_number

  generate_report_html(
    plots = plots,
    limma_result_2_and_3_plots = spline_comp_plots,
    plots_sizes = plots_sizes,
    level_headers_info = level_headers_info,
    spline_params = spline_params,
    report_info = report_info,
    data = bind_data_with_annotation(data, annotation),
    meta = meta,
    topTables = topTables,
    category_2_and_3_hits = category_2_and_3_hits,
    enrichr_format = enrichr_format,
    adj_pthresholds = adj_pthresholds,
    adj_pthresh_avrg_diff_conditions = adj_pthresh_avrg_diff_conditions,
    adj_pthresh_interaction_condition_time =
      adj_pthresh_interaction_condition_time,
    report_type = "cluster_hits",
    feature_name_columns = feature_name_columns,
    mode = mode,
    filename = "report_clustered_hits",
    report_dir = report_dir
  )

  return(plots)
}


#' Generate spline comparison plots for all condition pairs
#' 
#' @noRd
#'
#' @description
#' Generates the "double spline plots" (limma result categories 2 & 3).
#' This function generates spline comparison plots for all pairwise
#' combinations of conditions in the metadata. For each condition pair, it
#' compares the time effects of two conditions, plots the data points, and
#' overlays the fitted spline curves. The function only generates plots if
#' the adjusted p-values for the average difference between conditions and the
#' interaction between condition and time are below the specified thresholds.
#'
#' @param splineomics A list containing the splineomics results, including
#'  time effects,
#' average difference between conditions, and interaction between condition
#' and time.
#' @param data The data matrix containing the measurements.
#' @param meta The metadata associated with the measurements, which includes
#'  the condition.
#' @param condition Column name of meta that contains the levels of the
#' experiment.
#' @param replicate_column Column name of the meta column that specifies the
#' replicates per timepoint. For example Reactor with the unique values: 
#' 'ReactorE16', 'ReactorE17', ... which means that multiple bioreactors where
#' running this experiment and each timepoint has one sample from each reactor.
#' @param plot_info A list containing plotting information such as time unit
#' and axis labels.
#' @param adj_pthresh_avrg_diff_conditions The adjusted p-value threshold for
#'  the average
#' difference between conditions.
#' @param adj_pthresh_interaction The adjusted p-value threshold for the
#' interaction
#' between condition and time.
#' @param raw_data Optional. Data matrix with the raw (unimputed) data, still 
#' containing NA values. When provided, it highlights the datapoints in the 
#' spline plots that originally where NA and that were imputed.
#' @param predicted_timecurves A list returned by [predict_timecurves()],
#'   containing:
#'   \describe{
#'     \item{`time_grid`}{A numeric vector of dense time points used for
#'       evaluation.}
#'     \item{`predictions`}{A named list of matrices, one per condition level.
#'       Each matrix contains predicted values (rows = features, columns =
#'       timepoints).}
#'   }
#' @param max_hit_number Maximum number of hits for which the individual spline
#' plots are shown. This can be used to limit the computation time and size of
#' the HTML report in the case of many hits.
#'
#' @return A list of lists containing the comparison plots and feature names
#'         for each condition pair.
#'
generate_spline_comparisons <- function(
    splineomics,
    data,
    meta,
    condition,
    replicate_column,
    plot_info,
    raw_data,
    predicted_timecurves,
    max_hit_number,
    category_2_and_3_hits,
    adj_pthresh_avrg_diff_conditions,
    adj_pthresh_interaction
) {
  # Ensure `condition` column is character
  meta[[condition]] <- as.character(meta[[condition]])
  levels <- unique(meta[[condition]])

  c1 <- levels[1]
  c2 <- levels[2]
  pair_name <- paste0(c1, "_vs_", c2)
  
  # time effects for the two levels
  te_list <- splineomics[["limma_splines_result"]][["time_effect"]]
  te1 <- te_list[[paste0(condition, "_", c1)]]
  te2 <- te_list[[paste0(condition, "_", c2)]]
  
  # Call the plotting helper once for the single pair
  plots_and_feature_names <- plot_spline_comparisons(
    time_effect_1 = te1,
    condition_1 = c1,
    time_effect_2 = te2,
    condition_2 = c2,
    avrg_diff_conditions = category_2_and_3_hits[["category_2_hits"]],             
    interaction_condition_time = category_2_and_3_hits[["category_3_hits"]], 
    data = data,
    meta = meta,
    condition = condition,
    replicate_column = replicate_column,
    predicted_timecurves = predicted_timecurves,
    adj_pthresh_avrg_diff_conditions = adj_pthresh_avrg_diff_conditions,
    adj_pthresh_interaction = adj_pthresh_interaction,
    plot_info = plot_info,
    raw_data = raw_data,
    max_hit_number = max_hit_number
  )
  
  comparison_plots <- list()
  comparison_plots[[pair_name]] <- plots_and_feature_names
  comparison_plots
}


#' Clean the Gene Symbols
#' 
#' @noRd
#'
#' @description
#' This function preprocesses a vector of gene names by cleaning and
#' formatting them. It removes any non-alphanumeric characters after the
#' first block of alphanumeric characters and converts the remaining
#' characters to uppercase.
#'
#' @param genes A character vector containing gene names to be cleaned.
#'
#' @return A character vector of cleaned gene symbols (names) with the same
#' length as the input. The cleaned names will be in uppercase, and any
#' invalid or empty gene names will be replaced with NA.
#'
clean_gene_symbols <- function(genes) {
  
  message(paste0(
    "\033[33m\nGene symbols: Transforming all non-alphanumeric characters to ",
    "whitespace, then extracting the substring of alphanumeric characters ",
    "before the first whitespace or end of the string. The extracted ",
    "substring is then converted to uppercase.\033[0m"
  ))

  message(paste0(
    "\033[38;5;214mIf this does not produce valid gene symbols for your gene",
    "set enrichment analysis, modify ",
    "the genes argument of this function (cluster_hits) accordingly!\033[0m"
  ))

  # Apply cleaning process to each gene
  cleaned_genes <- vapply(genes, function(gene_name) {
    if (!is.na(gene_name) && gene_name != "") {
      # Replace all non-alphanumeric characters with whitespace
      gene_name <- gsub("[^A-Za-z0-9]", " ", gene_name)

      # Extract the first block of alphanumeric characters before the
      # first whitespace
      clean_gene_name <- sub("^([A-Za-z0-9]+).*", "\\1", gene_name)

      # Convert to uppercase
      toupper(clean_gene_name)
    } else {
      as.character(NA)
    }
  }, character(1))

  # Return cleaned genes, keeping the same index as input
  return(cleaned_genes)
}


#' Construct unified cluster summary table
#'
#' @noRd
#'
#' @description
#' Constructs a unified cluster summary table for all features across
#' time-effect (category 1) and, if present, average-difference
#' (category 2) and interaction (category 3) results. Combines cluster
#' assignments for two conditions, gene annotations, and feature names
#' into a single flat tibble. For cat3 (when available), cluster labels
#' are condition-combination strings (e.g., `"1_2"`, `"NA_2"`) shown
#' only for features in the cat3 hit set. For cat2 (when available),
#' the column encodes **direction** using two labels:
#' `"<cond1>_higher"` or `"<cond2>_higher"` (condition names are taken
#' from `clustered_hits_levels` with underscores removed). Direction is
#' determined from the signed `PhaseStationary` statistic in
#' `avrg_diff_conditions`, with **positive → `<cond2>_higher`** and
#' **negative → `<cond1>_higher`**. Features not significant in a
#' category receive `NA` in that category’s column. If
#' `limma_splines_results` contains only time-effect results, cat2/cat3
#' logic is skipped and those columns are omitted.
#'
#' @param limma_splines_results A list with required sublist
#'   `time_effect` (two tibbles, one per condition; each contains at
#'   least `feature_nr` and `feature_names`). It may also include:
#'   * `avrg_diff_conditions`: tibble of category 2 results (optional),
#'     including `feature_nr` and `PhaseStationary`.
#'   * `interaction_condition_time`: tibble of category 3 results
#'     (optional).
#' @param clustered_hits_levels A named list of two data frames mapping
#'   time-effect significant features to clusters. Each must have
#'   columns `feature` (numeric ID), `cluster` (factor/character), and
#'   optionally `gene`. Row names may store `feature_name`s. The list
#'   element names are used to name the two time-effect cluster columns
#'   in the output.
#' @param category_2_and_3_hits A list with elements `category_2_hits`
#'   and `category_3_hits` (each a tibble containing at least
#'   `feature_nr`). Used only if the corresponding cat2/cat3 result is
#'   present and non-empty; otherwise ignored.
#' @param annotation A tibble or data frame with row names equal to
#'   `feature_nr` and columns `Gene_symbol` and/or `Gene_name`.
#'
#' @return A tibble with columns:
#'   * `feature_nr` – numeric feature identifier.
#'   * `feature_name` – preferred feature name from any source.
#'   * `gene` – preferred gene symbol or fallback from cluster data.
#'   * `cluster_<cond1>` / `cluster_<cond2>` – clusters for each
#'     time-effect condition (cat1). `NA` indicates not a cat1 hit.
#'   * `cluster_cat2` – present only if category 2 results exist; a
#'     **direction label** `"<cond1>_higher"` or `"<cond2>_higher"`
#'     derived from `PhaseStationary` (positive → `<cond2>_higher`,
#'     negative → `<cond1>_higher`). `NA` indicates not a cat2 hit (or
#'     zero/undefined direction).
#'   * `cluster_cat3` – present only if category 3 results exist; a
#'     condition-combination string `"<cluster_<cond1>>_<cluster_<cond2>>"`
#'     shown only for cat3 hits, otherwise `NA`.
#'
#' @importFrom dplyr mutate transmute filter select rename left_join
#'   arrange distinct group_by ungroup slice_head bind_rows coalesce
#' @importFrom tibble as_tibble tibble
#' @importFrom rlang sym
#' 
construct_cluster_summary <- function(
    limma_splines_results,
    clustered_hits_levels,
    category_2_and_3_hits,
    genes
) {

  nm <- names(clustered_hits_levels)
  if (is.null(nm) || length(nm) != 2 || any(is.na(nm) | nm == "")) {
    nm <- c("condition1", "condition2")
  }
  c1 <- paste0("cluster_", nm[[1]])
  c2 <- paste0("cluster_", nm[[2]])
  nmc <- gsub("_", "", nm)
  
  has_c2 <- !is.null(limma_splines_results$avrg_diff_conditions) &&
    nrow(stbl(limma_splines_results$avrg_diff_conditions)) > 0
  has_c3 <- !is.null(limma_splines_results$interaction_condition_time) &&
    nrow(stbl(limma_splines_results$interaction_condition_time)) > 0
  use_cat23 <- has_c2 || has_c3
  
  no_genes <- is.null(genes)
  anot <- if (no_genes) {
    tibble(feature_nr = numeric(0), gan = character(0))
  } else {
    tibble(feature_nr = seq_along(genes), gan = as.character(genes)) %>%
      distinct(feature_nr, .keep_all = TRUE)
  }
  
  cl1 <- ncl(clustered_hits_levels[[1]], c1)
  cl2 <- ncl(clustered_hits_levels[[2]], c2)
  
  te <- limma_splines_results$time_effect
  add_parts <- list(
    toptbl_to_fn(te[[1]]),
    toptbl_to_fn(te[[2]])
  )
  if (has_c2) add_parts <- c(
    add_parts,
    list(toptbl_to_fn(limma_splines_results$avrg_diff_conditions))
  )
  if (has_c3) add_parts <- c(
    add_parts,
    list(toptbl_to_fn(limma_splines_results$interaction_condition_time))
  )
  fn_tbl <- bind_rows(add_parts) %>%
    distinct(feature_nr, .keep_all = TRUE)
  
  fn_from_cl <- bind_rows(
    cl1 %>% select(feature_nr, fnsrc) %>% rename(fname_cl = fnsrc),
    cl2 %>% select(feature_nr, fnsrc) %>% rename(fname_cl = fnsrc)
  ) %>%
    filter(!is.na(feature_nr), !is.na(fname_cl), fname_cl != "") %>%
    distinct(feature_nr, .keep_all = TRUE)
  
  allf_parts <- list(
    anot %>% select(feature_nr),
    cl1 %>% select(feature_nr),
    cl2 %>% select(feature_nr),
    fn_tbl %>% select(feature_nr)
  )
  
  if (use_cat23) {
    cat2h <- if (has_c2) {
      category_2_and_3_hits$category_2_hits %>%
        stbl() %>% transmute(feature_nr) %>% distinct()
    } else tibble(feature_nr = numeric(0))
    cat3h <- if (has_c3) {
      category_2_and_3_hits$category_3_hits %>%
        stbl() %>% transmute(feature_nr) %>% distinct()
    } else tibble(feature_nr = numeric(0))
    allf_parts <- c(allf_parts, list(cat2h, cat3h))
  }
  
  allf <- bind_rows(allf_parts) %>%
    distinct(feature_nr) %>%
    filter(!is.na(feature_nr)) %>%
    arrange(feature_nr)
  
  base <- allf %>%
    left_join(anot, by = "feature_nr") %>%
    left_join(cl1 %>% select(feature_nr, !!sym(c1), gcl, fnsrc),
              by = "feature_nr") %>%
    rename(gcl1 = gcl, fnsrc1 = fnsrc) %>%
    left_join(cl2 %>% select(feature_nr, !!sym(c2), gcl, fnsrc),
              by = "feature_nr") %>%
    rename(gcl2 = gcl, fnsrc2 = fnsrc) %>%
    left_join(fn_from_cl, by = "feature_nr") %>%
    left_join(fn_tbl, by = "feature_nr") %>%
    group_by(feature_nr) %>%
    slice_head(n = 1) %>%
    ungroup() %>%
    mutate(
      feature_name = coalesce(
        fname_tbl, fname_cl, fnsrc1, fnsrc2, as.character(feature_nr)
      ),
      gene = if (no_genes) NA_character_ else coalesce(gan, gcl1, gcl2)
    ) %>%
    select(feature_nr, feature_name, gene, all_of(c(c1, c2)))
  
  if (!use_cat23) {
    return(base %>% distinct(feature_nr, .keep_all = TRUE) %>%
             arrange(feature_nr))
  }
  
  # cat2: direction by <cond2 score> -> "<cond>_higher"
  out <- base
  if (has_c2) {
    c2_tbl <- stbl(limma_splines_results$avrg_diff_conditions)
    
    # pick cond2 score column ignoring underscores
    score_col <- find_col_ignore_underscores_rx(c2_tbl, nm[[2]])
    if (is.na(score_col) || !is.numeric(c2_tbl[[score_col]])) {
      stop_call_false(
        "Missing logFC column in topTable for avr diff conditions."
        )
    }
    
    c2_df <- c2_tbl %>%
      transmute(
        feature_nr,
        cluster_cat2 = dplyr::case_when(
          .data[[score_col]] > 0 ~ paste0(gsub("_","", nm[[2]]), "_higher"),
          .data[[score_col]] < 0 ~ paste0(gsub("_","", nm[[1]]), "_higher"),
          TRUE ~ NA_character_
        )
      ) %>%
      distinct(feature_nr, .keep_all = TRUE)
    
    if (!is.null(category_2_and_3_hits$category_2_hits) &&
        nrow(category_2_and_3_hits$category_2_hits) > 0) {
      cat2h <- category_2_and_3_hits$category_2_hits %>%
        stbl() %>% transmute(feature_nr) %>% distinct()
      c2_df <- c2_df %>%
        mutate(cluster_cat2 = ifelse(feature_nr %in% cat2h$feature_nr,
                                     cluster_cat2, NA_character_))
    }
    
    out <- out %>% left_join(c2_df, by = "feature_nr")
  }
  
  has_cat3_hits <- has_c3 &&
    !is.null(category_2_and_3_hits$category_3_hits) &&
    nrow(category_2_and_3_hits$category_3_hits) > 0
  
  if (has_cat3_hits) {
    cat3h <- category_2_and_3_hits$category_3_hits %>%
      stbl() %>% transmute(feature_nr) %>% distinct()
    cat3c <- mkc(base, cat3h, c1, c2) %>% rename(cluster_cat3 = .cmb)
    out <- out %>% left_join(cat3c, by = "feature_nr")
  } else if (has_c3) {
    # No category-3 hits, but we still want the column present (NA-filled)
    out <- out %>% mutate(cluster_cat3 = NA_character_)
  }
  
  out %>% distinct(feature_nr, .keep_all = TRUE) %>% arrange(feature_nr)
}


# Level 2 internal functions ---------------------------------------------------


#' Check for Between-Level Patterns in Top Tables
#' 
#' @noRd
#'
#' @description
#' This function checks if any of the elements within a list of top tables
#' contain element names that match the specified between-level pattern.
#'
#' @param top_tables A list where each element is itself a list containing
#' named elements.
#'
#' @return A list with two elements:
#' \describe{
#'   \item{between_levels}{A logical value indicating whether any element names
#'   match the between-level pattern.}
#'   \item{index_with_pattern}{The index of the first element in `top_tables`
#'   where all names match the between-level pattern, or NA if no match is
#'   found.}
#' }
#'
#' @details
#' The function iterates over each element in `top_tables`. For each element
#' that
#' is a list, it checks if all names within that inner list match the pattern
#' `".+_vs_.+"`. If a match is found, the function sets `between_levels` to TRUE
#' and records the index of the matching element. The search stops at the first
#' match.
#'
check_between_level_pattern <- function(top_tables) {
  # Initialize variables
  between_levels <- FALSE
  index_with_pattern <- NA

  # Define the regular expression pattern
  pattern <- ".+_vs_.+"

  # Check if top_tables is a list
  if (is.list(top_tables)) {
    # Iterate over each element in top_tables
    for (i in seq_along(top_tables)) {
      # Check if the element is a list
      if (is.list(top_tables[[i]])) {
        # Get the names of the elements in the inner list
        element_names <- names(top_tables[[i]])
        # Check if all names in the inner list match the pattern
        if (all(grepl(pattern, element_names))) {
          between_levels <- TRUE
          index_with_pattern <- i
          break
        }
      }
    }
  }

  return(list(
    between_levels = between_levels,
    index_with_pattern = index_with_pattern
  ))
}


#' Get Hit Indices for a Specific Level
#' 
#' @noRd
#'
#' @description
#' This function retrieves unique feature indices from a list of between-level
#' top tables for a specified level, based on adjusted p-value thresholds.
#'
#' @param between_level_top_tables A list of data frames containing the
#' between-level top tables.
#' @param level A string specifying the level to search for within the names
#' of the data frames.
#' @param adj_pthresholds A numeric vector of adjusted p-value thresholds for
#' each data frame in `between_level_top_tables`.
#'
#' @return A vector of unique feature indices that meet the adjusted p-value
#' threshold criteria for the specified level.
#'
#' @details
#' The function iterates over each data frame in `between_level_top_tables`. For
#' each data frame whose name contains the specified level (case insensitive),
#' it identifies the rows where the adjusted p-value is below the corresponding
#' threshold. The function then extracts the feature indices from these rows and
#' compiles a unique list of these indices.
#'
get_level_hit_indices <- function(
    between_level_top_tables,
    level,
    adj_pthresholds) {
  unique_hit_indices <- c()

  # Loop through the elements of the list
  for (i in seq_along(between_level_top_tables)) {
    # Get the name of the current data frame
    df_name <- names(between_level_top_tables)[i]

    # Check if the name contains the level string case insensitively
    if (grepl(level, df_name, ignore.case = TRUE)) {
      # Get the current data frame
      within_level_top_table <- between_level_top_tables[[i]]

      # Find the row indices that meet the condition
      hit_indices <-
        which(within_level_top_table[["adj.P.Val"]] < adj_pthresholds[i])

      # Extract the feature indices from the identified rows
      feature_indices <- within_level_top_table[hit_indices, "feature_nr"]
      feature_indices <- within_level_top_table[hit_indices,
        "feature_nr",
        drop = TRUE
      ]
      unique_hit_indices <- c(
        unique_hit_indices,
        feature_indices
      )
    }
  }

  # Get unique feature indices
  unique_hit_indices <- unique(unique_hit_indices)
}


#' Split or duplicate a data matrix by condition level
#' 
#' @noRd
#'
#' @description
#' This function returns a list of data matrices, either split by
#' condition level (if mode is "isolated") or duplicated for each level
#' (if mode is "integrated"). This is used to prepare per-condition data
#' subsets for downstream processing or plotting.
#'
#' @param data A numeric matrix with features as rows and samples as
#'   columns.
#' @param meta A data.frame containing sample-level metadata. Each row
#'   corresponds to a column in the data matrix.
#' @param condition A character string specifying the column in `meta`
#'   that defines the condition or group variable.
#' @param mode A string, either "isolated" or "integrated", determining
#'   whether to split the data or return full copies per level.
#'
#' @return A named list of data matrices, one for each condition level.
#' 
split_data_by_condition <- function(
    data,
    meta,
    condition,
    mode
    ) {
  
  datas <- list()
  levels <- unique(meta[[condition]])
  
  for (level in levels) {
    if (mode == "isolated") {
      cols <- which(meta[[condition]] == level)
      datas[[level]] <- data[, cols, drop = FALSE]
    } else {
      datas[[level]] <- data  # same full data for all levels
    }
  }
  
  return(datas)
}


#' Plot Heatmap
#' 
#' @noRd
#'
#' @description
#' Generates heatmaps for each level within a condition, showing z-scores of
#' log2 intensity values, split by clusters.
#'
#' @param datas A matrix of data values.
#' @param meta A dataframe containing metadata.
#' @param mode A character vector with length 1, specifying the type of limma
#'             design formula (integrated for formulas with interaction effects
#'             between the levels, isolated for formulas where each level is
#'             analysed in isolation (no interaction effects))
#' @param condition A character string specifying the condition.
#' @param all_levels_clustering A list containing clustering results for each
#' level within the condition.
#' @param time_unit_label A character string specifying the time unit label.
#' @param cluster_heatmap_columns Boolean specifying wether to cluster the
#' columns of the heatmap or not.
#' @param max_hit_number Maximum number of hits which are plotted within each
#' cluster. This can be used to limit the computation time and size of
#' the HTML report in the case of many hits.
#'
#' @return A list of ComplexHeatmap heatmap objects for each level.
#'
#' @seealso
#' \link[ComplexHeatmap]{Heatmap}, \link[dplyr]{arrange}
#'
#' @importFrom dplyr arrange mutate group_by summarize
#' @importFrom tidyr pivot_longer separate
#' @importFrom ComplexHeatmap Heatmap draw ht_opt
#' @importFrom ggplot2 ggplot geom_line facet_wrap geom_vline ylab theme unit
#' @importFrom ggplot2 theme_bw scale_x_continuous
#' @importFrom grid gpar
#'
plot_heatmap <- function(
    datas,
    meta,
    mode,
    condition,
    all_levels_clustering,
    time_unit_label,
    cluster_heatmap_columns,
    max_hit_number
    ) {
  
  BASE_TEXT_SIZE_PT <- 5

  ht_opt(
    simple_anno_size = unit(1.5, "mm"),
    COLUMN_ANNO_PADDING = unit(1, "pt"),
    DENDROGRAM_PADDING = unit(1, "pt"),
    HEATMAP_LEGEND_PADDING = unit(1, "mm"),
    ROW_ANNO_PADDING = unit(1, "pt"),
    TITLE_PADDING = unit(2, "mm"),
    heatmap_row_title_gp = gpar(fontsize = BASE_TEXT_SIZE_PT),
    heatmap_row_names_gp = gpar(fontsize = BASE_TEXT_SIZE_PT),
    heatmap_column_title_gp = gpar(fontsize = BASE_TEXT_SIZE_PT),
    heatmap_column_names_gp = gpar(fontsize = BASE_TEXT_SIZE_PT),
    legend_labels_gp = gpar(fontsize = BASE_TEXT_SIZE_PT),
    legend_title_gp = gpar(fontsize = BASE_TEXT_SIZE_PT),
    legend_border = FALSE
  )

  ht_opt$message <- FALSE

  levels <- unique(meta[[condition]])
  heatmaps <- list()

  # Generate a heatmap for every level
  for (i in seq_along(all_levels_clustering)) {
    # When a level has < 2 hits
    if (is.null(all_levels_clustering[[i]]) ||
      all(is.na(all_levels_clustering[[i]]))) {
      heatmaps[[length(heatmaps) + 1]] <- NA
      next
    }

    level_clustering <- all_levels_clustering[[i]]

    clustered_hits <- level_clustering$clustered_hits
    clusters <- clustered_hits |> dplyr::arrange(!!rlang::sym("cluster"))
    
    if (!is.infinite(max_hit_number)) {
      clusters <- clusters |>
        dplyr::group_by(cluster) |>
        dplyr::slice_head(n = max_hit_number) |>
        dplyr::ungroup()
    }

    level <- levels[[i]]
    level_indices <- which(meta[[condition]] == level)

    if (mode == "integrated") {
      data_level <- datas[[i]][, level_indices]
    } else { # mode == "isolated"
      data_level <- datas[[i]]
    }

    data_level <- data_level[as.numeric(clusters$feature), ]
    z_score <- t(scale(t(data_level)))

    meta_level <- meta[level_indices, ]

    row_labels <- truncate_row_names(rownames(data_level))

    if (is.null(cluster_heatmap_columns)) { # set default value
      cluster_heatmap_columns <- FALSE
    }

    ht <-
      ComplexHeatmap::Heatmap(
        z_score,
        name = paste0(
          "left-labels = cluster,",
          "top-labels = time"
        ),
        use_raster = TRUE,
        column_split = meta_level$Time,
        cluster_columns = cluster_heatmap_columns,
        row_split = clusters$cluster,
        cluster_rows = FALSE,
        heatmap_legend_param = list(
          title = "z-score of log2 values",
          title_position = "lefttop-rot"
        ),
        row_gap = unit(2, "pt"),
        column_gap = unit(2, "pt"),
        show_row_names = TRUE,
        row_labels = row_labels,
        show_column_names = TRUE,
        column_names_rot = 70,
        column_names_gp = gpar(fontsize = 5)
      )

    heatmaps[[length(heatmaps) + 1]] <- ht
  }
  heatmaps
}


#' Plot All Mean Splines
#' 
#' @noRd
#'
#' @description
#' Generates a plot of average curves for each cluster, showing min-max
#' normalized intensities over time.
#'
#' @param curve_values A dataframe containing curve values and cluster
#' assignments.
#' @param plot_info List containing the elements y_axis_label (string),
#'                  time_unit (string), treatment_labels (character vector),
#'                  treatment_timepoints (integer vector). All can also be NA.
#'                  This list is used to add this info to the spline plots.
#'                  time_unit is used to label the x-axis, and treatment_labels
#'                  and -timepoints are used to create vertical dashed lines,
#'                  indicating the positions of the treatments (such as
#'                  feeding, temperature shift, etc.).
#' @param level One of the unique values of the meta condition column. This is
#'              a factor that separates the experiment.
#'
#' @return A ggplot object representing the average curves by cluster.
#'
#' @importFrom scales hue_pal
#' @importFrom ggplot2 ggplot geom_line ggtitle xlab ylab scale_color_brewer
#'                     theme_minimal aes element_text
#' @importFrom rlang .data
#'
plot_all_mean_splines <- function(
    curve_values,
    plot_info,
    level
    ) {
  
  time <- as.numeric(colnames(curve_values)[-length(colnames(curve_values))])

  clusters <- unique(curve_values$cluster)
  average_curves <- data.frame()

  # Loop through each unique cluster value to calculate the average curve
  for (current_cluster in clusters) {
    # Filter rows for the current cluster
    subset_hits <- curve_values[curve_values$cluster == current_cluster, ]
    last_timepoint <- (which(names(curve_values) == "cluster")) - 1
    average_curve <- colMeans(subset_hits[, seq_len(last_timepoint)])

    # Create a data frame for the average curve with an additional 'Cluster'
    # column
    curve_df <- data.frame(
      Time = time, Value = average_curve,
      cluster = as.factor(current_cluster)
    )

    # Bind the curve data frame to the cumulative data frame
    average_curves <- rbind(
      average_curves,
      curve_df
    )
  }

  average_curves$cluster <- factor(
    average_curves$cluster,
    levels = sort(
      unique(as.numeric(average_curves$cluster))
    )
  )

  time_unit_label <- paste0("[", plot_info$time_unit, "]")

  cluster_colors <- scales::hue_pal()(length(unique(average_curves$cluster)))

  if (length(cluster_colors) > length(unique(average_curves$cluster))) {
    cluster_colors <- 
      cluster_colors[seq_len(length(unique(average_curves$cluster)))]
  }
  names(cluster_colors) <- paste(
    "Cluster",
    levels(average_curves$cluster)
  )

  color_values <- c(cluster_colors)
  distinct_colors <- c()

  # Create the base plot
  p_curves <- ggplot2::ggplot(
    average_curves,
    ggplot2::aes(
      x = !!rlang::sym("Time"),
      y = !!rlang::sym("Value"),
      color = paste("Cluster", factor(!!rlang::sym("cluster")))
    )
  ) +
    ggplot2::geom_line() +
    ggplot2::ggtitle(sprintf("Average Splines by Cluster - %s", level)) +
    ggplot2::xlab(paste("Time", time_unit_label)) +
    ggplot2::ylab(paste("min-max norm.", plot_info$y_axis_label)) +
    ggplot2::theme_minimal() +
    ggplot2::theme(plot.title = ggplot2::element_text(hjust = 0.5))

  # Call the wrapper function to conditionally add dashed lines and get
  # treatment colors
  result <- maybe_add_dashed_lines(
    p = p_curves,
    plot_info = plot_info,
    level = level
  )

  p_curves <- result$p
  treatment_colors <- result$treatment_colors

  # Combine cluster colors and treatment colors for a single color scale
  all_colors <- c(cluster_colors, treatment_colors)

  # Finalize color scale and theme adjustments
  p_curves <- p_curves +
    ggplot2::scale_color_manual(
      values = all_colors, # Combine both cluster and treatment colors
      name = NULL # No legend title
    ) +
    ggplot2::theme(
      legend.key.size = grid::unit(0.6, "cm"),
      legend.key.height = grid::unit(0.3, "cm"),
      legend.title = ggplot2::element_text(size = 8)
    )

  return(p_curves)
}


#' Plot Consensus Shapes
#' 
#' @noRd
#'
#' @description
#' Generates composite plots of single and consensus shapes for each cluster
#' of curve values.
#'
#' @param curve_values A dataframe containing curve values and cluster
#'  assignments.
#' @param plot_info List containing the elements y_axis_label (string),
#'                  time_unit (string), treatment_labels (character vector),
#'                  treatment_timepoints (integer vector). All can also be NA.
#'                  This list is used to add this info to the spline plots.
#'                  time_unit is used to label the x-axis, and treatment_labels
#'                  and -timepoints are used to create vertical dashed lines,
#'                  indicating the positions of the treatments (such as
#'                  feeding, temperature shift, etc.).
#' @param level Unique value within the condition.
#' @param max_hit_number Maximum number of hits which are plotted within each
#' cluster. This can be used to limit the computation time and size of
#' the HTML report in the case of many hits.
#'
#' @return A list containing a plot for every cluster
#'
#' @seealso
#' \code{\link{plot_single_and_mean_splines}}
#'
plot_cluster_mean_splines <- function(
    curve_values,
    plot_info,
    level,
    max_hit_number
    ) {

  clusters <- sort(unique(curve_values$cluster))
  plots <- list()
  
  for (current_cluster in clusters) {
    subset_df <- subset(
      curve_values,
      curve_values$cluster == current_cluster
    )
    
    nr_of_hits <- nrow(subset_df)
    
    if (!is.infinite(max_hit_number)) {
      n_keep <- min(max_hit_number, nrow(subset_df))
      subset_df <- subset_df[seq_len(n_keep), , drop = FALSE]
    }
    
    subset_df$cluster <- NULL
    current_title <- paste(
      "Cluster",
      current_cluster,
      "| Hits:",
      nr_of_hits,
      "|",
      level,
      sep = " "
    )

    plots[[length(plots) + 1]] <-
      plot_single_and_mean_splines(
        subset_df,
        current_title,
        plot_info = plot_info,
        level
      )
  }
  return(plots)
}


#' Plot Splines for Features Based on Top Table Information
#' 
#' @noRd
#'
#' @description This function generates plots for each feature listed in the
#' top table using spline
#' interpolation for fitted values. It creates individual plots for each feature
#' and combines them into a single composite plot.
#'
#' @param top_table A dataframe containing the indices and names of features,
#' along with their
#'                  statistical metrics such as intercepts and spline
#'                  coefficients.
#' @param data A matrix or dataframe containing the raw data values for each
#' feature.
#' @param meta A dataframe containing metadata for the data, including time
#' points.
#' @param predicted_timecurves A list returned by [predict_timecurves()],
#'   containing:
#'   \describe{
#'     \item{`time_grid`}{A numeric vector of dense time points used for
#'       evaluation.}
#'     \item{`predictions`}{A named list of matrices, one per condition level.
#'       Each matrix contains predicted values (rows = features, columns =
#'       timepoints).}
#'   }
#' @param time_unit_label A string shown in the plots as the unit for the time,
#' such as min or hours.
#' @param plot_info List containing the elements y_axis_label (string),
#'                  time_unit (string), treatment_labels (character vector),
#'                  treatment_timepoints (integer vector). All can also be NA.
#'                  This list is used to add this info to the spline plots.
#'                  time_unit is used to label the x-axis, and treatment_labels
#'                  and -timepoints are used to create vertical dashed lines,
#'                  indicating the positions of the treatments (such as
#'                  feeding, temperature shift, etc.).
#' @param adj_pthreshold Double > 0 and < 1 specifying the adj. p-val threshold.
#' @param replicate_column String specifying the column of the meta dataframe
#' that contains the labels of the replicate measurents. When that is not
#' given, this argument is NULL.
#' @param level Unique value of the meta condition column, such as 'treatment' 
#' or 'control'.
#' @param raw_data Optional. Data matrix with the raw (unimputed) data, still 
#' containing NA values. When provided, it highlights the datapoints in the 
#' spline plots that originally where NA and that were imputed.
#' @param report_info A named list containing report information such as analyst
#'                    name, fixed and random effects, etc.
#'
#' @return A list containing the composite plot and the number of rows used in
#' the plot layout.
#'
#' @importFrom splines ns
#' @importFrom ggplot2 ggplot geom_point geom_line theme_minimal labs theme
#' scale_x_continuous annotate
#' @importFrom patchwork wrap_plots plot_annotation
#' @importFrom scales hue_pal
#' @importFrom rlang .data
#'
plot_splines <- function(
    top_table,
    data,
    meta,
    predicted_timecurves,
    time_unit_label,
    plot_info,
    adj_pthreshold,
    replicate_column,
    level,
    raw_data,
    report_info,
    max_hit_number
    ) {

  # Sort so that HTML reports are easier to read and comparisons are easier.
  top_table <- top_table |> dplyr::arrange(.data$feature_names)
  smooth_timepoints <- predicted_timecurves$time_grid
  pred_mat_level    <- predicted_timecurves$predictions[[level]]

  DoF <- which(names(top_table) == "AveExpr") - 1
  time_points <- meta[["Time"]]

  titles <- data.frame(
    FeatureID = top_table$feature_nr,
    feature_names = top_table$feature_names
  )
  
  shape_values <- c(     # 16 = circle, 17 = triangle
    "Measured" = 16,
    "Imputed" = 17
    ) 
  
  plot_list <- list()
  n_hits <- min(
    max_hit_number,
    nrow(top_table)
    )
  
  for (hit in seq_len(n_hits)) {
    hit_index <- as.numeric(top_table$feature_nr[hit])
    feature_name <- top_table$feature_names[hit]
    # cumulative travel (effect size) for this feature in this level
    cum_travel_val <- NA_real_
    es_vec <- predicted_timecurves$effect_size[[level]]
    if (!is.null(es_vec)) {
      tmp <- unname(es_vec[feature_name])
      if (length(tmp)) cum_travel_val <- tmp[1]
    }
    fitted_values <- as.numeric(
      pred_mat_level[feature_name, ]
    )
    y_values <- data[hit_index, ]

    homosc_result <- report_info[["homosc_violation_result"]][["bp_df"]]
    heteroscedasticity <- homosc_result$violation_flag[hit_index]
    high_var_group <- homosc_result$max_var_group[hit_index]

    plot_data <- data.frame(
      Time = time_points,
      Y = y_values
    )

    # Mark original NA values from raw_data if available
    if (!is.null(raw_data)) {
      # Identify NA positions and mark them as "Imputed" in `plot_data`
      na_indices <- which(is.na(raw_data[hit_index, ]))
      plot_data$IsNA <- "Measured"
      plot_data$IsNA[na_indices] <- "Imputed"
    } else {
      plot_data$IsNA <- "Measured"
    }

    # If replicate_column is specified (i.e., a string), use replicate info
    if (!is.null(replicate_column) && is.character(replicate_column)) {
      replicates <- meta[[replicate_column]] # Get the replicate information
      plot_data$Replicate <- replicates # Add replicate info to plot data

      # Create color palette for replicates
      replicate_colors <- scales::hue_pal()(length(unique(replicates)))
      names(replicate_colors) <- unique(replicates)

      color_values <- c(
        "Spline" = "red",
        replicate_colors
      )
    } else {
      color_values <- c(
        "Data" = "blue",
        "Spline" = "red"
      )
    }


    # Get adjusted p-value and significance stars
    adj_p_value <- as.numeric(top_table[hit, "adj.P.Val"])
    significance_stars <- ifelse(
      adj_p_value < adj_pthreshold / 500,
      "****",
      ifelse(
        adj_p_value < adj_pthreshold / 50,
        "***",
        ifelse(
          adj_p_value < adj_pthreshold / 5,
          "**",
          ifelse(
            adj_p_value < adj_pthreshold,
            "*",
            ""
          )
        )
      )
    )

    avg_cv <- calc_cv(
      time_values = time_points,
      response_values = y_values
    )

    # Use local environment to avoid unwanted updating dynamic legend label.
    p <- local({
      plot_spline <- data.frame(
        Time = smooth_timepoints,
        Fitted = fitted_values
      )

      x_min <- min(time_points)
      x_max <- max(time_points)
      x_extension <- (x_max - x_min) * 0.001  # Etxtension on each side

      # Define color column outside aes()
      color_column_values <- if (!is.null(replicate_column) &&
        is.character(replicate_column)) {
        plot_data$Replicate # Use replicate column if it exists
      } else {
        rep("Data", nrow(plot_data))
      }

      plot_data$color_column <- factor(color_column_values)
      
      y_max <- max(c(y_values, fitted_values), na.rm = TRUE)
      y_min <- min(c(y_values, fitted_values), na.rm = TRUE)
      y_extension <- (y_max - y_min) * 0.1

      p <- ggplot2::ggplot() +
        ggplot2::geom_point(
          data = dplyr::filter(plot_data, !is.na(Y)),
          ggplot2::aes(
            x = Time,
            y = Y,
            color = color_column,
            shape = factor(IsNA)  # Map shape to "Data" or "Imputed"
          ),
          alpha = 0.5 # 50% transparent data dots
        ) +
        ggplot2::geom_line(
          data = plot_spline,
          ggplot2::aes(
            x = .data$Time,
            y = .data$Fitted,
            color = "Spline"
          )
        ) +
        ggplot2::scale_shape_manual(values = shape_values) + 
        ggplot2::theme_minimal() +
        ggplot2::scale_x_continuous(
          limits = c(x_min - x_extension, x_max + x_extension), 
          breaks = filter_timepoints(time_points),
          labels = function(x) {
            x
          }
        ) +
        ggplot2::coord_cartesian(ylim = c(y_min, y_max + y_extension)) +
        ggplot2::labs(
          x = paste0("Time ", time_unit_label),
          y = plot_info$y_axis_label
        ) +
        ggplot2::guides(
          color = ggplot2::guide_legend(title = NULL),
          shape = if (any(plot_data$IsNA == "Imputed")) {
            ggplot2::guide_legend(title = NULL)
          } else {
            "none" # Completely remove shape legend when no "Imputed" points
          }
        ) +
        ggplot2::theme(
          legend.position = "right",
          legend.justification = "center",
          legend.box = "vertical",
          legend.background = ggplot2::element_blank(),
          legend.title = ggplot2::element_blank(),
          legend.text = ggplot2::element_text(
            size = 6,
            margin = ggplot2::margin(t = 4, b = 4)
          ),
          axis.text.x = ggplot2::element_text(
            size = 8,
            angle = 45, # Tilt labels by 45 degrees
            hjust = 1 # Adjust horizontal justification
          ),
          axis.title.y = ggplot2::element_text(
            size = 8,
            margin = ggplot2::margin(t = 0, r = 2, b = 0, l = 0)
          ),
          axis.text.y = ggplot2::element_text(
            margin = ggplot2::margin(t = 0, r = 5, b = 0, l = 0)
          )
        )
      
      y_pos_label <- y_max + y_extension * 0.5
      
      result <- maybe_add_dashed_lines(
        p = p,
        plot_info = plot_info,
        level = level,
        y_pos = y_pos_label,
        horizontal_labels = TRUE
      )

      p <- result$p # Updated plot with dashed lines
      treatment_colors <- result$treatment_colors # Colors used for treatments

      color_values <- c(
        color_values,
        treatment_colors
        )

      # Add title and annotations
      matched_row <- dplyr::filter(
        titles,
        !!rlang::sym("FeatureID") == hit_index
      )

      title <- as.character(matched_row$feature_name)

      if (isTRUE(heteroscedasticity)) {
        if (!is.na(high_var_group)) {
          title_prefix <- paste0("\u26A0 (", high_var_group, " \u2191) | ")
        } else {
          title_prefix <- "\u26A0\uFE0F "
        }
      } else {
        title_prefix <- ""
      }
      
      title <- paste0(
        title_prefix,
        title
      )

      if (nchar(title) > 100) {
        title_before <- title
        title <- paste0(substr(title, 1, 100), " ...")
        message(paste(
          "The feature ID", title_before, "is > 100 characters.",
          "Truncating it to 100 chars:", title
        ))
      }

      if (is.na(title)) {
        title <- paste("feature:", hit_index)
      }

      p <- p +
        ggplot2::scale_colour_manual(
          values = color_values,
        ) +
        ggplot2::theme_minimal() +
        ggplot2::labs(
          title = paste(
            "<b>", title, "</b>",
            "<br>",
            "Cumulative travel:",
            ifelse(is.na(cum_travel_val), "NA", signif(cum_travel_val, 3)),
            "  |  avg CV: ", round(avg_cv, 2), "%",
            "  |  adj. p-val: ", signif(adj_p_value, digits = 2),
            " ", significance_stars
          ),
          x = paste("Time", time_unit_label),
          y = paste(plot_info$y_axis_label)
        ) +
        ggplot2::theme(
          plot.title = ggplot2::element_text(size = 6),
          axis.title.x = ggplot2::element_text(size = 8),
          axis.title.y = ggplot2::element_text(size = 8),
          legend.key.size = grid::unit(0.6, "cm"),
          legend.key.height = grid::unit(0.3, "cm"),
          legend.title = ggplot2::element_text(size = 8),
          legend.text = ggplot2::element_text(size = 6),
          axis.text.x = ggplot2::element_text(size = 6)
        )

      p
    })

    plot_list[[hit]] <- p
  }

  return(plot_list)
}


#' Create spline comparison plots for two conditions
#' 
#' @noRd
#'
#' @description
#' This function generates comparison plots for spline fits of two conditions
#' over time. It compares the time effects of two conditions, plots the data
#' points, and overlays the fitted spline curves. The function checks if the
#' adjusted p-values for the average difference between conditions and the
#' interaction between condition and time are below the specified thresholds
#' before generating plots. (this function generates the double spline plots).
#'
#' @param time_effect_1 A data frame containing the time effects for the first
#'  condition.
#' @param condition_1 The name of the first condition.
#' @param time_effect_2 A data frame containing the time effects for the second
#'  condition.
#' @param condition_2 The name of the second condition.
#' @param avrg_diff_conditions A data frame with the adjusted p-values for the
#'  average difference
#' between conditions.
#' @param interaction_condition_time A data frame with the adjusted p-values
#'  for the interaction between
#' condition and time.
#' @param data The data matrix containing the measurements.
#' @param meta The metadata associated with the measurements.
#' @param condition Column name of meta that contains the levels of the
#' experiment.
#' @param replicate_column Column name of the meta column that specifies the
#' replicates per timepoint. For example Reactor with the unique values: 
#' 'ReactorE16', 'ReactorE17', ... which means that multiple bioreactors where
#' running this experiment and each timepoint has one sample from each reactor.
#' @param predicted_timecurves A list returned by [predict_timecurves()],
#'   containing:
#'   \describe{
#'     \item{`time_grid`}{A numeric vector of dense time points used for
#'       evaluation.}
#'     \item{`predictions`}{A named list of matrices, one per condition level.
#'       Each matrix contains predicted values (rows = features, columns =
#'       timepoints).}
#'   }
#' @param plot_info A list containing plotting information such as time unit
#' and axis labels.
#' @param adj_pthresh_avrg_diff_conditions The adjusted p-value threshold for
#' the average difference
#' between conditions.
#' @param adj_pthresh_interaction The adjusted p-value threshold for the
#' interaction between
#' condition and time.
#' @param raw_data Optional. Data matrix with the raw (unimputed) data, still 
#' containing NA values. When provided, it highlights the datapoints in the 
#' spline plots that originally where NA and that were imputed.
#' @param max_hit_number Maximum number of hits for which the individual spline
#' plots are shown. This can be used to limit the computation time and size of
#' the HTML report in the case of many hits.
#'
#' @return A list containing:
#' \describe{
#'   \item{plots}{A list of ggplot2 plots comparing the two conditions.}
#'   \item{feature_names}{A list of feature names for the plotted features.}
#' }
#'
#' @importFrom rlang .data
#'
plot_spline_comparisons <- function(
    time_effect_1,
    condition_1,
    time_effect_2,
    condition_2,
    avrg_diff_conditions,        
    interaction_condition_time,  
    data,
    meta,
    condition,
    replicate_column,
    predicted_timecurves,
    plot_info,
    adj_pthresh_avrg_diff_conditions, 
    adj_pthresh_interaction,          
    raw_data,
    max_hit_number
) {
  # optional replicate mapping
  if (!is.null(replicate_column)) {
    replicate_mapping <- setNames(
      seq_along(unique(meta[[replicate_column]])),
      unique(meta[[replicate_column]])
    )
  }
  
  # sort inputs for stable behavior
  time_effect_1 <- dplyr::arrange(time_effect_1, .data$feature_names)
  time_effect_2 <- dplyr::arrange(time_effect_2, .data$feature_names)
  avrg_diff_conditions <- dplyr::arrange(
    avrg_diff_conditions,
    .data$feature_names
    )
  interaction_condition_time <- dplyr::arrange(
    interaction_condition_time,
    .data$feature_names
    )
  
  smooth_timepoints <- predicted_timecurves$time_grid
  pred_mat_1 <- predicted_timecurves$predictions[[condition_1]]
  pred_mat_2 <- predicted_timecurves$predictions[[condition_2]]
  
  # meta/time and titles
  time_points <- meta$Time
  titles <- data.frame(
    FeatureID = time_effect_1$feature_nr,
    feature_names = time_effect_1$feature_names
  )
  
  features_to_plot <- dplyr::bind_rows(
    dplyr::select(avrg_diff_conditions, feature_nr, feature_names),
    dplyr::select(interaction_condition_time, feature_nr, feature_names)
  ) |>
    dplyr::distinct() |>
    dplyr::slice_head(n = max_hit_number)
  
  # (Optional) sanity check: ensure features exist in prediction matrices
  if (!is.null(rownames(pred_mat_1))) {
    features_to_plot <- features_to_plot[
      features_to_plot$feature_names %in% rownames(pred_mat_1) &
        features_to_plot$feature_names %in% rownames(pred_mat_2),
      , drop = FALSE]
  }
  
  plot_list <- list()
  feature_names_list <- list()
  
  # helper for stars (annotation only)
  stars_from <- function(pval, thresh) {
    if (is.na(pval)) return("")
    if (pval < thresh/500) "****"
    else if (pval < thresh/50) "***"
    else if (pval < thresh/5) "**"
    else if (pval < thresh) "*"
    else ""
  }
  
  # precompute shape mapping if replicates used
  if (!is.null(replicate_column)) {
    distinct_shapes <- c(21,22,23,24,25,3,4,8)
    fallback_shapes <- rep(1, 100)
    uniq_rep <- unique(meta[[replicate_column]])
    shape_mapping <- setNames(
      c(distinct_shapes, fallback_shapes)[seq_along(uniq_rep)],
      uniq_rep
    )
  }
  
  for (i in seq_len(nrow(features_to_plot))) {
    hit_index   <- as.numeric(features_to_plot$feature_nr[i])
    feature_name <- features_to_plot$feature_names[i]
    # Determine membership (feature is in which category table)
    is_cat2 <- feature_name %in% avrg_diff_conditions$feature_names
    is_cat3 <- feature_name %in% interaction_condition_time$feature_names
    
    # Category 2 effect size (from FIRST column of avrg_diff_conditions)
    cat2_eff <- NA_real_
    cat2_colname <- colnames(avrg_diff_conditions)[1]
    if (is_cat2) {
      row_cat2 <- avrg_diff_conditions[
        avrg_diff_conditions$feature_names == feature_name,
        ,
        drop = FALSE
        ]
      if (nrow(row_cat2) > 0) {
        cat2_eff <- as.numeric(row_cat2[[1]])  # first column = effect size
      }
    }
    
    # Category 3 effect sizes per condition
    es1 <- NA_real_
    es2 <- NA_real_
    if (is_cat3) {
      es_list <- predicted_timecurves$effect_size
      if (!is.null(es_list[[condition_1]])) {
        es1 <- unname(es_list[[condition_1]][feature_name])
      }
      if (!is.null(es_list[[condition_2]])) {
        es2 <- unname(es_list[[condition_2]][feature_name])
      }
    }
    
    row_values  <- data[hit_index, ]
    
    # imputation flags (by condition)
    if (!is.null(raw_data)) {
      columns_condition_1 <- which(meta[[condition]] == condition_1)
      columns_condition_2 <- which(meta[[condition]] == condition_2)
      na_indices_cond1 <- columns_condition_1[
        which(is.na(raw_data[hit_index, columns_condition_1]))
      ]
      na_indices_cond2 <- columns_condition_2[
        which(is.na(raw_data[hit_index, columns_condition_2]))
      ]
      plot_data <- data.frame(
        Time = time_points,
        Y1 = ifelse(meta[[condition]] == condition_1, row_values, NA),
        Y2 = ifelse(meta[[condition]] == condition_2, row_values, NA),
        IsImputed1 = ifelse(
          seq_along(row_values) %in% na_indices_cond1,
          "Imputed",
          "Measured"
          ),
        IsImputed2 = ifelse(
          seq_along(row_values) %in% na_indices_cond2,
          "Imputed",
          "Measured"
          )
      )
      has_imputed_1 <- any(plot_data$IsImputed1 == "Imputed")
      has_imputed_2 <- any(plot_data$IsImputed2 == "Imputed")
    } else {
      plot_data <- data.frame(
        Time = time_points,
        Y1 = ifelse(meta[[condition]] == condition_1, row_values, NA),
        Y2 = ifelse(meta[[condition]] == condition_2, row_values, NA),
        IsImputed1 = "Measured",
        IsImputed2 = "Measured"
      )
      has_imputed_1 <- FALSE
      has_imputed_2 <- FALSE
    }
    
    if (!is.null(replicate_column)) {
      plot_data$Replicate <- meta[[replicate_column]]
      plot_data$ReplicateLabel <- replicate_mapping[meta[[replicate_column]]]
    }
    
    fitted_values_1 <- as.numeric(pred_mat_1[feature_name, ])
    fitted_values_2 <- as.numeric(pred_mat_2[feature_name, ])
    
    # pull p-values for annotation (dfs are already filtered)
    avrg_diff_pval <- avrg_diff_conditions |>
      dplyr::filter(.data$feature_names == feature_name) |>
      dplyr::pull(adj.P.Val) |>
      (\(.) ifelse(length(.) == 0, NA_real_, .[1]))()
    
    interaction_pval <- interaction_condition_time |>
      dplyr::filter(.data$feature_names == feature_name) |>
      dplyr::pull(adj.P.Val) |>
      (\(.) ifelse(length(.) == 0, NA_real_, .[1]))()
    
    avrg_diff_stars   <- stars_from(
      avrg_diff_pval,
      adj_pthresh_avrg_diff_conditions
      )
    interaction_stars <- stars_from(
      interaction_pval,
      adj_pthresh_interaction
      )
    
    # average CV per condition
    cv_1 <- calc_cv(
      time_values = plot_data$Time,
      response_values = plot_data$Y1
      )
    cv_2 <- calc_cv(
      time_values = plot_data$Time,
      response_values = plot_data$Y2
      )
    
    plot_data$ColorLabel1 <- ifelse(plot_data$IsImputed1 == "Imputed",
                                    paste("Imputed data", condition_1),
                                    paste("Data", condition_1))
    plot_data$ColorLabel2 <- ifelse(plot_data$IsImputed2 == "Imputed",
                                    paste("Imputed data", condition_2),
                                    paste("Data", condition_2))
    
    p <- local({
      p <- ggplot2::ggplot() +
        ggplot2::geom_point(
          data = plot_data,
          ggplot2::aes(
            x = .data$Time, y = .data$Y1,
            color = .data$ColorLabel1,
            shape = if (!is.null(replicate_column)) .data$Replicate else NULL
          ),
          na.rm = TRUE, alpha = 0.5
        ) +
        ggplot2::geom_line(
          data = data.frame(
            Time = smooth_timepoints,
            Fitted = fitted_values_1
            ),
          ggplot2::aes(
            x = .data$Time, 
            y = .data$Fitted,
            color = paste("Spline", condition_1)
            )
        ) +
        ggplot2::geom_point(
          data = plot_data,
          ggplot2::aes(
            x = .data$Time, y = .data$Y2,
            color = .data$ColorLabel2,
            shape = if (!is.null(replicate_column)) .data$Replicate else NULL
          ),
          na.rm = TRUE, alpha = 0.5
        ) +
        ggplot2::geom_line(
          data = data.frame(
            Time = smooth_timepoints,
            Fitted = fitted_values_2
            ),
          ggplot2::aes(
            x = .data$Time,
            y = .data$Fitted,
            color = paste("Spline", condition_2)
            )
        ) +
        ggplot2::guides(
          color = ggplot2::guide_legend(title = NULL),
          shape = ggplot2::guide_legend(title = "Replicate")
        ) +
        ggplot2::scale_x_continuous(breaks = filter_timepoints(time_points)) 

      title_lines <- c(
        feature_name,
        paste(
          "adj.P.Val avrg_diff_conditions:",
          signif(avrg_diff_pval, 2),
          avrg_diff_stars
        ),
        paste(
          "adj.P.Val interaction_condition_time:",
          signif(interaction_pval, 2),
          interaction_stars
        )
      )
      
      # Append effect-size lines according to the category
      if (is_cat2 && !is.na(cat2_eff)) {
        title_lines <- c(
          title_lines,
          paste0("Avrg diff conditions: ", signif(cat2_eff, 3))
        )
      }
      if (is_cat3 && (!is.na(es1) || !is.na(es2))) {
        title_lines <- c(
          title_lines,
          paste0(
            "Cumulative travels: ",
            condition_1, "=", ifelse(is.na(es1), "NA", signif(es1, 3)),
            " | ",
            condition_2, "=", ifelse(is.na(es2), "NA", signif(es2, 3))
          )
        )
      }
      
      # CV line (kept as before)
      title_lines <- c(
        title_lines,
        paste0(
          "avg CV ", condition_1, ": ", round(cv_1, 2), "% | ",
          "avg CV ", condition_2, ": ", round(cv_2, 2), "%"
        )
      )
      
      p <- p + ggplot2::labs(
        title = paste(title_lines, collapse = "\n"),
        x = paste0("Time [", plot_info$time_unit, "]"),
        y = plot_info$y_axis_label
      )
        
      
      if (!is.null(replicate_column)) {
        p <- p + ggplot2::scale_shape_manual(
          values = shape_mapping,
          name = "Replicate"
          )
      }
      
      p <- p + ggplot2::theme_minimal() +
        ggplot2::theme(
          legend.position = "right",
          legend.title = ggplot2::element_blank(),
          plot.title = ggplot2::element_text(size = 7),
          legend.text = ggplot2::element_text(size = 5),
          legend.key.height = ggplot2::unit(0.3, "cm"),
          legend.key.width  = ggplot2::unit(0.7, "cm"),
          axis.title.x = ggplot2::element_text(size = 8),
          axis.title.y = ggplot2::element_text(size = 8),
          axis.text.x  = ggplot2::element_text(size = 6)
        )
      
      level <- paste(condition_1, condition_2, sep = "_")
      y_combined <- c(plot_data$Y1, plot_data$Y2)
      y_max <- max(y_combined, na.rm = TRUE)
      y_min <- min(y_combined, na.rm = TRUE)
      y_extension <- (y_max - y_min) * 0.1
      y_pos_label <- y_max + y_extension * 0.5
      
      result <- maybe_add_dashed_lines(
        p = p,
        plot_info = plot_info,
        level = level,
        y_pos = y_pos_label,
        horizontal_labels = TRUE
      )
      p <- result$p
      treatment_colors <- result$treatment_colors
      
      color_values <- setNames(
        c("orange","orange","purple","purple","red","dodgerblue"),
        c(paste("Data", condition_1),
          paste("Spline", condition_1),
          paste("Data", condition_2),
          paste("Spline", condition_2),
          paste("Imputed data", condition_1),
          paste("Imputed data", condition_2))
      )
      
      filtered_labels <- c(
        paste("Data", condition_1),
        paste("Spline", condition_1),
        paste("Data", condition_2),
        paste("Spline", condition_2)
      )
      if (has_imputed_1) filtered_labels <- c(
        filtered_labels,
        paste(
          "Imputed data",
          condition_1
          )
        )
      if (has_imputed_2) filtered_labels <- c(
        filtered_labels, 
        paste(
          "Imputed data", 
          condition_2
          )
        )
      
      color_values <- c(
        color_values[names(color_values) %in% filtered_labels],
        treatment_colors
        )
      p + ggplot2::scale_color_manual(values = color_values)
    })
    
    plot_list[[length(plot_list) + 1]] <- p
    feature_names_list[[length(feature_names_list) + 1]] <- feature_name
  }
  
  list(
    plots = plot_list,
    feature_names = feature_names_list
  )
}


#' Merge Annotation with All Top Tables
#' 
#' @noRd
#'
#' @description
#' This function merges annotation information into the `top_table` of each
#' non-logical element in a list.
#'
#' @param all_levels_clustering A list where each element contains a `top_table`
#' dataframe with a `feature_nr` column. Some elements may be logical values.
#' @param annotation A dataframe containing the annotation information.
#'
#' @return A list with updated `top_table` dataframes containing merged
#' annotation information.
#'
merge_annotation_all_levels_clustering <- function(
    all_levels_clustering,
    annotation = NULL) {
  all_levels_clustering <- lapply(
    all_levels_clustering,
    function(x) {
      # Check if x is not logical and annotation is not NULL
      if (!is.logical(x) && !is.null(annotation)) {
        x$top_table <- merge_top_table_with_annotation(
          x$top_table,
          annotation
        )
      }
      return(x)
    }
  )

  return(all_levels_clustering)
}


#' Prepare Gene Lists for Enrichr and Return as String
#' 
#' @noRd
#'
#' @description
#' This function processes the clustered hits in each element of
#' `all_levels_clustering`, formats the gene names for easy copy-pasting into
#' Enrichr, and returns the formatted gene lists as a string.
#'
#' @param all_levels_clustering A list where each element contains a dataframe
#' `clustered_hits` with columns `feature` and `cluster`.
#' @param genes A vector of gene names corresponding to the feature indices.
#'
#' @return A character vector with the formatted gene lists for each cluster.
#'
prepare_gene_lists_for_enrichr <- function(
    all_levels_clustering,
    genes) {
  formatted_gene_lists <- list()

  for (i in seq_along(all_levels_clustering)) {
    if (is.logical(all_levels_clustering[[i]])) next

    level_name <- names(all_levels_clustering)[i]
    clustered_hits <- all_levels_clustering[[i]]$clustered_hits

    # Process each cluster
    clusters <- split(
      clustered_hits$feature,
      clustered_hits$cluster
    )

    level_gene_lists <- list()

    for (cluster_id in names(clusters)) {
      cluster_genes <- clusters[[cluster_id]]

      gene_list <- genes[cluster_genes]
      gene_list <- na.omit(gene_list) # Remove NAs if any

      if (length(gene_list) > 0) {
        level_gene_lists[[paste0("Cluster ", cluster_id)]] <-
          paste(gene_list, collapse = "\n")
      }
    }

    formatted_gene_lists[[level_name]] <- level_gene_lists
  }

  # Prepare the background genes list using preprocessed genes
  background_gene_list <- paste(
    na.omit(genes),
    collapse = "\n"
  )

  return(list(
    gene_lists = formatted_gene_lists,
    background = background_gene_list
  ))
}


#' Build Cluster Hits Report
#' 
#' @noRd
#'
#' @description
#' Generates an HTML report for clustered hits, including plots and
#' spline parameter details, with a table of contents.
#'
#' @param header_section A character string containing the HTML header section.
#' @param plots A list of ggplot2 plot objects.
#' @param limma_result_2_and_3_plots List containing the list of lists with all
#' the plots for all the pairwise comparisons of the condition in terms of
#' average spline diff and interaction condition time, and another list of lists
#' where the respective names of each plot are stored.
#' @param plots_sizes A list of integers specifying the size of each plot.
#' @param level_headers_info A list of header information for each level.
#' @param spline_params A list of spline parameters.
#' @param adj_pthresholds Float vector with values for any level for adj.p.tresh
#' @param adj_pthresh_avrg_diff_conditions Float
#' @param adj_pthresh_interaction_condition_time Float
#' @param row_counts_dict A nested list containing row counts for dataframes 
#'   from `category_2_and_3_hits`. The outer keys are `"category_2"` and 
#'   `"category_3"`, representing the two sublists. The inner keys are derived 
#'   from the portion of each dataframe name after the second underscore (`_`), 
#'   or the full name if fewer than two underscores exist. The values are 
#'   integers representing the number of rows in each dataframe.
#' @param mode A character string specifying the mode
#'            ('isolated' or 'integrated').
#' @param report_info A named list containg the report info fields. Here used
#'                    for the email hotkey functionality.
#' @param output_file_path A character string specifying the path to save the
#'                         HTML report.
#'
#' @return No return value, called for side effects.
#'
#' @seealso
#' \code{\link{plot2base64}}, \code{\link{create_progress_bar}}
#'
build_cluster_hits_report <- function(
    header_section,
    plots,
    limma_result_2_and_3_plots,
    plots_sizes,
    level_headers_info,
    spline_params,
    adj_pthresholds,
    adj_pthresh_avrg_diff_conditions,
    adj_pthresh_interaction_condition_time,
    category_2_and_3_hit_counts,
    mode,
    report_info,
    output_file_path
    ) {
  
  html_content <- paste(header_section, "<!--TOC-->", sep = "\n")

  toc <- create_toc()

  styles <- define_html_styles()
  section_header_style <- styles$section_header_style
  toc_style <- styles$toc_style

  current_header_index <- 1
  j <- 0
  level_headers_info <- Filter(
    Negate(is.null),
    level_headers_info
    )

  pb <- create_progress_bar(plots)
  # pb$tick(0)          # show a 0-% bar immediately

  header_index <- 0
  level_index <- 0
  
  # Generate the sections and plots
  for (index in seq_along(plots)) {
    header_index <- header_index + 1

    if (current_header_index <= length(level_headers_info)) {
      header_info <- level_headers_info[[current_header_index]]
      nr_hits <- header_info$nr_hits
      adj_pvalue_threshold <- header_info$adj_pvalue_threshold

      # means this is the section of a new level
      # The very first level is also a new level
      if (names(plots)[index] == "new_level") {
        level_index <- level_index + 1

        time_effect_section_header <- paste(
          "Time Effect of Condition:",
          header_info$header_name
        )

        section_header <- sprintf(
          "<h2 style='%s' id='section%d'>%s</h2>",
          section_header_style,
          header_index,
          time_effect_section_header
        )

        html_content <- paste(
          html_content,
          section_header,
          sep = "\n"
        )

        if (mode == "integrated") {
          j <- 1
        } else { # mode == "isolated" or mode == NA
          j <- j + 1
        }

        spline_params_info <-
          get_spline_params_info(
            spline_params = spline_params,
            j = j
          )

        html_content <- paste(
          html_content,
          spline_params_info,
          sep = "\n"
        )

        hits_info <- sprintf(
          paste0(
            "<p style='text-align: center; font-size: 30px;'>",
            "adj.p-value threshold: %.4g</p>",
            "<p style='text-align: center; font-size: 30px;'>",
            "Number of hits: %d</p>",
            "<div style='text-align: center; font-size: 30px;'>%s</div>",
            "<hr>"
          ),
          adj_pvalue_threshold,
          nr_hits,
          generate_asterisks_definition(adj_pvalue_threshold)
        )

        html_content <- paste(
          html_content,
          hits_info,
          sep = "\n"
        )
        
        toc_entry <- sprintf(
          "<li style='%s'><a href='#section%d'>%s</a></li>",
          toc_style,
          header_index,
          time_effect_section_header
        )
        toc <- paste(
          toc,
          toc_entry,
          sep = "\n"
        )

        current_header_index <- current_header_index + 1

        pb$tick()
        next
      }
    }

    element_name <- names(plots)[index]

    header_levels <- c(
      "dendrogram",
      "cluster_mean_splines",
      "heatmap",
      "individual_spline_plots"
    )

    if (element_name %in% header_levels) {
      if (element_name == "dendrogram") {
        header_text <- "Overall Clustering"
      } else if (element_name == "cluster_mean_splines") {
        header_text <- "Min-max normalized individual and mean splines"
      } else if (element_name == "heatmap") {
        header_text <- "Z-Score of log2 Value Heatmap"
      
        heatmap_description <- paste(
          "<div style='text-align: center; font-size: 1.5em;'>",
          "Rows = features (labels on the right, cluster labels on the left),",
          "columns = timepoints; Blue = down, red = up, --> compared to the rest
          of the row;",
          "</div>"
        )
      } else { # element_name == "individual_spline_plots"
        adjusted_p_val <- adj_pthresholds[level_index]
        header_text <- "Individual Significant Features (Hits) Splines"
        asterisks_definition <- generate_asterisks_definition(adjusted_p_val)
      }

      # Add the main title as a section title with an anchor
      # before the first plot
      header <- paste0(
        "<h2 id='section",
        header_index,
        "' style='text-align: center; font-size: 3.5em;'>",
        header_text,
        "</h2>",
        if (exists("heatmap_description")) heatmap_description else ""
      )

      if (exists("heatmap_description")) rm(heatmap_description)

      # Add the asterisks definition if it exists
      if (exists("asterisks_definition")) {
        header <- paste0(
          header,
          "<div style='text-align: center;",
          "font-size: 1.5em;'>",
          asterisks_definition,
          "</div>"
        )

        rm(asterisks_definition) # Otherwise, the next level has it everywhere
      }

      html_content <- paste(
        html_content,
        header,
        sep = "\n"
      )

      toc_entry <- paste0(
        "<li style='margin-left: 30px; font-size: 30px;'>",
        "<a href='#section",
        header_index,
        "'>",
        header_text,
        "</a></li>"
      )

      toc <- paste(toc, toc_entry, sep = "\n")
    }

    header_index <- header_index + 1

    result <- process_plots(
      plots_element = plots[[index]],
      element_name = names(plots)[index],
      plots_size = plots_sizes[[index]],
      html_content = html_content,
      toc = toc,
      header_index = header_index
    )

    html_content <- result$html_content
    toc <- result$toc

    pb$tick()
  }
  pb$terminate()

  # Add sections for limma_result_2_and_3_plots
  if (length(limma_result_2_and_3_plots) > 0) {
    # Create a new main header for the limma result plots
    header_index <- header_index + 1

    # Add the main header and anchor it
    limma_main_header <- sprintf(
      "<h2 style='%s' id='section%d'>%s</h2>",
      section_header_style,
      header_index,
      "Avrg diff conditions & interaction condition time"
    )

    html_content <- paste(
      html_content,
      limma_main_header,
      sep = "\n"
    )

    # Define the asterisks definition for both adjusted p-values,
    # centered, with larger p-value text
    asterisks_definition_avrg_diff <- paste(
      "<div style='text-align:center; margin-bottom: 20px;'>",
      "<b><span style='font-size:24pt;
      '>Asterisks definition (Average Diff Conditions):</span></b><br>",
      paste(
        "<span style='font-size:18pt;'>Adj. p-value <",
        adj_pthresh_avrg_diff_conditions,
        "--> *</span>",
        sep = " "
      ),
      "<br>",
      paste(
        "<span style='font-size:18pt;'>Adj. p-value <",
        adj_pthresh_avrg_diff_conditions / 5,
        "--> **</span>",
        sep = " "
      ),
      "<br>",
      paste(
        "<span style='font-size:18pt;'>Adj. p-value <",
        adj_pthresh_avrg_diff_conditions / 50,
        "--> ***</span>",
        sep = " "
      ),
      "<br>",
      paste(
        "<span style='font-size:18pt;'>Adj. p-value <",
        adj_pthresh_avrg_diff_conditions / 500,
        "--> ****</span>",
        sep = " "
      ),
      "</div>",
      sep = "\n"
    )

    asterisks_definition_interaction <- paste(
      "<div style='text-align:center; margin-bottom: 40px;'>",
      "<b><span style='font-size:24pt;
      '>Asterisks definition (Interaction):</span></b><br>",
      paste(
        "<span style='font-size:18pt;'>Adj. p-value <",
        adj_pthresh_interaction_condition_time,
        "--> *</span>",
        sep = " "
      ),
      "<br>",
      paste(
        "<span style='font-size:18pt;'>Adj. p-value <",
        adj_pthresh_interaction_condition_time / 5,
        "--> **</span>",
        sep = " "
      ),
      "<br>",
      paste(
        "<span style='font-size:18pt;'>Adj. p-value <",
        adj_pthresh_interaction_condition_time / 50,
        "--> ***</span>",
        sep = " "
      ),
      "<br>",
      paste(
        "<span style='font-size:18pt;'>Adj. p-value <",
        adj_pthresh_interaction_condition_time / 500,
        "--> ****</span>",
        sep = " "
      ),
      "</div>",
      sep = "\n"
    )

    # Add the asterisks definitions to the HTML content
    html_content <- paste(
      html_content,
      asterisks_definition_avrg_diff,
      asterisks_definition_interaction,
      sep = "\n"
    )

    # Add an entry in the table of contents for this new section
    toc_entry <- sprintf(
      "<li style='%s'><a href='#section%d'>%s</a></li>",
      toc_style,
      header_index,
      "Avrg diff conditions & interaction condition time"
    )
    toc <- paste(
      toc,
      toc_entry,
      sep = "\n"
    )

    # We now assume limma_result_2_and_3_plots contains a single named element
    comparison_name <- names(limma_result_2_and_3_plots)[1]
    
    # Create a subheader for this single comparison
    header_index <- header_index + 1
    subheader <- sprintf(
      "<h3 style='font-size: 3.5em; color: #001F3F; text-align: center;'
      id='section%d'>%s</h3>",
      header_index,
      comparison_name
    )

    # Access row counts directly
    avrg_diff_hits <- category_2_and_3_hit_counts[["category_2"]]
    interaction_hits <- category_2_and_3_hit_counts[["category_3"]]
    
    # Create the HTML for hits
    hits_info <- sprintf(
      paste0(
        "<p style='font-size: 2em; text-align: center;'>",
        "Avrg diff conditions hits: %d</p>",
        "<p style='font-size: 2em; text-align: center;'>",
        "Interaction condition time hits: %d</p>",
        "<hr>"
      ),
      avrg_diff_hits,
      interaction_hits
    )
    
    html_content <- paste(
      html_content,
      subheader,
      hits_info,
      sep = "\n"
    )
    
    # Add an entry in the TOC
    toc_entry <- paste0(
      "<li style='margin-left: 30px; font-size: 30px;'>",
      "<a href='#section",
      header_index,
      "'>",
      comparison_name,
      "</a></li>"
    )
    
    toc <- paste(
      toc,
      toc_entry,
      sep = "\n"
    )
    
    # Extract plots + feature names
    comparison <- limma_result_2_and_3_plots[[comparison_name]]
    comparison_plots <- comparison$plots
    comparison_feature_names <- comparison$feature_names
    
    # Iterate through each plot and its feature name
    for (i in seq_along(comparison_plots)) {
      # Feature name above plot
      feature_name_div <- sprintf(
        '<div style="text-align: center;
    font-size: 36px; margin-bottom: 10px;">%s</div>',
        comparison_feature_names[[i]]
      )
      
      html_content <- paste(
        html_content,
        feature_name_div,
        sep = "\n"
      )
      
      # Insert plot
      result <- process_plots(
        plots_element = comparison_plots[[i]],
        plots_size = 1.5,
        html_content = html_content,
        toc = toc,
        header_index = header_index,
        element_name = ""
      )
      
      html_content <- result$html_content
      toc <- result$toc
    }
  }

  generate_and_write_html(
    toc = toc,
    html_content = html_content,
    report_info = report_info,
    output_file_path = output_file_path
  )
}


#' Adjust predicted spline curves to match empirical data intercepts
#'
#' @noRd
#'
#' @description
#' This function adjusts the intercept of predicted spline-based
#' timecourses so that they visually align with the actual data. It does
#' so by calculating the optimal constant offset (per feature) that
#' minimizes the squared difference between the predicted and observed
#' values, across all available samples for the specified condition level.
#'
#' In contrast to simple regression models, the linear models used in this
#' context (e.g., using `limma`) include not only spline terms but also
#' additional scientific covariates (e.g., batch effects, condition
#' indicators). These covariates influence the fitted intercept, meaning
#' the predicted curve does not necessarily pass through the "center of
#' mass" of the actual data. Instead, the model’s intercept serves as an
#' anchor for interpreting *effects*, not for minimizing residual error.
#'
#' Therefore, for the sake of visual clarity in plotting, this function
#' adjusts the entire predicted timecourse vertically—without altering its
#' shape—so that it better reflects the empirical data. This adjustment is
#' purely cosmetic and does not affect statistical inference. Only the
#' *shape* of the spline is tested in hypothesis testing; the intercept
#' shift is applied post hoc for visualization.
#'
#' @param pred_mat A numeric matrix of predicted values from the spline
#'   model. Rows are features, columns are timepoints (as in the prediction
#'   grid).
#' @param data A numeric matrix of observed data. Same feature × sample
#'   structure as used in model fitting.
#' @param meta A `data.frame` containing metadata for each sample (i.e.,
#'   column of `data`), including `Time` and the condition variable used to
#'   stratify the prediction.
#' @param condition A string giving the name of the condition column in
#'   `meta` (e.g., `"Phase"`).
#' @param level The condition level for which the predictions were
#'   generated (e.g., `"Stationary"`).
#' @param time_grid The numeric vector of time values used for spline
#'   prediction (i.e., the x-axis of `pred_mat`).
#'
#' @return A matrix of the same shape as `pred_mat`, where each row has
#'   been shifted by a constant so that the predicted curve better matches
#'   the empirical values under least-squares alignment.
#'   
adjust_intercept_least_squares <- function(
    pred_mat,
    data,
    meta, 
    condition,
    level,
    time_grid
) {

  # Match samples for this group
  sample_idx <- which(meta[[condition]] == level)
  
  if (length(sample_idx) == 0) {
    warning(
      "No samples found for level ",
      level,
      ". Skipping intercept adjustment."
    )
    return(pred_mat)
  }
  
  # Actual data matrix: features × group samples
  data_subset <- data[, sample_idx, drop = FALSE]
  # Subset data to match the rows in pred_mat
  common_rows <- intersect(rownames(pred_mat), rownames(data_subset))
  
  if (length(common_rows) != nrow(pred_mat)) {
    missing_rows <- setdiff(rownames(pred_mat), common_rows)
    stop_call_false(
      "The following features in pred_mat were not found in data_subset",
      "(condition '", 
      level,
      "'): ",
      paste(missing_rows, collapse = ", ")
    )
  }

  data_subset <- data_subset[common_rows, , drop = FALSE]
  
  pred_mat <- pred_mat[common_rows, , drop = FALSE]
  
  # Time values of samples
  sample_times <- meta$Time[sample_idx]
  
  # Match each sample time to nearest time grid index
  matched_indices <- vapply(
    sample_times,
    function(t) which.min(abs(t - time_grid)),
    integer(1)
  )

  # For each sample, extract the corresponding prediction column
  pred_mat_expanded <- pred_mat[, matched_indices, drop = FALSE]
  
  # Compute offset: empirical - predicted mean across matched samples
  offset <- rowMeans(data_subset - pred_mat_expanded, na.rm = TRUE)
  offset[is.na(offset)] <- 0  # fallback for all-NA rows
  
  # Apply offset to all predicted timepoints
  pred_mat <- pred_mat + offset
  
  return(pred_mat)
}


#' Safely convert object to tibble
#'
#' @noRd
#' 
#' @description
#' Safely convert an input object to a tibble. Handles `NULL`, data
#' frames, and lists of data frames by coercing them to tibbles and
#' binding them together. Any other input type returns an empty tibble.
#'
#' @param x An object to be converted to a tibble. Can be `NULL`,
#'   a data frame, or a list of data frames.
#'
#' @return A tibble. If `x` is `NULL`, returns an empty tibble. If `x`
#'   is a data frame, returns it as a tibble. If `x` is a list of data
#'   frames, returns them bound into a single tibble.
#'
#' @importFrom tibble as_tibble tibble
#' @importFrom dplyr bind_rows
#' 
stbl <- function(x) {
  
  if (is.null(x)) return(tibble())
  if (inherits(x, "data.frame")) return(as_tibble(x))
  if (is.list(x)) {
    xs <- lapply(x, function(y)
      if (inherits(y, "data.frame")) as_tibble(y) else tibble())
    return(bind_rows(xs))
  }
  tibble()
}


#' Normalize cluster dataframe
#'
#' @noRd
#' 
#' @description
#' Normalizes a cluster assignment data frame by standardizing column
#' names, ensuring one row per `feature_nr`, and adding a specified
#' output column for the cluster. Handles optional `gene` and feature
#' name information from row names. Non-data-frame inputs are first
#' converted using \code{stbl()}.
#'
#' @param df A data frame or object convertible by \code{stbl()}
#'   containing at least a `cluster` column, and optionally `feature`
#'   and `gene` columns. Row names may store feature names.
#' @param outcol A character scalar giving the name for the cluster
#'   column in the returned tibble.
#'
#' @return A tibble with columns:
#'   * `feature_nr` – numeric feature identifier.
#'   * `outcol` – cluster assignment as character.
#'   * `gcl` – optional gene from the input if present.
#'   * `fnsrc` – feature name source from row names.
#'
#' @importFrom tibble tibble
#' @importFrom dplyr filter group_by slice_head ungroup
#' 
ncl <- function(
    df,
    outcol
    ) {
  
  df <- stbl(df)
  if (nrow(df) == 0) {
    return(tibble(feature_nr = numeric(0),
                  !!outcol := NA_character_,
                  gcl = NA_character_,
                  fnsrc = NA_character_))
  }
  hf <- "feature" %in% names(df)
  rn <- rownames(df)
  fnsrc <- if (!is.null(rn)) rn else rep(NA_character_, nrow(df))
  feature_nr <- if (hf) df$feature else suppressWarnings(as.numeric(rn))
  tibble(feature_nr = feature_nr,
         !!outcol := as.character(df$cluster),
         gcl = if ("gene" %in% names(df))
           as.character(df$gene) else NA_character_,
         fnsrc = fnsrc) %>%
    filter(!is.na(feature_nr)) %>%
    group_by(feature_nr) %>%
    slice_head(n = 1) %>%
    ungroup()
}


#' Extract feature names from toptable
#'
#' @noRd
#' 
#' @description
#' Extracts `feature_nr` and corresponding feature names from a
#' toptable-like data frame. Accepts either `feature_names`,
#' `feature_name`, or falls back to converting `feature_nr` to a
#' character string. Input is first normalized with \code{stbl()}.
#'
#' @param df A toptable data frame or object convertible by
#'   \code{stbl()}, containing at least `feature_nr` and optionally
#'   `feature_names` or `feature_name`.
#'
#' @return A tibble with columns:
#'   * `feature_nr` – numeric feature identifier.
#'   * `fname_tbl` – character feature name from the table.
#'   Only non-missing, non-empty names are retained and the result
#'   contains distinct `feature_nr` entries.
#'
#' @importFrom tibble tibble
#' @importFrom dplyr filter distinct
#' 
toptbl_to_fn <- function(df) {
  
  df <- stbl(df)
  if (nrow(df) == 0) return(tibble())
  cols <- names(df)
  fn <- if ("feature_names" %in% cols) df[["feature_names"]]
  else if ("feature_name" %in% cols) df[["feature_name"]]
  else as.character(df[["feature_nr"]])
  tibble(feature_nr = df[["feature_nr"]],
         fname_tbl = as.character(fn)) %>%
    filter(!is.na(feature_nr), !is.na(fname_tbl), fname_tbl != "") %>%
    distinct(feature_nr, .keep_all = TRUE)
}


#' Make combined cluster labels for category hits
#'
#' @noRd
#' 
#' @description
#' Creates combined cluster labels by concatenating the values of two
#' specified cluster columns for features present in a given hit set.
#' For features not in the hit set, the combined cluster label is set
#' to `NA`.
#'
#' @param df A data frame containing at least `feature_nr` and the two
#'   cluster columns specified by \code{c1} and \code{c2}.
#' @param hits A data frame or tibble containing a column
#'   `feature_nr` that identifies the features to include in the
#'   combined cluster labeling.
#' @param c1 A character scalar giving the name of the first cluster
#'   column.
#' @param c2 A character scalar giving the name of the second cluster
#'   column.
#'
#' @return A tibble with columns:
#'   * `feature_nr` – numeric feature identifier.
#'   * `.cmb` – combined cluster label in the format
#'     `<cluster_c1>_<cluster_c2>` for hits, otherwise `NA`.
#'
#' @importFrom dplyr mutate select
#' @importFrom rlang sym
#' 
mkc <- function(
    df,
    hits,
    c1, 
    c2
    ) {
  
  df %>%
    mutate(.cmb = paste0(!!sym(c1), "_", !!sym(c2)),
           .cmb = ifelse(feature_nr %in% hits$feature_nr,
                         .cmb, NA_character_)) %>%
    select(feature_nr, .cmb)
}


#' Find a column name ignoring underscores
#'
#' @noRd
#'
#' @description
#' Returns the first column name in \code{df} that matches \code{target}
#' after removing underscores from both. Matching is **case-sensitive** and
#' only ignores underscores (no other characters are normalized).
#'
#' @param df A data frame (or tibble) whose column names are searched.
#' @param target Character scalar with the desired column name. Underscores
#'   in \code{target} are ignored for matching.
#'
#' @return A single character string with the matched column name from
#'   \code{df}, or \code{NA_character_} if no match is found.
#'
#' @details
#' This helper strips \code{"_"} from both the candidate column names and
#' \code{target} and compares them for equality. If multiple columns match,
#' the first is returned. Only underscores are ignored; other differences
#' (e.g., case, hyphens) are not.

find_col_ignore_underscores_rx <- function(df, target) {
  nn  <- names(df)
  key <- gsub("_", "", target)
  hit <- which(gsub("_", "", nn) == key)
  if (length(hit)) nn[hit[1]] else NA_character_
}


# Level 3 internal functions ---------------------------------------------------


#' Normalize Curve Values
#' 
#' @noRd
#'
#' @description This function normalizes each row in a data frame or matrix
#' of curve values.
#' Normalization is performed so that each row's values range from 0
#' (corresponding to the
#' minimum value of the row) to 1
#' (corresponding to the maximum value of the row).
#'
#' @param curve_values A data frame or matrix of curve values where each row
#' represents
#'        a curve and each column a time point.
#' @return A data frame or matrix with the same dimensions as the input, where
#'  each row
#'         has been normalized.
#'
normalize_curves <- function(curve_values) {
  normalized_curves <- apply(curve_values, 1, function(row) {
    (row - min(row)) / (max(row) - min(row))
  })

  normalized_curves <- t(normalized_curves)
  curve_values[, ] <- normalized_curves
  curve_values
}


#' K-means Clustering of Temporal Curves using MiniBatchKmeans
#' 
#' @noRd
#'
#' @description
#' Performs MiniBatch K-means clustering on smoothed time-series (curve) data.
#' Automatically selects the best number of clusters using the Bayesian 
#' Information Criterion (BIC).
#' Cluster assignments are added to the provided `top_table`, and the clustered
#'  data is returned.
#'
#' @param curve_values A numeric matrix of normalized time-series values 
#' (rows = features, cols = timepoints).
#' @param k_range Integer vector specifying the range of cluster numbers to 
#' evaluate (e.g., `2:8`).
#' @param smooth_timepoints Numeric vector of timepoints used as column names 
#' in the output.
#' @param top_table Data frame with column `feature_nr` indicating feature
#'  indices. Will be updated with cluster assignments.
#' @param condition_level Character string indicating the current condition 
#' level (used for error messages).
#'
#' @return A list with the following components:
#' \describe{
#'   \item{clustered_hits}{A data frame with `feature` and `cluster` 
#'   assignments.}
#'   \item{hc}{The MiniBatchKmeans object for the best `k`.}
#'   \item{curve_values}{The input matrix with a `cluster` column added.}
#'   \item{top_table}{The input `top_table`, updated with cluster assignments.}
#'   \item{clusters}{The best number of clusters (`k_best`) selected via BIC.}
#' }
#'
#' @importFrom ClusterR MiniBatchKmeans predict_KMeans
#' @importFrom pbapply pblapply
#' 
kmeans_clustering <- function(
    curve_values,
    k_range,
    smooth_timepoints,
    top_table,
    condition_level
    ) {

  if (nrow(curve_values) <= max(k_range)) {  # Clustering would fail
    stop_call_false(paste(
      "For condition_level '", condition_level, "':",
      "the number of requested clusters (", max(k_range), ")",
      "must be strictly less than",
      "the number of hits (", nrow(curve_values), ").",
      "Please choose fewer clusters to avoid failure during k-means."
    ))
  }

  if (length(k_range) == 1L && k_range[1L] == 1L) {
    # All series in one cluster, skip any computation
    k_best <- 1L
    cl     <- NULL
    cluster_assignments <- rep(1L, nrow(curve_values))
  } else {
    set.seed(42)
    n_obs <- nrow(curve_values)
    
    if (n_obs <= 1000) {    # Small dataset: use full k-means
      fits <- pbapply::pblapply(k_range, function(k) {
        stats::kmeans(
          curve_values,
          centers  = k,
          nstart   = 10,
          iter.max = 300
        )
      })
      
      tot_within <- vapply(
        fits,
        function(f)
          f$tot.withinss,
        numeric(1)
        )
      cluster_assignments_list <- lapply(fits, `[[`, "cluster")
      
    } else {     # Large dataset: use MiniBatchKmeans
      batch_size <- min(                 # never larger than the data
        n_obs,
        max(20L, 2L * max(k_range), floor(0.05 * n_obs))
      )
      
      fits <- pbapply::pblapply(k_range, function(k) {
        ClusterR::MiniBatchKmeans(
          data            = curve_values,
          clusters        = k,
          batch_size      = batch_size,
          num_init        = 10,
          max_iters       = 300,
          init_fraction   = 1.0,
          early_stop_iter = 10,
          tol             = 1e-4,
          verbose         = FALSE
        )
      })
      
      tot_within <- vapply(
        fits,
        function(f) sum(f$WCSS_per_cluster),
        numeric(1)
        )
      cluster_assignments_list <- lapply(
        fits,
        function(f) 
          ClusterR::predict_KMeans(
            curve_values,
            f$centroids
            )
        )
    }
    p <- ncol(curve_values)
    # Bayesian Information Criterion (BIC).
    bic <- n_obs * log(tot_within / n_obs) + k_range * log(n_obs) * p
    best_idx <- which.min(bic)
    
    k_best <- k_range[best_idx]
    cl <- fits[[best_idx]]
    cluster_assignments <- cluster_assignments_list[[best_idx]]
  }

  clustered_hits <- data.frame(
    feature = top_table$feature_nr,
    cluster = cluster_assignments
  )
  
  clustered_hits <- clustered_hits[, c("feature", "cluster")]
  
  colnames(curve_values) <- smooth_timepoints
  curve_values <- as.data.frame(curve_values)
  curve_values$cluster <- cluster_assignments
  
  top_table$cluster <- NA
  top_table$cluster[seq_len(nrow(clustered_hits))] <-
    as.integer(clustered_hits$cluster)

  group_clustering <- list(
    clustered_hits = clustered_hits,
    hc = cl,
    curve_values = curve_values,
    top_table = top_table,
    clusters = k_best
  )
}


#' Get Spline Parameters Info
#' 
#' @noRd
#'
#' @description
#' This function retrieves the spline parameters information for a given index.
#' It ensures the spline parameters are valid and constructs an HTML string
#' describing the spline parameters.
#'
#' @param spline_params A list containing the spline parameters. The list should
#'                      include elements: `spline_type`, `degree`, `dof`,
#'                      `knots`, and `bknots`.
#' @param j An integer specifying the index of the spline parameters to
#' retrieve.
#'
#' @details
#' The function checks if the spline parameters are not `NULL` and have a length
#' greater than or equal to the specified index `j`. If a parameter is
#' invalid or
#' missing, it sets the parameter to `NA`. It then constructs an HTML string
#' describing the spline parameters, including spline type, degree, degrees of
#' freedom (DoF), knots, and boundary knots.
#'
#' @return A character string containing HTML-formatted information about the
#'         spline parameters at the specified index.
#'
get_spline_params_info <- function(
    spline_params,
    j) {
  if (!is.null(spline_params$spline_type) &&
    length(spline_params$spline_type) >= j) {
    spline_params$spline_type[j] <- spline_params$spline_type[j]
  } else {
    spline_params$spline_type[j] <- NA
  }

  if (!is.null(spline_params$degree) &&
    length(spline_params$degree) >= j) {
    spline_params$degree[j] <- spline_params$degree[j]
  } else {
    spline_params$degree[j] <- NA
  }

  if (!is.null(spline_params$dof) &&
    length(spline_params$dof) >= j) {
    spline_params$dof[j] <- spline_params$dof[j]
  } else {
    spline_params$dof[j] <- NA
  }

  if (!is.null(spline_params$knots) &&
    length(spline_params$knots) >= j) {
    spline_params$knots[j] <- spline_params$knots[j]
  } else {
    spline_params$knots[j] <- NA
  }

  if (!is.null(spline_params$bknots) &&
    length(spline_params$bknots) >= j) {
    spline_params$bknots[j] <- spline_params$bknots[j]
  } else {
    spline_params$bknots[j] <- NA
  }

  if (spline_params$spline_type[j] == "b") {
    spline_params_info <- sprintf(
      "
    <p style='text-align: center; font-size: 30px;'>
        <span style='color: blue;'>Spline-type:</span> B-spline<br>
        <span style='color: blue;'>Degree:</span> %s<br>
        <span style='color: blue;'>DoF:</span> %s<br>
        <span style='color: blue;'>Knots:</span> %s<br>
        <span style='color: blue;'>Boundary-knots:</span> %s
    </p>",
      spline_params$degree[j], spline_params$dof[j],
      spline_params$knots[j], spline_params$bknots[j]
    )
  } else { # spline_type == "n"
    spline_params_info <- sprintf(
      "
    <p style='text-align: center; font-size: 30px;'>
        <span style='color: blue;'>Spline-type:</span> Natural cubic spline<br>
        <span style='color: blue;'>DoF:</span> %s<br>
        <span style='color: blue;'>Knots:</span> %s<br>
        <span style='color: blue;'>Boundary-knots:</span> %s
    </p>",
      spline_params$dof[j], spline_params$knots[j],
      spline_params$bknots[j]
    )
  }
  return(spline_params_info)
}


#' Truncate Row Names
#' 
#' @noRd
#'
#' @description
#' This function truncates row names that exceed a specified maximum length.
#' If the row name length exceeds the maximum length, it appends " ..."
#' to indicate truncation.
#'
#' @param names A character vector of row names.
#' @param max_length An integer specifying the maximum length of the row names.
#' Default is 40.
#'
#' @return A character vector of truncated row names.
#'
truncate_row_names <- function(
    names,
    max_length = 40) {
  vapply(names, function(x) {
    if (nchar(x) > max_length) {
      return(paste0(substr(x, 1, max_length - 3), " ..."))
    } else {
      return(x)
    }
  }, character(1))
}


#' Filter Time Points Based on Minimum Spacing
#' 
#' @noRd
#'
#' @description
#' The `filter_timepoints()` function filters a sequence of time points by 
#' ensuring that the retained points are spaced by at least a certain 
#' percentage of the maximum time point. This is useful for simplifying 
#' time series data or reducing labels for visualization.
#'
#' @param time_points A numeric vector of time points to filter.
#' @param percentage_threshold A numeric value specifying the minimum spacing 
#'   between consecutive time points, expressed as a percentage of the 
#'   maximum time point. Default is `0.05` (5% of the maximum time point).
#'
#' @details
#' The function calculates the minimum spacing as a percentage of the 
#' maximum time point. It then iterates through the sorted sequence of 
#' time points and retains only those that meet the spacing criteria. 
#' This ensures that retained time points are sufficiently far apart 
#' for downstream applications such as visualization or analysis.
#'
#' @return
#' A numeric vector of filtered time points that satisfy the minimum 
#' spacing requirement.
#'
filter_timepoints <- function(
    time_points,
    percentage_threshold = 0.05) {
  x_max <- as.numeric(max(time_points))

  # Calculate the minimum spacing based on the threshold
  min_spacing <- x_max * percentage_threshold

  all_time_points <- unique(c(time_points))

  # Calculate the differences between consecutive time points
  time_diffs <- diff(all_time_points)

  # Keep labels that are more than the minimum spacing apart
  keep_labels <- c(TRUE, time_diffs > min_spacing)
  filtered_time_points <- all_time_points[keep_labels]

  return(filtered_time_points)
}


#' Calculate average CV across unique time points
#' 
#' @noRd
#'
#' @description
#' This function calculates the coefficient of variation (CV) for each unique
#' time point based on the provided time values and response values. It then
#' returns the average CV across all time points. The CV is only calculated if
#' there are more than one valid (non-NA) values for a given time point and
#' the mean of the values is non-zero.
#'
#' @param time_values A numeric vector containing the time points. Time points
#' may repeat across replicates.
#' @param response_values A numeric vector of response values corresponding to
#' the time points.
#'
#' @return The average coefficient of variation (CV) across all time points.
#' Returns NA if all CVs are NA.
#'
calc_cv <- function(
    time_values,
    response_values) {
  time_data <- data.frame(
    Time = time_values,
    Response = response_values
  )

  unique_times <- unique(time_data$Time)

  cvs <- vapply(
    unique_times,
    function(t) {
      # Subset for the specific time point
      values_at_time <- time_data$Response[time_data$Time == t]
      # Calculate CV if the mean is not zero and there are enough data points
      if (mean(values_at_time, na.rm = TRUE) != 0 &&
        sum(!is.na(values_at_time)) > 1) {
        (sd(
          values_at_time,
          na.rm = TRUE
        ) /
          mean(
            values_at_time,
            na.rm = TRUE
          )) * 100
      } else {
        NA # Return NA for CV when mean is 0 or insufficient data points
      }
    },
    numeric(1)
  )
  # Return the average CV across time points
  return(mean(
    cvs,
    na.rm = TRUE
  ))
}


#' Plot Single and Mean Splines
#' 
#' @noRd
#'
#' @description
#' Generates a plot showing individual time series shapes and their consensus
#' (mean) shape.
#'
#' @param time_series_data A dataframe or matrix with time series data.
#' @param title A character string specifying the title of the plot.
#' @param plot_info List containing the elements y_axis_label (string),
#'                  time_unit (string), treatment_labels (character vector),
#'                  treatment_timepoints (integer vector). All can also be NA.
#'                  This list is used to add this info to the spline plots.
#'                  time_unit is used to label the x-axis, and treatment_labels
#'                  and -timepoints are used to create vertical dashed lines,
#'                  indicating the positions of the treatments (such as
#'                  feeding, temperature shift, etc.).
#'
#' @return A ggplot object representing the single and consensus shapes.
#'
#' @seealso
#' \code{\link{ggplot2}}
#'
#' @importFrom dplyr arrange mutate
#' @importFrom tibble rownames_to_column
#' @importFrom tidyr pivot_longer
#' @importFrom ggplot2 ggplot geom_line scale_colour_manual theme_minimal
#'                     ggtitle aes labs element_rect
#' @importFrom rlang sym .data
#' @importFrom scales hue_pal
#'
plot_single_and_mean_splines <- function(
    time_series_data,
    title,
    plot_info,
    level
    ) {
  
  time_col <- rlang::sym("time")
  feature_col <- rlang::sym("feature")

  # Convert data to long format
  df_long <- as.data.frame(t(time_series_data)) |>
    tibble::rownames_to_column(var = "time") |>
    tidyr::pivot_longer(
      cols = -!!time_col,
      names_to = "feature",
      values_to = "intensity"
    ) |>
    dplyr::arrange(!!feature_col) |>
    dplyr::mutate(time = as.numeric(.data$time))

  # Compute consensus (mean of each column)
  consensus <- colMeans(time_series_data, na.rm = TRUE)

  consensus_df <- data.frame(
    time = as.numeric(colnames(time_series_data)),
    consensus = consensus
  )

  time_unit_label <- paste0("[", plot_info$time_unit, "]")

  color_values <- c(
    "Mean" = "darkblue",
    "Spline" = "#6495ED"
  )

  p <- ggplot2::ggplot() +
    ggplot2::geom_line(
      data = df_long,
      ggplot2::aes(
        x = !!rlang::sym("time"),
        y = !!rlang::sym("intensity"),
        group = !!rlang::sym("feature"),
        colour = "Spline"
      ),
      alpha = 0.3, linewidth = 0.5
    ) +
    ggplot2::geom_line(
      data = consensus_df,
      ggplot2::aes(
        x = !!rlang::sym("time"),
        y = consensus,
        colour = "Mean"
      ),
      linewidth = 1.5
    )

  treatment_labels <- NA

  result <- maybe_add_dashed_lines(
    p = p,
    plot_info = plot_info,
    level = level
  )

  p <- result$p
  treatment_colors <- result$treatment_colors

  # Combine the original colors with the treatment colors
  color_values <- c(color_values, treatment_colors)

  # Add the final scale for colors and adjust legend
  p <- p +
    ggplot2::scale_colour_manual(
      name = "",
      values = color_values,
      guide = ggplot2::guide_legend(
        override.aes = list(
          size = c(
            1.5, # First line's size
            0.5, # Second line's size
            rep(0.5, length(na.omit(treatment_colors))) # Treatment line sizes
          )
        )
      )
    ) +
    ggplot2::coord_cartesian(clip = "off") +
    ggplot2::theme_minimal() +
    ggplot2::labs(
      title = title,
      x = paste("Time", time_unit_label),
      y = paste("min-max norm.", plot_info$y_axis_label)
    ) +
    ggplot2::theme(
      plot.margin = grid::unit(c(1, 1, 1.5, 1), "lines"),
      legend.position = "right",
      legend.box = "vertical",
      legend.title = ggplot2::element_text(size = 8),
      legend.background = ggplot2::element_blank(),
      axis.title.y = ggplot2::element_text(size = 6),
      plot.title = ggplot2::element_text(hjust = 0.5),
      legend.key.size = grid::unit(0.6, "cm"),
      legend.key.height = grid::unit(0.3, "cm")
    )

  return(p)
}


#' Conditionally add dashed lines for treatment timepoints
#' 
#' @noRd
#'
#' @description
#' This internal function checks whether there are valid treatment
#' timepoints and labels in the `plot_info` list. If found, it adds
#' dashed vertical lines and their corresponding x-axis values to the plot.
#' The treatment timepoints and labels can either be named lists (for
#' multiple levels) or unnamed single elements.
#'
#' @param p A ggplot object. The plot to which dashed lines and labels
#' will be added.
#' @param plot_info A list containing the treatment timepoints and
#' treatment labels. Treatment timepoints and labels can either be
#' unnamed elements or named lists where each element corresponds
#' to a different `level`.
#' @param level A character string. Used to extract the treatment
#' timepoints and labels when they are stored in named lists.
#' @param y_pos A numeric value specifying the y-axis position where
#' the text labels should be placed. Defaults to 1.
#' @param horizontal_labels Boolean flag indicating whether to have a vertical
#' label (default) or horizontal label.
#'
#' @return A list containing:
#' - `p`: The ggplot object with possibly added dashed lines and labels.
#' - `treatment_colors`: A named vector of colors used for the treatment labels.
#'
#' @importFrom scales hue_pal
#'
maybe_add_dashed_lines <- function(
    p,
    plot_info,
    level,
    y_pos = 1,
    horizontal_labels = FALSE
    ) {

  # Initialize an empty vector to store treatment colors
  treatment_colors <- c()

  # Check if there are treatment labels
  if (!all(is.na(plot_info$treatment_labels))) {
    # Initialize variables to store treatment_timepoints and treatment_labels
    treatment_timepoints <- NULL
    treatment_labels <- NULL

    # Case when there is a single unnamed element in the lists
    if (is.null(names(plot_info$treatment_labels))) {
      # Take the single unnamed element
      treatment_timepoints <- plot_info$treatment_timepoints[[1]]
      treatment_labels <- plot_info$treatment_labels[[1]]
    } else {
      # Check if the key (level) is in the named lists
      if (level %in% names(plot_info$treatment_labels) &&
        level %in% names(plot_info$treatment_timepoints)) {
        # Extract the corresponding named elements
        treatment_timepoints <- plot_info$treatment_timepoints[[level]]
        treatment_labels <- plot_info$treatment_labels[[level]]
      }
    }

    # If we have valid treatment_timepoints and treatment_labels, 
    # add the dashed lines
    if (!is.null(treatment_timepoints) &&
      !is.null(treatment_labels) &&
      all(!is.na(treatment_timepoints)) &&
      all(!is.na(treatment_labels))) {
      # Generate colors for the treatment labels
      treatment_colors <- scales::hue_pal()(length(treatment_labels))
      names(treatment_colors) <- treatment_labels

      # Call the function to add dashed lines
      p <- add_dashed_lines(
        p = p,
        treatment_timepoints = treatment_timepoints,
        treatment_labels = treatment_labels,
        y_pos = y_pos,
        horizontal_labels = horizontal_labels
      )
    }
  }

  # Return both the updated plot and the treatment colors
  return(list(
    p = p,
    treatment_colors = treatment_colors
  ))
}


#' Generate Asterisks Definition HTML
#'
#' @noRd
#'
#' @description
#' This function generates an HTML string that defines the asterisk notation
#' based on the adjusted p-value threshold.
#'
#' @param adj_pvalue_threshold Numeric. The adjusted p-value threshold.
#'
#' @return A character string containing the HTML definition for the asterisks.
#'
#' @examples
#' generate_asterisks_definition(0.05)
#' # Returns an HTML string for the asterisk definitions.
generate_asterisks_definition <- function(adj_pvalue_threshold) {
  paste(
    "<b><span style='font-size:20pt; margin-bottom: 0;'>",
    "Asterisks definition:</span></b>",
    paste("Adj. p-value <", adj_pvalue_threshold, "--> *", sep = " "),
    paste("Adj. p-value <", adj_pvalue_threshold / 5, "--> **", sep = " "),
    paste("Adj. p-value <", adj_pvalue_threshold / 50, "--> ***", sep = " "),
    paste("Adj. p-value <", adj_pvalue_threshold / 500, "--> ****", sep = " "),
    sep = "<br>"
  )
}


#' Preselect features for plotting based on significance
#' 
#' @noRd
#'
#' @param avrg_diff_conditions Data frame with columns `feature_names`,
#'   `feature_nr`, and `adj.P.Val` for the average difference condition.
#'
#' @param interaction_condition_time Data frame with columns `feature_names`,
#'   `feature_nr`, and `adj.P.Val` for the interaction condition-time.
#'
#' @param max_hit_number Maximum number of features to select for each category.
#'
#' @param adj_pthresh_avrg_diff_conditions Adjusted p-value threshold for the
#'   average difference condition.
#'
#' @param adj_pthresh_interaction Adjusted p-value threshold for the
#'   interaction condition-time.
#'
#' @return A data frame with columns `feature_names` and `feature_nr`,
#'   containing the union of selected features from both categories.
#' 
preselect_features_for_plotting <- function(
    avrg_diff_conditions,
    interaction_condition_time,
    max_hit_number,
    adj_pthresh_avrg_diff_conditions,
    adj_pthresh_interaction
) {
  
  # Select top features for average difference
  sig_avg <- avrg_diff_conditions |>
    dplyr::filter(.data$adj.P.Val < adj_pthresh_avrg_diff_conditions) |>
    dplyr::arrange(.data$adj.P.Val) |>
    head(max_hit_number) |>
    dplyr::mutate(selected_avg = TRUE) |>
    dplyr::select(feature_names, feature_nr, selected_avg)
  
  # Select top features for interaction
  sig_interaction <- interaction_condition_time |>
    dplyr::filter(.data$adj.P.Val < adj_pthresh_interaction) |>
    dplyr::arrange(.data$adj.P.Val) |>
    head(max_hit_number) |>
    dplyr::mutate(selected_interaction = TRUE) |>
    dplyr::select(feature_names, feature_nr, selected_interaction)
  
  # Full outer join by feature_names and feature_nr
  features_to_plot <- dplyr::full_join(
    sig_avg,
    sig_interaction,
    by = c("feature_names", "feature_nr")
  )
  
  # Fix NA columns after join
  features_to_plot <- features_to_plot |>
    dplyr::mutate(
      selected_avg = tidyr::replace_na(.data$selected_avg, FALSE),
      selected_interaction = tidyr::replace_na(
        .data$selected_interaction,
        FALSE
        )
    )
  
  return(features_to_plot)
}


# Level 4 internal functions ---------------------------------------------------


#' Add dashed lines for treatment timepoints to a plot
#' 
#' @noRd
#'
#' @description
#' This internal function adds dashed vertical lines at specified
#' treatment timepoints to a plot, along with text labels that
#' display the corresponding x-axis values.
#'
#' @param p A ggplot object. The plot to which dashed lines and labels
#' will be added.
#' @param treatment_timepoints A numeric vector of timepoints where
#' dashed lines should be drawn.
#' @param treatment_labels A character vector of labels corresponding
#' to each treatment timepoint. These labels are used for coloring
#' the lines, but the x-axis coordinates are displayed as the labels.
#' @param y_pos A numeric value specifying the y-axis position where
#' the text labels should be placed.
#' @param horizontal_labels Boolean flag indicating whether to have a vertical
#' label (default) or horizontal label.
#'
#' @return A ggplot object with added dashed lines and labels.
#'
#' @importFrom ggplot2 geom_vline geom_text aes
#' @importFrom scales hue_pal
#'
add_dashed_lines <- function(
    p,
    treatment_timepoints,
    treatment_labels,
    y_pos = 1,
    horizontal_labels = FALSE
    ) {
  
  # Check if treatment labels and timepoints are valid
  if (!is.null(treatment_timepoints) &&
    !is.null(treatment_labels) &&
    all(!is.na(treatment_timepoints)) &&
    all(!is.na(treatment_labels))) {
    # Create a data frame for the treatment lines
    treatment_df <- data.frame(
      Time = treatment_timepoints,
      Label = treatment_labels,
      y_pos = y_pos
    )

    # Generate distinct colors for the treatment labels
    treatment_colors <- scales::hue_pal()(length(treatment_labels))
    names(treatment_colors) <- treatment_labels

    # Add dashed vertical lines and text labels to the plot
    p <- p +
      ggplot2::geom_vline(
        data = treatment_df,
        ggplot2::aes(
          xintercept = .data$Time,
          color = .data$Label
        ),
        linetype = "dashed",
        linewidth = 0.5
      ) +
      ggplot2::geom_text(
        data = treatment_df,
        ggplot2::aes(
          x = 
            if (horizontal_labels) Time + max(treatment_timepoints) * 0.04 
            else Time - max(treatment_timepoints) * 0.005, 
          y = .data$y_pos,
          label = round(Time, 2),
          color = Label
        ),
        angle = if (horizontal_labels) 0 else 90,  
        vjust = if (horizontal_labels) -0.2 else 0,  
        hjust = if (horizontal_labels) 0.5 else 1,  
        size = 3, # Text size
        show.legend = FALSE # Prevent text labels from appearing in the legend
      )
  }

  return(p) # Return the updated plot object
}