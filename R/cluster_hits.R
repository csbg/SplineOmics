#' Cluster the significant features based on spline similarity
#'
#' Performs kmeans clustering of significant features from top tables
#' generated by limma.
#'
#' @param splineomics `SplineOmics`: An S3 object of class `SplineOmics` that 
#' contains all the necessary data and parameters for the analysis, including:
#' \itemize{
#'   \item \code{data}: `matrix` The data matrix with the values. The columns 
#'   are the samples (timepoint + replicate combo) and the rows are the
#'    features (e.g. genes or proteins).
#'   \item \code{meta}: `data.frame` A dataframe containing metadata 
#'   corresponding to the \code{data}, must include a 'Time' column and any 
#'   columns specified by \code{conditions}. In general, the columns of meta 
#'   correspond to the different types of metadata, and each row corresponds to 
#'   a column of data (contains the metadata for that sample).
#'   \item \code{annotation}: `data.frame` A dataframe that maps the rows of 
#'   \code{data} to annotation info, such as the gene name or database 
#'   identifiers.
#'   \item \code{report_info}: `list` A named list describing the experiment. 
#'   Must include the following fields (`character(1)`):
#'     - \code{"omics_data_type"}
#'     - \code{"data_description"}
#'     - \code{"data_collection_date"}
#'     - \code{"analyst_name"}
#'     - \code{"contact_info"}
#'     - \code{"project_name"}
#'
#'   May also include the following optional fields (`character(1)`):
#'     - \code{"method_description"}
#'     - \code{"results_summary"}
#'     - \code{"conclusions"}
#'   \item \code{design}: `character(1)` A character of length 1 representing 
#'   the limma design formula.
#'   \item \code{mode}: `character(1)` Specifies how the design formula is 
#'   constructed: either `"isolated"` or `"integrated"`.
#'
#'   - `"isolated"`: Each level is analyzed independently, using only the 
#'     subset of data corresponding to that level. The design formula does not 
#'     include the condition variable, since only one condition is present in 
#'     each subset.
#'
#'   - `"integrated"`: All levels are analyzed together in a single model, 
#'     using the full dataset. The design formula includes the condition 
#'     variable (and optionally interaction terms with it) so that results are 
#'     estimated jointly across all levels.
#'   \item \code{condition}: `character(1)` Character vector of length 1 
#'   specifying the column name in \code{meta} used to define groups for 
#'   analysis.
#'   \item \code{spline_params}: `list` A list of spline parameters for the 
#'   analysis.
#'   \item \code{meta_batch_column}: `character(1)` A character string 
#'   specifying the column name in the metadata used for batch effect removal.
#'   \item \code{meta_batch2_column}: `character(1)` A character string 
#'   specifying the second column name in the metadata used for batch effect 
#'   removal.
#'   \item \code{limma_splines_result}: `list(data.frame)` and 
#'   `list(list(data.frame))` A list containing dataframes or lists of 
#'   dataframes. Each df represents a top table from the limma spline analysis
#'   of the run_limma_splines() function that has to be run before. 
#'   \item \code{feature_name_columns}: `character()` Character vector of 
#'   strings that each specify a column of the original data dataframe which 
#'   were used to automatically build the feature names with the 
#'   \code{extract_data} function.
#' }
#'
#' @param nr_clusters `list`: Named list specifying the number of clusters per 
#'   condition level. The list must have one element per condition level, and 
#'   each element must be named exactly with the corresponding condition name 
#'   (e.g., \code{"condition1"}, \code{"condition2"}).
#'
#'   Each element's value controls the \code{k} used by k-means for that level:
#'
#'   - \strong{Single integer} (`integer(1)`, \code{k > 0}, e.g. \code{3}): use 
#'     exactly that many clusters.
#'   - \strong{Integer range} (`integer()`, written with \code{:}, 
#'     e.g. \code{2:6}): choose the \code{k} within the range that 
#'     \strong{minimizes the Bayesian Information Criterion (BIC)} computed 
#'     from the k-means fit over that range (lower is better). Ties are broken 
#'     by the first minimum encountered.
#'
#'   \strong{Notes}
#'   \itemize{
#'     \item All condition levels must be present exactly once as names.
#'     \item Values must be positive integers; ranges must be increasing 
#'           (e.g. \code{2:6}).
#'     \item BIC is computed from k-means using Euclidean distance. A common 
#'           form is \eqn{\mathrm{BIC} = n \log(\mathrm{WCSS}/n) + k \log(n)\, 
#'           p}, where \eqn{n} is the number of series, \eqn{p} the number of 
#'           timepoints (features), and \eqn{\mathrm{WCSS}} the total 
#'           within-cluster sum of squares for the fit.
#'     \item Clustering will fail if the requested \code{k} is not strictly 
#'           less than the number of available series for that level.
#'   }
#'
#'   \strong{Example}
#'   Fixed k for condition1, BIC-selected k for condition2
#'   nr_clusters <- list(
#'     condition1 = 4,
#'     condition2 = 2:6
#'   )
#'
#' @param adj_pthresh_time_effect `numeric(1)`: adj. p-value threshold
#' for the limma time effect results (category 1).
#'
#' @param adj_pthresh_avrg_diff_conditions `numeric(1)`: adj. p-value threshold
#' for the limma average difference between conditions results (category 2).
#'
#' @param adj_pthresh_interaction_condition_time `numeric(1)`: adj. p-value 
#' threshold for the limma interaction of condition and time results
#' (category 3).
#'
#' @param min_effect_size `list`: A named list that specifies the minimum 
#' effect size thresholds to consider a feature as biologically meaningful, in 
#' addition to statistical significance. This allows users to filter out 
#' "trivial" hits that pass adjusted p-value cutoffs but show negligible effect 
#' sizes.
#'
#'   The list must contain the following elements:
#'   - `time_effect`: `numeric(1)` Minimum cumulative travel for time effects 
#'     (Category 1). Features with a smaller travel will be ignored even if 
#'     significant.
#'   - `avg_diff_cond`: `numeric(1)` Minimum absolute effect size for average 
#'     differences between conditions (Category 2). Ensures that only contrasts 
#'     with a relevant magnitude are reported.
#'   - `interaction_cond_time`: `numeric(1)` Minimum effect size for the 
#'     interaction between condition and time (Category 3). This controls how 
#'     large the differential curve travel must be across conditions to count 
#'     as a hit.
#'
#'   Values should be numeric scalars (typically >0). For example: 
#'   `min_effect_size = list(time_effect = 1, avg_diff_cond = 1, 
#'   interaction_cond_time = 2)` will only keep features with cumulative 
#'   travels or condition-time differences above those cutoffs. Use smaller 
#'   values (e.g., 0.1) for permissive filtering, or larger values for more 
#'   conservative thresholds.
#'
#'   The default is 0 for all three elements.
#'   
#' @param min_cluster_r2 `numeric(1)`: A value >=0 and <1
#' specifying the minimum allowed squared Pearson correlation (r2) of any
#' cluster member to the centroid of its assigned cluster.
#'
#' After k-means clustering, each cluster is iteratively pruned. Members whose
#' r2 to the current cluster centroid falls below `min_cluster_r2` are removed
#' from that cluster and reassigned to cluster `0` (the "other" cluster).
#'
#' Pruning is repeated until all remaining members satisfy the constraint, a
#' maximum of 10 iterations is reached, or the cluster would shrink below a
#' minimum size of 10 members. If a cluster cannot satisfy the constraint under
#' these conditions, all of its remaining members are reassigned to cluster `0`.
#'
#' Cluster `0` therefore contains all features that do not meet the minimum
#' centroid similarity criterion. These features are retained in the output but
#' are not considered part of any valid cluster.
#'
#' @param genes `character()`: A character vector of gene names corresponding 
#'  to the features to be analyzed. The order of entries must match the feature 
#'  order in \code{data}. Gene names should be standardized (cleaned) to ensure 
#'  compatibility with downstream databases used for overrepresentation 
#'  analysis after clustering.
#'
#' @param verbose `logical(1)`: Boolean flag controlling the display of 
#' messages.
#'
#' @return
#' A named list with three elements:
#' \describe{
#'   \item{\code{cluster_table}}{
#'     A tibble containing one row per \code{feature_nr} with metadata and
#'     cluster assignments across the analysis categories. The structure is:
#'     \itemize{
#'       \item \code{feature_nr} - Numeric feature identifier.
#'       \item \code{feature_name} - Preferred feature name, prioritizing
#'         values from the limma tables, then from the cluster table row
#'         names, and falling back to the numeric feature ID.
#'       \item \code{gene} - Preferred gene symbol from the \code{annotation}
#'         table if available, otherwise taken from the cluster tables.
#'       \item \code{cluster_<cond1>} / \code{cluster_<cond2>} - Cluster
#'         assignments for each time-effect condition, named according to
#'         the elements of \code{clustered_hits_levels}.
#'       \item \code{cluster_cat2} - Present only if category 2 results are
#'         available; a combined cluster label in the form
#'         \code{"<cluster_<cond1>>_<cluster_<cond2>>"} for features that
#'         are significant in category 2. If this value is \code{NA}, the
#'         feature was not a category 2 hit.
#'       \item \code{cluster_cat3} - Present only if category 3 results are
#'         available; a combined cluster label in the form
#'         \code{"<cluster_<cond1>>_<cluster_<cond2>>"} for features that
#'         are significant in category 3. If this value is \code{NA}, the
#'         feature was not a category 3 hit.
#'     }
#'     For any category-specific cluster column (\code{cluster_<cond1>},
#'     \code{cluster_<cond2>}, \code{cluster_cat2}, \code{cluster_cat3}),
#'     a value of \code{NA} indicates that the feature was not significant
#'     (not a hit) in that category.
#'   }
#'   \item{\code{spline_results}}{
#'     A named list summarizing the fitted spline trajectories, their shared
#'     time grid, and effect-size based significance flags. Structure:
#'     \describe{
#'       \item{\code{time_grid}}{Numeric vector of length \eqn{T} giving the
#'         common time points (e.g., hours since cultivation start) on which
#'         all splines were predicted.}
#'       \item{\code{predictions}}{Named list by condition (e.g.,
#'         \code{constant}, \code{temp_shift}). Each entry is a numeric
#'         matrix of size \eqn{N \times T} with rows corresponding to features
#'         and columns to \code{time_grid}. Values are the predicted spline
#'         trajectories on the absolute scale used in the analysis
#'         (e.g., log2-CPM after \code{voom}). Row order matches the feature
#'         order used throughout the analysis.}
#'       \item{\code{time_effect_effect_size}}{Named list by condition with a
#'         numeric vector (length \eqn{N}) per condition giving the
#'         \emph{cumulative travel} (integrated temporal change) of each
#'         feature`s spline across \code{time_grid}. Larger values indicate
#'         stronger within-condition temporal modulation.}
#'       \item{\code{time_effect_passed_threshold}}{Named list by condition
#'         with a logical vector (length \eqn{N}) per condition indicating
#'         whether the corresponding \code{time_effect_effect_size} exceeds
#'         the user-defined effect-size threshold (i.e., time-effect hits).}
#'       \item{\code{interaction_effect_size}}{Numeric vector (length \eqn{N})
#'         giving the \emph{differential cumulative travel} between the two
#'         condition-specific splines of each feature, computed on the same
#'         \code{time_grid}. Larger values indicate stronger differences in
#'         temporal behaviour between conditions (condition-time interaction).}
#'       \item{\code{interaction_passed_threshold}}{Logical vector (length
#'         \eqn{N}) indicating whether \code{interaction_effect_size}
#'         exceeds the interaction effect-size threshold (i.e., features with
#'         significantly different temporal profiles across conditions).}
#'     }
#'     Unless stated otherwise, vectors are aligned to the same feature order
#'     used in the prediction matrices; condition names match
#'     \code{levels(meta[[condition]])}.
#'   }
#'   \item{\code{report_payload}}{
#'     A structured list containing all information required to generate
#'     downstream clustering reports and visualizations, without recomputing
#'     any statistical results. This payload is designed to be consumed by
#'     dedicated reporting functions (e.g.,
#'     \code{create_clustering_report()}) and enables a strict separation
#'     between computation and reporting.
#'     The contents of \code{report_payload} are intended to be treated as
#'     read-only and should not be modified by the user. Any changes to
#'     visualization or reporting behavior should be performed by supplying
#'     appropriate arguments to the reporting functions rather than altering
#'     the payload itself.
#'     The payload includes:
#'     \describe{
#'       \item{\code{splineomics}}{
#'         The original `SplineOmics` object used for the analysis, providing
#'         access to the input data, metadata, design, spline parameters, and
#'         analysis settings.
#'       }
#'       \item{\code{all_levels_clustering}}{
#'         Clustering results for each condition level (Category 1) and, when
#'         available, clustering metadata for Categories 2/3.
#'       }
#'       \item{\code{genes}}{
#'         `character()` Vector of gene or feature names corresponding to the
#'         analyzed features.
#'       }
#'       \item{\code{adj_pthresh_time_effect}}{
#'         Adjusted p-value threshold used to define significant time-effect
#'         hits (Category 1).
#'       }
#'       \item{\code{adj_pthresh_avrg_diff_conditions}}{
#'         Adjusted p-value threshold used for average differences between
#'         conditions (Category 2).
#'       }
#'       \item{\code{adj_pthresh_interaction_condition_time}}{
#'         Adjusted p-value threshold used for condition--time interaction
#'         effects (Category 3).
#'       }
#'       \item{\code{category_2_and_3_hits}}{
#'         Data structure describing significant features from Categories 2 and
#'         3 (average differences and interactions), including effect-size
#'         annotations.
#'       }
#'       \item{\code{min_effect_size}}{
#'         Named list of effect-size thresholds applied in addition to
#'         statistical significance.
#'       }
#'       \item{\code{predicted_timecurves}}{
#'         Predicted spline trajectories and associated summaries (time grid,
#'         predictions per condition, and effect-size metrics).
#'       }
#'     }
#'   }
#' }
#'
#' @examples
#' # Toy data: 4 features x 6 samples (two conditions, three time points)
#' toy_data <- matrix(
#'     c(
#'         3, 5, 8, 12, 17, 23, # f1
#'         23, 17, 13, 9, 6, 4, # f2
#'         5, 3, 2, 2, 3, 5, # f3
#'         1, 4, 9, 8, 4, 1, # f4
#'         10, 10, 10, 10, 10, 10, # f5
#'         2, 2, 2, 9, 12, 15, # f6
#'         4, 5, 7, 10, 14, 19, # f7
#'         12, 11, 9, 8, 9, 12 # f8
#'     ),
#'     nrow = 8, ncol = 6, byrow = TRUE,
#'     dimnames = list(paste0("f", 1:8), paste0("s", 1:6))
#' )
#'
#' toy_meta <- data.frame(
#'     Time = c(0, 1, 2, 0, 1, 2),
#'     condition = rep(c("WT", "KO"), each = 3),
#'     Replicate = rep(c("R1", "R2"), each = 3),
#'     row.names = colnames(toy_data),
#'     stringsAsFactors = FALSE
#' )
#'
#' toy_annot <- data.frame(
#'     feature_nr = 1:8,
#'     gene = c("G1", "G2", "G3", "G4"),
#'     stringsAsFactors = FALSE
#' )
#'
#' # Stub limma "top tables" with minimal required fields
#' # (feature_nr + adj.P.Val)
#' tt_wt <- data.frame(feature_nr = 1:4, adj.P.Val = c(0.01, 0.20, 0.04, 0.60))
#' tt_ko <- data.frame(feature_nr = 1:4, adj.P.Val = c(0.50, 0.03, 0.70, 0.02))
#' tt_c2 <- data.frame(feature_nr = 1:4, adj.P.Val = c(0.04, 0.70, 0.80, 0.90))
#' tt_c3 <- data.frame(feature_nr = 1:4, adj.P.Val = c(0.20, 0.90, 0.03, 0.80))
#'
#' design_str <- "~ 1 + Time*condition"
#'
#' # Minimal spline parameters required by spline machinery
#' spline_params <- list(
#'     spline_type = "n", # natural cubic splines
#'     dof = 1L # degrees of freedom for the spline basis
#' )
#'
#' toy_splineomics <- list(
#'     data = toy_data,
#'     meta = toy_meta,
#'     annotation = toy_annot,
#'     report_info = list(
#'         omics_data_type = "RNA-seq",
#'         data_description = "toy example",
#'         data_collection_date = "2025-01-01",
#'         analyst_name = "Example",
#'         contact_info = "example@example.org",
#'         project_name = "ToyProject"
#'     ),
#'     design = design_str,
#'     mode = "integrated",
#'     condition = "condition",
#'     spline_params = spline_params,
#'     meta_batch_column = NULL,
#'     meta_batch2_column = NULL,
#'     limma_splines_result = list(
#'         time_effect                  = list(WT = tt_wt, KO = tt_ko),
#'         avrg_diff_conditions         = tt_c2,
#'         interaction_condition_time   = tt_c3
#'     ),
#'     feature_name_columns = "gene"
#' )
#' class(toy_splineomics) <- "SplineOmics"
#'
#' toy_splineomics <- run_limma_splines(toy_splineomics)
#'
#' # Clustering configuration: fixed k per condition
#' nr_k <- list(WT = 2L, KO = 2L)
#'
#' # Keep outputs light and write into a temporary directory
#' out <- cluster_hits(
#'     splineomics = toy_splineomics,
#'     nr_clusters = nr_k,
#'     adj_pthresh_time_effect = 0.05,
#'     adj_pthresh_avrg_diff_conditions = 0.05,
#'     adj_pthresh_interaction_condition_time = 0.05,
#'     min_effect_size = list(
#'         time_effect = 0,
#'         avg_diff_cond = 0,
#'         interaction_cond_time = 0
#'     ),
#'     genes = toy_annot$gene,
#' )
#'
#' @export
#'
cluster_hits <- function(
    splineomics,
    nr_clusters,
    adj_pthresh_time_effect = 0.05,
    adj_pthresh_avrg_diff_conditions = 0.05,
    adj_pthresh_interaction_condition_time = 0.05,
    min_effect_size = list(
        time_effect = 0,
        avg_diff_cond = 0,
        interaction_cond_time = 0
    ),
    min_cluster_r2 = 0,
    genes = NULL,
    verbose = FALSE
    ) {
    start_time <- Sys.time()

    check_splineomics_elements(
        splineomics = splineomics,
        func_type = "cluster_hits"
    )

    min_effect_size <- check_inputs_cluster_hits(
        min_effect_size = min_effect_size,
        min_cluster_r2 = min_cluster_r2
        )

    args <- lapply(
        as.list(match.call()[-1]),
        eval,
        parent.frame()
    )
    args[["verbose"]] <- verbose
    check_null_elements(args)
    input_control <- InputControl$new(args)
    input_control$auto_validate()

    top_tables <- splineomics[["limma_splines_result"]][["time_effect"]]
    data <- splineomics[["data"]]
    meta <- splineomics[["meta"]]
    mode <- splineomics[["mode"]]
    condition <- splineomics[["condition"]]
    spline_params <- splineomics[["spline_params"]]


    within_level_top_tables <- filter_top_tables(
        top_tables = top_tables,
        adj_pthresh_time_effect = adj_pthresh_time_effect,
        meta = meta,
        condition = condition
    )
    if (is.null(within_level_top_tables)) { # when <2 hits for all levels
        return(NULL)
    }

    predicted_timecurves <- predict_timecurves(
        splineomics = splineomics,
        data = data,
        meta = meta,
        condition = condition,
        spline_params = spline_params,
        mode = mode
    )

    predicted_timecurves <- add_cat1_and_cat3_effectsizes(
        predicted_timecurves,
        min_effect_sizes = min_effect_size
    )

    if (
        (mode != "isolated") &&
            (adj_pthresh_avrg_diff_conditions > 0 ||
                adj_pthresh_interaction_condition_time > 0)
    ) {
        category_2_and_3_hits <- get_category_2_and_3_hits(
            splineomics = splineomics,
            adj_pthresh_avrg_diff_conditions = adj_pthresh_avrg_diff_conditions,
            adj_pthresh_interaction = adj_pthresh_interaction_condition_time,
            avg_diff_cond_threshold = min_effect_size[["avg_diff_cond"]],
            predicted_timecurves = predicted_timecurves
        )
    } else {
        category_2_and_3_hits <- NULL
    }

    all_top_tables <- add_effect_size_columns(
        time_effect_effect_size = 
          predicted_timecurves[["time_effect_effect_size"]],
        interaction_effect_size = 
          predicted_timecurves[["interaction_effect_size"]],
        category_2_and_3_hits = category_2_and_3_hits,
        within_level_top_tables = within_level_top_tables
    )

    all_levels_clustering <- perform_clustering(
        time_effect_hits = all_top_tables[["within_level_top_tables"]],
        nr_clusters = nr_clusters,
        condition = condition,
        predicted_timecurves = predicted_timecurves,
        min_cluster_r2 = min_cluster_r2,
        verbose = verbose
    )

    cluster_table <- construct_cluster_table(
        limma_splines_results = splineomics[["limma_splines_result"]],
        all_levels_clustering = all_levels_clustering,
        category_2_and_3_hits = all_top_tables[["category_2_and_3_hits"]],
        genes = genes
    )
    
    report_payload <- list(
        splineomics = splineomics,
        all_levels_clustering = all_levels_clustering,
        genes = genes,
        adj_pthresh_time_effect = adj_pthresh_time_effect,
        adj_pthresh_avrg_diff_conditions = adj_pthresh_avrg_diff_conditions,
        adj_pthresh_interaction_condition_time =
            adj_pthresh_interaction_condition_time,
        category_2_and_3_hits = all_top_tables[["category_2_and_3_hits"]],
        min_effect_size = min_effect_size,
        predicted_timecurves = predicted_timecurves
    )
    class(report_payload) <- c(
        "SplineOmicsClusterHitsReportPayload",
        class(report_payload
        ))

    if (verbose) {
        end_time <- Sys.time()
        elapsed <- difftime(
            end_time,
            start_time,
            units = "min"
        )
        message(
            sprintf(
                "Running this function took %.1f min",
                as.numeric(elapsed)
            )
        )
    }

    list(
        cluster_table = cluster_table,
        spline_results = predicted_timecurves,
        report_payload = report_payload
    )
}


# Level 1 internal functions ---------------------------------------------------


#' Validate input arguments for clustering of significant hits
#'
#' @noRd
#'
#' @description
#' Checks that control parameters for clustering are well formed. Validates
#' the structure of `min_effect_size`.
#' Missing effect size entries are filled with 0.
#'
#' @param min_effect_size A named list of numeric scalars used as minimum
#'   effect size thresholds. Allowed names are:
#'   - `time_effect` (Category 1)
#'   - `avg_diff_cond` (Category 2)
#'   - `interaction_cond_time` (Category 3)
#'   The list may contain any subset of these names; missing names are set
#'   to 0. Any other names are rejected.
#'   
#' @param min_cluster_r2 `numeric(1)`: A value >=0 and <1
#' specifying the minimum allowed squared Pearson correlation (r2) of any
#' cluster member to the centroid of its assigned cluster.
#'
#' After k-means clustering, each cluster is iteratively pruned. Members whose
#' r2 to the current cluster centroid falls below `min_cluster_r2` are removed
#' from that cluster and reassigned to cluster `0` (the "other" cluster).
#'
#' Pruning is repeated until all remaining members satisfy the constraint, a
#' maximum of 10 iterations is reached, or the cluster would shrink below a
#' minimum size of 10 members. If a cluster cannot satisfy the constraint under
#' these conditions, all of its remaining members are reassigned to cluster `0`.
#'
#' Cluster `0` therefore contains all features that do not meet the minimum
#' centroid similarity criterion. These features are retained in the output but
#' are not considered part of any valid cluster.
#'
#' @return The completed `min_effect_size` list with all three allowed
#'   names present. Missing names are filled with 0. The function raises
#'   an error if any check fails.
#'
#' @details
#' - `min_effect_size` must be a list. All provided values must be single
#'   numerics. Names must be a subset of the allowed set.
#' - `max_hit_number` must be length 1 and either an integer >= 1 or `Inf`.
#'
check_inputs_cluster_hits <- function(
    min_effect_size,
    min_cluster_r2
    ) {
    if (!is.list(min_effect_size)) {
        rlang::abort("`min_effect_size` must be a list.")
    }

    allowed_names <- c(
        "time_effect",
        "avg_diff_cond",
        "interaction_cond_time"
        )
    nm <- names(min_effect_size)

    # names must be a subset of the allowed set (no extras)
    if (length(nm) > 0 && !all(nm %in% allowed_names)) {
        bad <- setdiff(nm, allowed_names)
        rlang::abort(c(
            "`min_effect_size` has unknown names:",
            paste(bad, collapse = ", ")
        ))
    }

    # start filled list with zeros
    filled <- as.list(setNames(rep(0, length(allowed_names)), allowed_names))

    # copy provided values with validation
    for (n in intersect(nm, allowed_names)) {
        val <- min_effect_size[[n]]
        if (!is.numeric(val) || length(val) != 1L) {
            rlang::abort(c(
                "`min_effect_size$", n, "` must be one numeric value."
            ))
        }
        filled[[n]] <- val
    }
    
    # Check min_cluster_r2
    if (!is.numeric(min_cluster_r2) ||
        length(min_cluster_r2) != 1L ||
        min_cluster_r2 < 0 ||
        min_cluster_r2 >= 1) {
        rlang::abort(c(
            "min_cluster_r2 must be a float >=0 and <1 but is",
            min_cluster_r2
            ))
    }

    # return the completed list (with zeros filled in)
    filled
}


#' Filter Top Tables by Adjusted P-Values and Levels
#'
#' @noRd
#'
#' @description
#' Filters a set of limma top tables based on adjusted p-value thresholds
#' and metadata levels. This function supports both within-level and
#' between-level analyses. It removes hits that do not meet the specified
#' criteria and ensures that clustering can only proceed for levels with
#' at least two hits.
#'
#' @param top_tables A list of limma top tables, where each top table
#' corresponds to a specific level or comparison.
#' @param adj_pthresh_time_effect `numeric(1)`: adj. p-value threshold
#' for the limma time effect results (category 1).
#' @param meta A dataframe containing metadata for the RNA-seq data,
#'   including the condition column used to identify levels.
#' @param condition A character string specifying the name of the condition
#'   column in the `meta` dataframe. Each level of this column corresponds
#'   to a separate analysis.
#'
#' @details
#' If a between-level analysis is detected, the function identifies the
#' appropriate indices for within-level and between-level top tables.
#' It filters within-level top tables based on feature indices from the
#' between-level results or adjusted p-value thresholds.
#'
#' For within-level analysis, only features with an adjusted p-value less
#' than the specified thresholds are retained. If fewer than two hits are
#' found for a level, clustering is skipped for that level, and an NA is
#' returned for that level in the filtered top tables.
#'
#' If all levels have fewer than two hits, the function stops execution
#' with an error message, as clustering cannot proceed.
#'
#' @return
#' A list of filtered top tables, where each entry corresponds to a level
#' in the condition. Levels with fewer than two hits are assigned NA.
#' If all levels are skipped, an error is thrown.
#'
filter_top_tables <- function(
    top_tables,
    adj_pthresh_time_effect,
    meta,
    condition) {
    result <- check_between_level_pattern(top_tables)

    if (result$between_levels) { # between_level analysis
        if (result$index_with_pattern == 1) {
            within_level_top_tables_index <- 2
            between_level_top_tables_index <- 1
        } else { # between level top_tables are at index 2
            within_level_top_tables_index <- 1
            between_level_top_tables_index <- 2
        }

        within_level_top_tables <- top_tables[[within_level_top_tables_index]]
        between_level_top_tables <- top_tables[[between_level_top_tables_index]]
    } else { # no between level analysis
        within_level_top_tables <- top_tables
    }

    for (i in seq_along(within_level_top_tables)) {
        within_level_top_table <- within_level_top_tables[[i]]
        level <- unique(as.character(meta[[condition]]))[i]

        if (result$between_levels) {
            hit_indices <- get_level_hit_indices(
                between_level_top_tables,
                level,
                adj_pthresh_time_effect
            )
        } else { # within level
            hit_indices <- within_level_top_table[["feature_nr"]][
                within_level_top_table[["adj.P.Val"]] < adj_pthresh_time_effect
            ]
        }

        top_table_filtered <-
            within_level_top_table[within_level_top_table[["feature_nr"]]
            %in% hit_indices, ]

        if (nrow(top_table_filtered) < 2) {
            message(
                "Level",
                level,
                "has < 2 hits. Skipping clustering for this level"
            )
            within_level_top_tables[[i]] <- NA
        } else {
            within_level_top_tables[[i]] <- top_table_filtered
        }
    }

    if (all(is.na(within_level_top_tables))) {
        message("All levels have < 2 hits. Cannot run clustering. Stopping.")
        return(NULL)
    }

    within_level_top_tables
}


#' Predict smooth timecourses from spline-augmented limma model
#'
#' @noRd
#'
#' @description
#' Predicts smooth expression or abundance trajectories for all features in a
#' spline-based limma model across all condition levels. The model must use
#' natural cubic splines (`ns`) or B-splines (`bs`) to represent time, with or
#' without condition-specific interaction terms.
#'
#' The function builds design matrices over a smooth time grid and uses
#' fitted model coefficients to reconstruct fitted curves for each feature,
#' optionally handling different modeling modes ("isolated" or "integrated").
#'
#' This is typically used to visualize model-implied dynamics over time for
#' multiple biological conditions.
#'
#' Note that this function does not use the random effects in case the linear
#' mixed model from the variancePartition::dream() was used. This is because
#' they model subject-specific deviations, not the fixed-effect population trend
#'  that defines the curve shape.
#'
#' @param splineomics A list containing top tables and model results (not used
#'   internally, but passed for interface compatibility).
#' @param data A dataframe containg the data used for fitting the linear models.
#' @param meta A data.frame containing metadata, including time and condition
#'   annotations.
#' @param condition String specifying the column in `meta` with experimental
#'   condition levels.
#' @param spline_params A list with spline specification:
#'   - `spline_type`: "n" for natural spline, "b" for B-spline (per condition)
#'   - `dof`: degrees of freedom (per condition)
#'   - `degree`: spline degree (only used for B-spline)
#' @param mode Either `"isolated"` or `"integrated"` depending on model setup.
#'
#' @return A list with:
#'   \describe{
#'     \item{`time_grid`}{Numeric vector of 1000 time points for prediction.}
#'     \item{`predictions`}{Named list by condition level. Each entry is a
#'     matrix of predicted values (features x time points).}
#'   }
#'
predict_timecurves <- function(
    splineomics,
    data,
    meta,
    condition,
    spline_params,
    mode) {
    # time grid (common to all levels)
    # number of unique sampling points
    fit <- splineomics[["fit"]]
    n_unique_time <- dplyr::n_distinct(meta[["Time"]])

    ## build a grid 10 x denser than the raw sampling
    smooth_timepoints <- seq(
        from = min(meta[["Time"]]),
        to = max(meta[["Time"]]),
        length.out = 10 * n_unique_time
    )

    pred_list <- list() # results

    # iterate over each condition level
    for (level in unique(meta[[condition]])) {
        # pick the right fit object
        if (mode == "isolated") {
            fit_lv <- fit[[level]]
            if (is.null(fit_lv)) {
                fit_lv <- fit[[paste0(condition, "_", level)]]
            }
        } else {
            fit_lv <- fit
        }
        if (is.null(fit_lv$coefficients)) {
            stop("missing coefficients for level: ", level)
        }

        design_n <- colnames(fit_lv$coefficients)

        # spline columns X1, X2, ...
        spline_cols <- grep(
            "^X\\d*$",
            design_n,
            value = TRUE
        )
        k <- length(spline_cols)

        # decide which row in spline_params to use
        idx <- if (mode == "isolated") {
            match(level, unique(meta[[condition]])) %||% 1L
        } else {
            1L
        }

        # build spline basis
        B <- if (spline_params$spline_type[idx] == "n") {
            splines::ns(
                smooth_timepoints,
                df = spline_params$dof[idx] %||% k
            )
        } else {
            splines::bs(
                smooth_timepoints,
                df     = spline_params$dof[idx] %||% k,
                degree = spline_params$degree[idx]
            )
        }
        colnames(B) <- spline_cols

        if (mode == "isolated") {
            # only intercept and spline terms
            X_new <- cbind("(Intercept)" = 1, B)
            needed <- c("(Intercept)", spline_cols)
        } else {
            # integrated fit: must include interaction terms for non-reference
            # levels
            cond_prefix <- condition
            all_levels <- unique(as.character(meta[[condition]]))
            design_cols <- colnames(fit_lv$coefficients)

            dummy_suffixes <- sub(
                paste0("^", cond_prefix),
                "",
                grep(
                    paste0(
                        "^",
                        cond_prefix
                    ),
                    design_cols,
                    value = TRUE
                )
            )
            reference_level <- setdiff(all_levels, dummy_suffixes)[1]

            if (identical(level, reference_level)) {
                X_new <- cbind(
                    "(Intercept)" = 1,
                    B
                )
                needed <- c(
                    "(Intercept)",
                    spline_cols
                )
            } else {
                dummy_col <- paste0(
                    cond_prefix,
                    level
                )
                # Find interaction columns dynamically
                int_cols <- vapply(spline_cols, function(spline_col) {
                    possible_matches <- colnames(fit_lv$coefficients)[
                        grepl(dummy_col, colnames(fit_lv$coefficients)) &
                            grepl(spline_col, colnames(fit_lv$coefficients))
                    ]
                    if (length(possible_matches) != 1) {
                        stop(
                            "Could not uniquely identify interaction col for: ",
                            dummy_col,
                            " and ", 
                            spline_col
                        )
                    }
                    possible_matches
                }, character(1))

                # Add intercept for non-reference level if present
                has_group_intercept <- 
                    dummy_col %in% colnames(fit_lv$coefficients)
                if (has_group_intercept) {
                    X_new <- cbind(
                        "(Intercept)" = 1,
                        B,
                        group_effect = 1,
                        B # interaction terms
                    )
                    colnames(X_new) <- c(
                        "(Intercept)",
                        spline_cols,
                        dummy_col,
                        int_cols
                    )
                    needed <- c(
                        "(Intercept)",
                        spline_cols,
                        dummy_col,
                        int_cols
                    )
                } else {
                    X_new <- cbind(
                        "(Intercept)" = 1,
                        B,
                        B # interaction terms only
                    )
                    colnames(X_new) <- c(
                        "(Intercept)",
                        spline_cols,
                        int_cols
                    )
                    needed <- c("(Intercept)", spline_cols, int_cols)
                }
            }
        }

        # coefficients matrix
        coef_full <- as.matrix(fit_lv$coefficients)
        # ensure missing columns are handled
        missing_cols <- setdiff(needed, colnames(coef_full))
        if (length(missing_cols)) {
            for (col in missing_cols) {
                coef_full[, col] <- 0
            }
        }

        # subset in correct order
        coef_mat <- coef_full[, needed, drop = FALSE]

        # predictions
        pred_mat <- coef_mat %*% t(X_new)

        pred_mat <- adjust_intercept_least_squares(
            pred_mat = pred_mat,
            data = data,
            meta = meta,
            condition = condition,
            level = level,
            time_grid = smooth_timepoints
        )

        # propagate feature names
        rownames(pred_mat) <- rownames(coef_mat)

        pred_list[[level]] <- pred_mat
    }

    list(
        time_grid   = smooth_timepoints,
        predictions = pred_list # named by condition level
    )
}


#' Add cat1 and cat3 effect sizes to predicted time curves
#'
#' @noRd
#'
#' @description
#' Computes two effect sizes for each feature from predicted time curves:
#' (1) cat1 cumulative travel per condition (sum of absolute successive
#' differences), and (2) cat3 differential travel for each pair of
#' conditions (sum of absolute differences between successive changes of
#' the two conditions). Thresholds are read from `min_effect_sizes`.
#'
#' @param predicted_timecurves A list returned by `predict_timecurves()`
#'   with a `$predictions` element. `$predictions` is a named list of
#'   matrices (features x time), one per condition. Row names are feature
#'   names; columns are ordered timepoints shared across conditions.
#' @param min_effect_sizes A list of numeric scalars with names
#'   `"time_effect"` and `"interaction_cond_time"`. Missing names are
#'   treated as zero by the caller. Values give the thresholds for cat1
#'   and cat3, respectively.
#'
#' @return The input `predicted_timecurves` with the following elements
#'   added:
#'   * `time_effect_effect_size`: list per condition of numeric vectors
#'     (cumulative travel per feature, cat1).
#'   * `time_effect_passed_threshold`: list per condition of logical
#'     vectors indicating cat1 pass/fail vs
#'     `min_effect_sizes$time_effect`.
#'   * `interaction_effect_size`: named list of numeric vectors, one per
#'     unordered condition pair. Each entry corresponds to a contrast
#'     named `"<cond1>_vs_<cond2>"` and stores the cat3 differential
#'     travel per feature for that pair.
#'   * `interaction_passed_threshold`: named list of logical vectors
#'     with the same structure as `interaction_effect_size`, indicating
#'     cat3 pass/fail vs `min_effect_sizes$interaction_cond_time` for
#'     each condition pair.
#'
#' @details
#' Cat1 cumulative travel for a feature in a condition is
#' `sum_{j=1}^{T-1} |x_{j+1} - x_j|`. It measures total movement of the
#' curve regardless of direction.
#'
#' For cat3, we consider all unordered condition pairs. For a pair
#' (k1, k2), we take successive steps
#' `d1_j = x1_{j+1}-x1_j` and `d2_j = x2_{j+1}-x2_j` and sum
#' `sum_{j=1}^{T-1} |d1_j - d2_j|`. This is large when the two
#' conditions move differently over time and zero when they change in
#' lockstep. The result is stored per pair and per feature.
#'
add_cat1_and_cat3_effectsizes <- function(
        predicted_timecurves,
        min_effect_sizes
        ) {
    thr_cat1 <- min_effect_sizes[["time_effect"]]
    thr_cat3 <- min_effect_sizes[["interaction_cond_time"]]
    
    # helper: cumulative travel per row
    cum_travel <- function(mat) {
        if (!is.matrix(mat)) {
            mat <- as.matrix(mat)
        }
        if (ncol(mat) < 2L) {
            out <- rep(0, nrow(mat))
            names(out) <- rownames(mat)
            return(out)
        }
        tr <- rowSums(
            abs(
                mat[, -1, drop = FALSE] -
                    mat[, -ncol(mat), drop = FALSE]
            )
        )
        if (!is.null(rownames(mat))) {
            names(tr) <- rownames(mat)
        }
        tr
    }
    
    # cat1 per level
    if (!is.list(predicted_timecurves$predictions) ||
        length(predicted_timecurves$predictions) < 1L) {
        stop_call_false(
            "`predicted_timecurves$predictions` is missing or empty."
        )
    }
    
    preds <- predicted_timecurves$predictions
    
    cat1_effects <- lapply(preds, cum_travel)
    cat1_passed <- lapply(
        cat1_effects,
        function(x) x >= thr_cat1
    )
    
    predicted_timecurves$time_effect_effect_size <- cat1_effects
    predicted_timecurves$time_effect_passed_threshold <- cat1_passed
    
    # cat3: movement-difference for all condition pairs
    levs <- names(preds)
    
    interaction_effect_size <- list()
    interaction_passed_threshold <- list()
    
    if (length(levs) >= 2L) {
        combs <- utils::combn(levs, 2L, simplify = FALSE)
        
        for (pair in combs) {
            k1 <- pair[1L]
            k2 <- pair[2L]
            
            m1 <- as.matrix(preds[[k1]])
            m2 <- as.matrix(preds[[k2]])
            
            if (!identical(dim(m1), dim(m2))) {
                stop_call_false(
                    "Predicted matrices for conditions '",
                    k1,
                    "' and '",
                    k2,
                    "' must have the same dimensions."
                )
            }
            
            if (ncol(m1) < 2L) {
                md <- rep(0, nrow(m1))
                names(md) <- rownames(m1)
            } else {
                d1 <- m1[, -1, drop = FALSE] -
                    m1[, -ncol(m1), drop = FALSE]
                d2 <- m2[, -1, drop = FALSE] -
                    m2[, -ncol(m2), drop = FALSE]
                md <- rowSums(abs(d1 - d2))
                names(md) <- rownames(m1)
            }
            
            cname <- paste0(k1, "_vs_", k2)
            interaction_effect_size[[cname]] <- md
            interaction_passed_threshold[[cname]] <- (md >= thr_cat3)
        }
    }
    
    predicted_timecurves$interaction_effect_size <-
        interaction_effect_size
    predicted_timecurves$interaction_passed_threshold <-
        interaction_passed_threshold
    
    predicted_timecurves
}


#' Perform clustering on predicted timecourses
#'
#' @noRd
#'
#' @description
#' Performs clustering of predicted timecourses for each condition
#' level (Category 1).
#'
#' Only features that both appear in the input
#' `time_effect_hits` and pass the time-effect size threshold are
#' clustered. Curves are z-score normalised before clustering.
#'
#' @param time_effect_hits A named list of data.frames or vectors giving
#'   Category 1 hits per condition level. Each entry must contain
#'   feature identifiers (`feature_nr`, `feature_names`) or numeric
#'   indices. Names must be in the format `{condition}_{level}`.
#' @param nr_clusters A list whose length matches `time_effect_hits`;
#'   each element is a numeric vector of candidate cluster numbers
#'   (e.g. `1:1`, `2:8`) for the corresponding condition level.
#' @param condition A string giving the name of the column in `meta`
#'   that encodes condition levels (e.g., `"Phase"`).
#' @param predicted_timecurves A list containing smoothed predictions,
#'   effect-size filters, and time grid.
#' @param min_cluster_r2 `numeric(1)`: A value >=0 and <1
#' specifying the minimum allowed squared Pearson correlation (r2) of any
#' cluster member to the centroid of its assigned cluster.
#'
#' After k-means clustering, each cluster is iteratively pruned. Members whose
#' r2 to the current cluster centroid falls below `min_cluster_r2` are removed
#' from that cluster and reassigned to cluster `0` (the "other" cluster).
#'
#' Pruning is repeated until all remaining members satisfy the constraint, a
#' maximum of 10 iterations is reached, or the cluster would shrink below a
#' minimum size of 10 members. If a cluster cannot satisfy the constraint under
#' these conditions, all of its remaining members are reassigned to cluster `0`.
#'
#' Cluster `0` therefore contains all features that do not meet the minimum
#' centroid similarity criterion. These features are retained in the output but
#' are not considered part of any valid cluster.
#' @param verbose Boolean flag controlling the display of messages.
#'
#' @return A named list of clustering results (one entry per condition
#'   level, plus an optional `paired_category_3` entry). Each entry is
#'   either:
#'   \describe{
#'     \item{A structured list}{Containing
#'       \itemize{
#'         \item `clustered_hits`: Feature-to-cluster assignments
#'         \item `hc`: The `hclust` object
#'         \item `curve_values`: Normalized curves with cluster labels
#'         \item `top_table`: Top table with added cluster column
#'         \item `clusters`: The number of clusters used
#'       }}
#'     \item{A string}{Informative message if clustering was skipped
#'       due to insufficient hits.}
#'   }
#'
#' @details
#' - Category 1 clustering is performed independently per condition
#'   level.
#' - Category 3 clustering is only performed if two condition levels
#'   are present and at least as many hits as requested clusters are
#'   available.
#'
perform_clustering <- function(
    time_effect_hits,
    nr_clusters,
    condition,
    predicted_timecurves,
    min_cluster_r2,
    verbose
    ) {
    if (verbose) {
        message("\n Performing the clustering...")
    }

    # common dense time grid (same for every level)
    time_grid <- predicted_timecurves$time_grid

    # container for clustering results
    results <- vector("list", length = length(time_effect_hits))
    names(results) <- names(time_effect_hits)

    # loop over every condition level
    for (i in seq_along(time_effect_hits)) {
        key <- names(time_effect_hits)[i]
        level <- sub(paste0("^", condition, "_"), "", key)
        if (verbose) {
            message(paste("For the level: ", level))
        }
        k_range <- nr_clusters[[level]]

        tbl <- time_effect_hits[[key]]
        if (is.data.frame(tbl)) {
            feat_idx <- tbl$feature_nr
            feat_names <- tbl$feature_names
        } else if (length(tbl) == 0L || all(is.na(tbl))) {
            feat_idx <- integer(0)
            feat_names <- character(0)
        } else {
            feat_idx <- as.integer(tbl)
            feat_names <- rownames(
                predicted_timecurves$predictions[[level]]
            )[feat_idx]
        }

        passed <- predicted_timecurves$time_effect_passed_threshold[[level]]
        feat_names <- feat_names[feat_names %in% names(passed)[passed]]

        if (length(feat_names) == 0L) {
            results[[key]] <- NA
            next
        }

        pred_mat <- predicted_timecurves$predictions[[level]]
        curves <- pred_mat[as.character(feat_names), , drop = FALSE]
        norm_cur <- normalize_curves(curves)
        top_table <- tbl[tbl$feature_names %in% feat_names, , drop = FALSE]

        results[[key]] <- kmeans_clustering(
            curve_values      = norm_cur,
            k_range           = k_range,
            smooth_timepoints = time_grid,
            top_table         = top_table,
            condition_level   = level,
            min_cluster_r2    = min_cluster_r2,
            verbose           = verbose
        )
    }

    # Leave a message for the user instead of just NA.
    results <- lapply(results, function(x) {
        if (is.logical(x)) {
            return(
                "No result for this level, because the top_table had < 2 hits"
                )
        } else {
            return(x)
        }
    })

    results
}


#' Get Category 2 and 3 Hits
#'
#' @noRd
#'
#' @description
#' Filter limma/dream top tables in the \code{splineomics} object to
#' identify significant features in two categories, across all pairwise
#' condition contrasts:
#' \itemize{
#'   \item \strong{Category 2}: Features with a significant average
#'   difference between conditions, based on both adjusted p-value and a
#'   minimum absolute effect size threshold.
#'   \item \strong{Category 3}: Features with a significant condition x
#'   time interaction (adjusted p-value), that also pass a precomputed
#'   interaction effect-size threshold stored in
#'   \code{predicted_timecurves$interaction_passed_threshold}.
#' }
#'
#' @param splineomics An S3 object containing spline-based limma/dream
#'   results. It must include a \code{limma_splines_result} element with:
#'   \itemize{
#'     \item \code{avrg_diff_conditions}: a named list of data frames,
#'       one per contrast, each containing average condition differences.
#'     \item \code{interaction_condition_time}: a named list of data
#'       frames, one per contrast, each containing condition x time
#'       interaction statistics.
#'   }
#'   For backward compatibility, these elements may also be single data
#'   frames, in which case they are treated as single-contrast lists.
#'
#' @param adj_pthresh_avrg_diff_conditions Numeric. Threshold for the
#'   adjusted p-value when testing average differences between
#'   conditions (Category 2).
#'
#' @param adj_pthresh_interaction Numeric. Threshold for the adjusted
#'   p-value when testing the interaction between condition and time
#'   (Category 3).
#'
#' @param avg_diff_cond_threshold Numeric. Minimum absolute effect size
#'   required for Category 2 hits (applied to the main effect column,
#'   e.g. \code{logFC}).
#'
#' @param predicted_timecurves A list of model predictions. It must
#'   contain an element \code{interaction_passed_threshold}. In the
#'   multi-condition setting this is a named list of logical vectors,
#'   one per unordered condition pair (contrast). Each element is named
#'   like \code{"A_vs_B"} and its entries are named by feature
#'   identifiers (e.g. feature names), indicating whether the Cat3
#'   interaction effect-size threshold was passed for that feature in
#'   that contrast. For backward compatibility it may also be a single
#'   logical vector (old two-condition behaviour).
#'
#' @return A list with two named lists of data frames:
#' \itemize{
#'   \item \code{category_2_hits}: named list of filtered top tables for
#'     average condition differences, one element per contrast.
#'   \item \code{category_3_hits}: named list of filtered top tables for
#'     condition x time interaction, one element per contrast.
#' }
#' Each inner data frame contains only the features that pass the
#' respective filters for that contrast.
#'
get_category_2_and_3_hits <- function(
        splineomics,
        adj_pthresh_avrg_diff_conditions,
        adj_pthresh_interaction,
        avg_diff_cond_threshold,
        predicted_timecurves
        ) {
    avrg_diff_conditions <-
        splineomics[["limma_splines_result"]][["avrg_diff_conditions"]]
    interaction_condition_time <-
        splineomics[["limma_splines_result"]][["interaction_condition_time"]]
    
    # Backward-compat: if old structure was a single data.frame
    if (is.data.frame(avrg_diff_conditions)) {
        avrg_diff_conditions <- list(contrast_1 = avrg_diff_conditions)
    }
    if (is.data.frame(interaction_condition_time)) {
        interaction_condition_time <-
            list(contrast_1 = interaction_condition_time)
    }
    
    # Helper: find effect-size column for category 2
    get_effect_col <- function(df) {
        if ("logFC" %in% names(df)) {
            "logFC"
        } else {
            num_cols <- which(vapply(df, is.numeric, logical(1L)))
            if (length(num_cols) == 0L) {
                stop(
                    "No numeric columns found in avrg_diff_conditions ",
                    "table; cannot apply effect size threshold."
                )
            }
            names(df)[num_cols[1L]]
        }
    }
    
    # Category 2: p-value + effect size threshold, per contrast
    category_2_hits <- lapply(
        avrg_diff_conditions,
        function(df) {
            if (nrow(df) == 0L) {
                return(df)
            }
            eff_col <- get_effect_col(df)
            
            keep <- df$adj.P.Val < adj_pthresh_avrg_diff_conditions &
                abs(df[[eff_col]]) >= avg_diff_cond_threshold
            
            df[keep, , drop = FALSE]
        }
    )
    
    # Category 3: p-value filter + interaction_passed_threshold,
    # per contrast
    pass_obj <- predicted_timecurves$interaction_passed_threshold
    if (is.null(pass_obj)) {
        stop(
            "'predicted_timecurves$interaction_passed_threshold' ",
            "must be provided for Category 3 filtering."
        )
    }
    
    # Helper: given a contrast-name from interaction_condition_time and
    # pass_obj, return the appropriate logical vector (or NULL).
    get_pass_vec_for_contrast <- function(contrast_name) {
        # Backward compat: single logical vector
        if (is.logical(pass_obj) && !is.list(pass_obj)) {
            return(pass_obj)
        }
        
        if (!is.list(pass_obj) || is.null(names(pass_obj))) {
            return(NULL)
        }
        
        nm <- names(pass_obj)
        
        # Strip common prefixes from contrast names, e.g.
        # "time_interaction_A_vs_B" -> "A_vs_B"
        stripped <- sub("^time_interaction_", "", contrast_name)
        stripped <- sub("^interaction_", "", stripped)
        
        cand <- c(contrast_name, stripped)
        
        idx <- which(nm %in% cand)[1L]
        if (length(idx) == 0L || is.na(idx)) {
            return(NULL)
        }
        
        pass_obj[[idx]]
    }

    category_3_hits <- vector(
        mode = "list",
        length = length(interaction_condition_time)
    )
    names(category_3_hits) <- names(interaction_condition_time)
    
    for (nm in names(interaction_condition_time)) {
        df <- interaction_condition_time[[nm]]
        
        if (nrow(df) == 0L) {
            category_3_hits[[nm]] <- df
            next
        }
        
        # First: p-value filter
        keep_p <- df$adj.P.Val < adj_pthresh_interaction
        if (!any(keep_p)) {
            category_3_hits[[nm]] <- df[FALSE, , drop = FALSE]
            next
        }
        
        df_sub <- df[keep_p, , drop = FALSE]
        
        if (!"feature_names" %in% names(df_sub)) {
            stop(
                "Expected column 'feature_names' in ",
                "'interaction_condition_time' table."
            )
        }
        
        pass_vec <- get_pass_vec_for_contrast(nm)
        
        if (is.null(pass_vec) || length(pass_vec) == 0L) {
            # No matching effect-size vector -> fall back to p-value only
            category_3_hits[[nm]] <- df_sub
            next
        }
        
        keys <- as.character(df_sub$feature_names)
        keep_effect <- pass_vec[keys]
        
        # unmatched or NA entries are treated as not passing the effect
        keep_effect[is.na(keep_effect)] <- FALSE
        keep_effect[is.null(keep_effect)] <- FALSE
        
        category_3_hits[[nm]] <- df_sub[keep_effect, , drop = FALSE]
    }
    
    list(
        category_2_hits = category_2_hits,
        category_3_hits = category_3_hits
    )
}


#' Construct unified cluster summary table (multi-condition)
#'
#' @noRd
#'
#' @description
#' Builds a unified cluster summary across:
#' * **Category 1** (per-condition time-effect clusters),
#' * **Category 2** (per-contrast average differences),
#' * **Category 3** (per-contrast condition-time interactions).
#'
#' The table merges:
#'   * per-condition cluster assignments,
#'   * per-contrast Category 2 and Category 3 assignments,
#'   * gene annotations,
#'   * feature names
#'
#' into a single flat tibble where each feature appears once.
#'
#'
#' ## Category 1 (time effect)
#' For every condition we create one column:
#'
#' \preformatted{
#'   cluster_<condition>
#' }
#'
#' where `<condition>` is taken from `names(all_levels_clustering)`
#' (excluding any `"paired_category_3"` entry).  
#' Values are the cluster indices from the `clustered_hits` table of that
#' condition.  
#'
#'
#' ## Category 2 (average difference, per contrast)
#' For every contrast listed in
#' `limma_splines_results$avrg_diff_conditions` we create a column:
#'
#' \preformatted{
#'   cluster_cat2_<suffix>
#' }
#'
#' where `<suffix>` is the contrast name 
#' **without the `"avrg_diff_"` prefix**,  
#' e.g. `"A_vs_B"`, `"constant_vs_more_oxygen"`, etc.
#'
#' Let `<cond1>_vs_<cond2>` be that suffix.  
#' The numeric effect column is assumed to be `"logFC"` if present,
#' otherwise the first numeric column other than `feature_nr`.
#' A positive sign yields `"<cond2>_higher"`, a negative sign yields
#' `"<cond1>_higher"`.  
#'
#' Only features present in the corresponding
#' `category_2_and_3_hits$category_2_hits[[suffix]]` are assigned a label;
#' all others receive `NA`.
#'
#'
#' ## Category 3 (interaction, per contrast)
#' For every contrast listed in
#' `limma_splines_results$interaction_condition_time` we create a column:
#'
#' \preformatted{
#'   cluster_cat3_<suffix>
#' }
#'
#' where `<suffix>` is the contrast name 
#' **without the `"time_interaction_"` prefix**,  
#' again of the form `<cond1>_vs_<cond2>`.
#'
#' The value is a string:
#'
#' \preformatted{
#'   "<cluster_of_cond1>_<cluster_of_cond2>"
#' }
#'
#' obtained by reading the Category 1 clusters from  
#' `cluster_<cond1>` and `cluster_<cond2>`.  
#' `"ns"` is inserted wherever a per-condition cluster is missing.
#'
#' Only features present in the corresponding
#' `category_2_and_3_hits$category_3_hits[[suffix]]` are assigned a label;
#' all others receive `NA`.
#'
#'
#' @param limma_splines_results A list with:
#'   * `time_effect`: named list of per-condition tibbles containing at
#'     least `feature_nr` and feature name columns.
#'   * `avrg_diff_conditions`: named list of per-contrast tibbles (names
#'     beginning with `"avrg_diff_"`), each containing at least
#'     `feature_nr` and one numeric contrast column.
#'   * `interaction_condition_time`: named list of per-contrast tibbles
#'     (names beginning with `"time_interaction_"`), each containing at
#'     least `feature_nr`.
#'
#' @param all_levels_clustering A named list with one entry per
#'   condition, each containing a `clustered_hits` data frame with
#'   columns `feature_nr` and `cluster`. An optional
#'   `"paired_category_3"` entry is ignored here.
#'
#' @param category_2_and_3_hits A list containing:
#'   * `category_2_hits`: named list of per-contrast tibbles (same names
#'     as in `avrg_diff_conditions`), each containing at least
#'     `feature_nr`.
#'   * `category_3_hits`: named list of per-contrast tibbles (same names
#'     as in `interaction_condition_time`), each containing at least
#'     `feature_nr`.
#'   These define which features are allowed non-NA entries in the
#'   Cat2/Cat3 result columns.
#'
#' @param genes Optional character vector of gene symbols indexed by
#'   `feature_nr`. Use `NULL` to disable gene annotation.
#'
#' @return A tibble with one row per feature and columns:
#'   * `feature_nr`
#'   * `feature_name`
#'   * `gene`
#'   * `cluster_<condition>` for each condition
#'   * `cluster_cat2_<suffix>` for each Cat2 contrast
#'   * `cluster_cat3_<suffix>` for each Cat3 contrast
#'
#' @importFrom dplyr mutate transmute filter select rename left_join
#'   arrange distinct group_by ungroup slice_head bind_rows coalesce
#'   case_when rowwise c_across
#' @importFrom tibble as_tibble tibble
#' @importFrom rlang sym .data
#'
construct_cluster_table <- function(
        limma_splines_results,
        all_levels_clustering,
        category_2_and_3_hits,
        genes
        ) {
    # condition names from clustering
    cond_names <- setdiff(
        names(all_levels_clustering),
        "paired_category_3"
    )
    # short condition IDs used in contrast suffixes: strip
    # "Condition_" or "condition_"
    short_cond_names <- sub("^(?i)condition_", "", cond_names, perl = TRUE)
    names(short_cond_names) <- short_cond_names  # name by short id

    map_short_to_full <- function(short) {
        idx <- match(short, short_cond_names)
        if (is.na(idx)) {
            cand <- grep(
                paste0("(^|_)", short, "$"),
                short_cond_names
            )
            if (length(cand) == 1L) {
                idx <- cand
            }
        }
        if (is.na(idx)) {
            stop(
                "Cannot map condition label '",
                short,
                "' to all_levels_clustering names."
            )
        }
        cond_names[[idx]]
    }
    
    has_c2 <- is.list(category_2_and_3_hits) &&
        "category_2_hits" %in% names(category_2_and_3_hits)
    
    has_c3 <- is.list(category_2_and_3_hits) &&
        "category_3_hits" %in% names(category_2_and_3_hits)
    
    no_genes <- is.null(genes)
    anot <- if (no_genes) {
        tibble::tibble(
            feature_nr = numeric(0),
            gan = character(0)
        )
    } else {
        tibble::tibble(
            feature_nr = seq_along(genes),
            gan = as.character(genes)
        ) |>
            dplyr::distinct(
                dplyr::across("feature_nr"),
                .keep_all = TRUE
            )
    }
    
    # per-condition cluster tables (Cat1)
    clustered_hits_levels <- lapply(
        all_levels_clustering[cond_names],
        function(x) {
            if (is.list(x) && !is.null(x$clustered_hits)) {
                x$clustered_hits
            } else {
                x
            }
        }
    )
    
    cl_list <- list()
    for (cond in cond_names) {
        cl_name <- paste0("cluster_", cond)
        cl_list[[cond]] <- ncl(
            clustered_hits_levels[[cond]],
            cl_name
        )
    }
    
    # feature-name table from time_effect and all limma tables
    te_list <- limma_splines_results$time_effect
    add_parts <- lapply(te_list, toptbl_to_fn)
    
    if (has_c2) {
        c2_all <- dplyr::bind_rows(
            limma_splines_results$avrg_diff_conditions
        )
        add_parts <- c(
            add_parts,
            list(toptbl_to_fn(c2_all))
        )
    }
    if (has_c3) {
        c3_all <- dplyr::bind_rows(
            limma_splines_results$interaction_condition_time
        )
        add_parts <- c(
            add_parts,
            list(toptbl_to_fn(c3_all))
        )
    }
    
    fn_tbl <- dplyr::bind_rows(add_parts) |>
        dplyr::distinct(
            dplyr::across("feature_nr"),
            .keep_all = TRUE
        )
    
    fn_from_cl <- dplyr::bind_rows(
        lapply(
            cl_list,
            function(x) {
                x |>
                    dplyr::transmute(
                        feature_nr = .data$feature_nr,
                        fname_cl   = .data$fnsrc
                    )
            }
        )
    ) |>
        dplyr::filter(
            !is.na(.data$feature_nr),
            !is.na(.data$fname_cl),
            .data$fname_cl != ""
        ) |>
        dplyr::distinct(
            dplyr::across("feature_nr"),
            .keep_all = TRUE
        )
    
    allf <- dplyr::bind_rows(
        anot |> dplyr::select("feature_nr"),
        dplyr::bind_rows(
            lapply(
                cl_list,
                function(x) x |> dplyr::select("feature_nr")
            )
        ),
        fn_tbl |> dplyr::select("feature_nr")
    ) |>
        dplyr::distinct(
            dplyr::across("feature_nr")
        ) |>
        dplyr::filter(!is.na(.data$feature_nr)) |>
        dplyr::arrange(.data$feature_nr)
    
    base <- allf |>
        dplyr::left_join(anot, by = "feature_nr")
    
    gcl_cols <- character(0)
    
    for (cond in cond_names) {
        cluster_col <- paste0("cluster_", cond)
        gcl_col <- paste0("gcl_", cond)
        
        cl <- cl_list[[cond]]
        
        base <- base |>
            dplyr::left_join(
                cl |>
                    dplyr::transmute(
                        feature_nr = .data$feature_nr,
                        !!cluster_col := .data[[cluster_col]],
                        gcl = .data$gcl
                    ) |>
                    dplyr::rename_with(
                        ~ gcl_col,
                        .cols = "gcl"
                    ),
                by = "feature_nr"
            )
        
        gcl_cols <- c(gcl_cols, gcl_col)
    }
    
    base <- base |>
        dplyr::left_join(fn_from_cl, by = "feature_nr") |>
        dplyr::left_join(fn_tbl, by = "feature_nr") |>
        dplyr::group_by(.data$feature_nr) |>
        dplyr::slice_head(n = 1) |>
        dplyr::ungroup() |>
        dplyr::mutate(
            feature_name = dplyr::coalesce(
                .data$fname_tbl,
                .data$fname_cl,
                as.character(.data$feature_nr)
            )
        )
    
    if (no_genes) {
        base <- base |>
            dplyr::mutate(gene = NA_character_)
    } else {
        gene_cols <- c(
            "gan",
            gcl_cols[gcl_cols %in% names(base)]
        )
        base <- base |>
            dplyr::rowwise() |>
            dplyr::mutate(
                gene = {
                    vals <- dplyr::c_across(
                        dplyr::all_of(gene_cols)
                    )
                    idx <- which(!is.na(vals) & vals != "")[1]
                    if (is.na(idx)) {
                        NA_character_
                    } else {
                        vals[[idx]]
                    }
                }
            ) |>
            dplyr::ungroup()
    }
    
    keep_clusters <- paste0("cluster_", cond_names)
    keep_clusters <- intersect(keep_clusters, names(base))
    
    cols <- c(
        "feature_nr",
        "feature_name",
        "gene",
        keep_clusters
    )
    out <- base[, cols]
    
    # Category 2: per contrast
    if (has_c2) {
        c2_res  <- limma_splines_results$avrg_diff_conditions
        c2_hits <- category_2_and_3_hits$category_2_hits
        
        for (cn in names(c2_res)) {
            c2_tbl <- c2_res[[cn]]
            if (is.null(c2_tbl) || nrow(c2_tbl) == 0) {
                next
            }
            
            score_col <- if ("logFC" %in% names(c2_tbl)) {
                "logFC"
            } else {
                num_cols <- names(c2_tbl)[
                    vapply(c2_tbl, is.numeric, logical(1))
                ]
                num_cols <- setdiff(num_cols, "feature_nr")
                if (length(num_cols) == 0) next
                num_cols[[1]]
            }
            
            suffix <- sub("^avrg_diff_", "", cn)
            parts <- strsplit(suffix, "_vs_")[[1]]
            cond1_short <- parts[1]
            cond2_short <- parts[2]
            
            c2_df <- c2_tbl |>
                dplyr::transmute(
                    feature_nr = .data$feature_nr,
                    cat2_tmp = dplyr::case_when(
                        .data[[score_col]] > 0 ~ paste0(
                            gsub("_", "", cond2_short),
                            "_higher"
                        ),
                        .data[[score_col]] < 0 ~ paste0(
                            gsub("_", "", cond1_short),
                            "_higher"
                        ),
                        TRUE ~ NA_character_
                    )
                ) |>
                dplyr::distinct(
                    dplyr::across("feature_nr"),
                    .keep_all = TRUE
                )
            
            hit_tbl <- c2_hits[[cn]]
            if (!is.null(hit_tbl) && nrow(hit_tbl) > 0) {
                cat2h <- hit_tbl |>
                    dplyr::transmute(
                        feature_nr = .data$feature_nr
                    ) |>
                    dplyr::distinct()
                c2_df <- c2_df |>
                    dplyr::mutate(
                        cat2_tmp = ifelse(
                            .data$feature_nr %in% cat2h$feature_nr,
                            .data$cat2_tmp,
                            NA_character_
                        )
                    )
            }
            
            out_col <- paste0("cluster_cat2_", suffix)
            c2_df <- c2_df |>
                dplyr::rename_with(
                    ~ out_col,
                    .cols = "cat2_tmp"
                )
            
            out <- out |>
                dplyr::left_join(c2_df, by = "feature_nr")
        }
    }

    # Category 3: per contrast
    if (has_c3) {
        c3_hits <- category_2_and_3_hits$category_3_hits
        ic_res  <- limma_splines_results$interaction_condition_time
        
        for (cn in names(ic_res)) {
            hit_tbl <- c3_hits[[cn]]
            
            if (!is.null(hit_tbl) && nrow(hit_tbl) > 0) {
                sig_c3 <- hit_tbl |>
                    dplyr::transmute(
                        feature_nr = .data$feature_nr
                    ) |>
                    dplyr::distinct() |>
                    dplyr::pull("feature_nr")
            } else {
                sig_c3 <- integer(0)
            }
            
            suffix <- sub("^time_interaction_", "", cn)
            parts <- strsplit(suffix, "_vs_")[[1]]
            cond1_short <- parts[1]
            cond2_short <- parts[2]
            
            cond1_full <- map_short_to_full(cond1_short)
            cond2_full <- map_short_to_full(cond2_short)
            
            col1 <- paste0("cluster_", cond1_full)
            col2 <- paste0("cluster_", cond2_full)
            
            out_col <- paste0("cluster_cat3_", suffix)
            
            tmp <- out |>
                dplyr::transmute(
                    feature_nr = .data$feature_nr,
                    cat3_tmp = dplyr::case_when(
                        !(.data$feature_nr %in% sig_c3) ~
                            NA_character_,
                        TRUE ~ paste0(
                            ifelse(
                                is.na(.data[[col1]]),
                                "nohit",
                                as.character(.data[[col1]])
                            ),
                            "_",
                            ifelse(
                                is.na(.data[[col2]]),
                                "nohit",
                                as.character(.data[[col2]])
                            )
                        )
                    )
                ) |>
                dplyr::rename_with(
                    ~ out_col,
                    .cols = "cat3_tmp"
                )
            
            out <- out |>
                dplyr::left_join(tmp, by = "feature_nr")
        }
    }
    
    out |>
        dplyr::distinct(
            dplyr::across("feature_nr"),
            .keep_all = TRUE
        ) |>
        dplyr::arrange(.data$feature_nr)
}


#' Add cT and cDT columns to hit and top tables
#'
#' @noRd
#'
#' @description
#' For \code{category_2_and_3_hits$category_3_hits}, add per-condition
#' time-effect columns \code{cT_<cond>} (one per condition in the
#' contrast), mapped by \code{feature_nr} into the corresponding
#' effect-size vectors in \code{time_effect_effect_size}. Also add a
#' combined interaction column \code{cDT} taken from
#' \code{interaction_effect_size}, again mapped by \code{feature_nr}.
#'
#' \code{category_2_and_3_hits$category_3_hits} is expected to be a
#' named list of tibbles/data frames, one per pairwise contrast. Each
#' element must contain a numeric \code{feature_nr} column. For backward
#' compatibility, a single tibble is also accepted and is treated as a
#' single-element list.
#'
#' For \code{within_level_top_tables}, a \code{cT} column is added to
#' each tibble whose name matches the entries in
#' \code{time_effect_effect_size}. Matching is done via stripping the
#' prefix up to the first underscore (e.g. \code{"Condition_A"} ->
#' \code{"A"}).
#'
#' @param time_effect_effect_size
#'   A named list of numeric vectors. Each vector holds per-feature
#'   time-effect sizes for one condition level. Names are the "short"
#'   condition labels (e.g. \code{"A"}, \code{"B"}, \code{"constant"})
#'   as used in contrast suffixes like \code{"A_vs_B"}. These names are
#'   used to:
#'   \itemize{
#'     \item create \code{cT_<cond>} columns in the Category 3 hit
#'       tables (only for the two conditions participating in each
#'       contrast), and
#'     \item match within-level top tables named \code{Condition_<cond>}
#'       in \code{within_level_top_tables}.
#'   }
#'
#' @param interaction_effect_size
#'   A named list of numeric vectors, one per contrast. Names are
#'   contrast suffixes such as \code{"A_vs_B"}. Each vector holds
#'   per-feature interaction effect sizes for that contrast, and is
#'   mapped into a \code{cDT} column in the corresponding Category 3
#'   hit table using \code{feature_nr}. For backward compatibility, a
#'   single numeric vector is also accepted and is used for all
#'   contrasts.
#'
#' @param category_2_and_3_hits
#'   A list returned by \code{get_category_2_and_3_hits()}, containing
#'   an element \code{category_3_hits}. This element is a named list of
#'   tibbles (one per contrast) or a single tibble, each with a numeric
#'   \code{feature_nr} column.
#'
#' @param within_level_top_tables
#'   A list of tibbles/data frames, typically named
#'   \code{Condition_<cond>}, each containing a numeric
#'   \code{feature_nr} column. These are within-level time-effect top
#'   tables to which a \code{cT} column is added.
#'
#' @return
#'   A list with elements:
#'   \itemize{
#'     \item \code{within_level_top_tables}: updated list of tibbles
#'       with added \code{cT} columns.
#'     \item \code{category_2_and_3_hits}: updated list with
#'       \code{category_3_hits} tables now containing per-contrast
#'       \code{cT_<cond>} and \code{cDT} columns.
#'   }
#'
add_effect_size_columns <- function(
        time_effect_effect_size,
        interaction_effect_size,
        category_2_and_3_hits,
        within_level_top_tables
        ) {
    # Category 3 top tables (cT, cDT)
    if (!is.null(category_2_and_3_hits)) {
        cat3 <- category_2_and_3_hits[["category_3_hits"]]
        norm <- normalize_cat3_hits(cat3)

        if (!is.null(norm$list)) {
            cat3_list <- norm$list
            
            cat3_list <- Map(
                f = function(
                        tbl,
                        contrast_name
                        ) {
                        parsed <- parse_contrast_conditions(contrast_name)
                        suffix <- parsed$suffix
                        parts  <- parsed$parts
                        
                        tbl <- add_cat3_cT(
                            tbl,
                            time_effect_effect_size,
                            parts
                        )
                        
                        ies_vec <- get_interaction_es_vec(
                            interaction_effect_size = interaction_effect_size,
                            suffix = suffix,
                            contrast_name = contrast_name
                        )
                        
                        add_cat3_cDT(
                            tbl,
                            ies_vec,
                            context = contrast_name
                        )
                    },
                tbl = cat3_list,
                contrast_name = names(cat3_list)
                )
            
            # restore original structure (df vs list)
            category_2_and_3_hits[["category_3_hits"]] <- if (norm$was_df) {
                cat3_list[[1L]]
            } else {
                cat3_list
            }
        }
    }
    
    # category 1: within_level_top_tables: per-condition cT
    for (nm in names(time_effect_effect_size)) {
        
        tt_name <- find_within_level_table_name(
            within_level_top_tables,
            nm
            )
        if (is.na(tt_name)) next
        
        tt <- within_level_top_tables[[tt_name]]
        
        # skip NA-like placeholders
        if (is.atomic(tt) && length(tt) == 1L && is.na(tt)) next

        vec <- time_effect_effect_size[[nm]]
        tt[["cT"]] <- map_effect_by_feature_strict(
            effect_vec = vec,
            table_features = tt[["feature_names"]],
            context = paste0("within_level cT in ", tt_name)
        )
        
        within_level_top_tables[[tt_name]] <- tt
    }
    
    list(
        within_level_top_tables = within_level_top_tables,
        category_2_and_3_hits = category_2_and_3_hits
    )
}


# Level 2 internal functions ---------------------------------------------------


#' Check for Between-Level Patterns in Top Tables
#'
#' @noRd
#'
#' @description
#' This function checks if any of the elements within a list of top tables
#' contain element names that match the specified between-level pattern.
#'
#' @param top_tables A list where each element is itself a list containing
#' named elements.
#'
#' @return A list with two elements:
#' \describe{
#'   \item{between_levels}{A logical value indicating whether any element names
#'   match the between-level pattern.}
#'   \item{index_with_pattern}{The index of the first element in `top_tables`
#'   where all names match the between-level pattern, or NA if no match is
#'   found.}
#' }
#'
#' @details
#' The function iterates over each element in `top_tables`. For each element
#' that
#' is a list, it checks if all names within that inner list match the pattern
#' `".+_vs_.+"`. If a match is found, the function sets `between_levels` to TRUE
#' and records the index of the matching element. The search stops at the first
#' match.
#'
check_between_level_pattern <- function(top_tables) {
    # Initialize variables
    between_levels <- FALSE
    index_with_pattern <- NA

    # Define the regular expression pattern
    pattern <- ".+_vs_.+"

    # Check if top_tables is a list
    if (is.list(top_tables)) {
        # Iterate over each element in top_tables
        for (i in seq_along(top_tables)) {
            # Check if the element is a list
            if (is.list(top_tables[[i]])) {
                # Get the names of the elements in the inner list
                element_names <- names(top_tables[[i]])
                # Check if all names in the inner list match the pattern
                if (all(grepl(pattern, element_names))) {
                    between_levels <- TRUE
                    index_with_pattern <- i
                    break
                }
            }
        }
    }

    return(list(
        between_levels = between_levels,
        index_with_pattern = index_with_pattern
    ))
}


#' Get Hit Indices for a Specific Level
#'
#' @noRd
#'
#' @description
#' This function retrieves unique feature indices from a list of between-level
#' top tables for a specified level, based on adjusted p-value thresholds.
#'
#' @param between_level_top_tables A list of data frames containing the
#' between-level top tables.
#' @param level A string specifying the level to search for within the names
#' of the data frames.
#' @param adj_pthresh_time_effect `numeric(1)`: adj. p-value threshold
#' for the limma time effect results (category 1).
#'
#' @return A vector of unique feature indices that meet the adjusted p-value
#' threshold criteria for the specified level.
#'
#' @details
#' The function iterates over each data frame in `between_level_top_tables`. For
#' each data frame whose name contains the specified level (case insensitive),
#' it identifies the rows where the adjusted p-value is below the corresponding
#' threshold. The function then extracts the feature indices from these rows and
#' compiles a unique list of these indices.
#'
get_level_hit_indices <- function(
    between_level_top_tables,
    level,
    adj_pthresh_time_effect) {
    unique_hit_indices <- c()

    # Loop through the elements of the list
    for (i in seq_along(between_level_top_tables)) {
        # Get the name of the current data frame
        df_name <- names(between_level_top_tables)[i]

        # Check if the name contains the level string case insensitively
        if (grepl(level, df_name, ignore.case = TRUE)) {
            # Get the current data frame
            within_level_top_table <- between_level_top_tables[[i]]

            # Find the row indices that meet the condition
            hit_indices <-which(
                within_level_top_table[["adj.P.Val"]] < adj_pthresh_time_effect
                )

            # Extract the feature indices from the identified rows
            feature_indices <- within_level_top_table[hit_indices, "feature_nr"]
            feature_indices <- within_level_top_table[hit_indices,
                "feature_nr",
                drop = TRUE
            ]
            unique_hit_indices <- c(
                unique_hit_indices,
                feature_indices
            )
        }
    }

    # Get unique feature indices
    unique_hit_indices <- unique(unique_hit_indices)
}


#' Adjust predicted spline curves to match empirical data intercepts
#'
#' @noRd
#'
#' @description
#' This function adjusts the intercept of predicted spline-based
#' timecourses so that they visually align with the actual data. It does
#' so by calculating the optimal constant offset (per feature) that
#' minimizes the squared difference between the predicted and observed
#' values, across all available samples for the specified condition level.
#'
#' In contrast to simple regression models, the linear models used in this
#' context (e.g., using `limma`) include not only spline terms but also
#' additional scientific covariates (e.g., batch effects, condition
#' indicators). These covariates influence the fitted intercept, meaning
#' the predicted curve does not necessarily pass through the "center of
#' mass" of the actual data. Instead, the model`s intercept serves as an
#' anchor for interpreting *effects*, not for minimizing residual error.
#'
#' Therefore, for the sake of visual clarity in plotting, this function
#' adjusts the entire predicted timecourse vertically-without altering its
#' shape-so that it better reflects the empirical data. This adjustment is
#' purely cosmetic and does not affect statistical inference. Only the
#' *shape* of the spline is tested in hypothesis testing; the intercept
#' shift is applied post hoc for visualization.
#'
#' @param pred_mat A numeric matrix of predicted values from the spline
#'   model. Rows are features, columns are timepoints (as in the prediction
#'   grid).
#' @param data A numeric matrix of observed data. Same feature x sample
#'   structure as used in model fitting.
#' @param meta A `data.frame` containing metadata for each sample (i.e.,
#'   column of `data`), including `Time` and the condition variable used to
#'   stratify the prediction.
#' @param condition A string giving the name of the condition column in
#'   `meta` (e.g., `"Phase"`).
#' @param level The condition level for which the predictions were
#'   generated (e.g., `"Stationary"`).
#' @param time_grid The numeric vector of time values used for spline
#'   prediction (i.e., the x-axis of `pred_mat`).
#'
#' @return A matrix of the same shape as `pred_mat`, where each row has
#'   been shifted by a constant so that the predicted curve better matches
#'   the empirical values under least-squares alignment.
#'
adjust_intercept_least_squares <- function(
    pred_mat,
    data,
    meta,
    condition,
    level,
    time_grid) {
    # Match samples for this group
    sample_idx <- which(meta[[condition]] == level)

    if (length(sample_idx) == 0) {
        warning(
            "No samples found for level ",
            level,
            ". Skipping intercept adjustment."
        )
        return(pred_mat)
    }

    # Actual data matrix: features x group samples
    data_subset <- data[, sample_idx, drop = FALSE]
    # Subset data to match the rows in pred_mat
    common_rows <- intersect(rownames(pred_mat), rownames(data_subset))

    if (length(common_rows) != nrow(pred_mat)) {
        missing_rows <- setdiff(rownames(pred_mat), common_rows)
        stop_call_false(
            "The following features in pred_mat were not found in data_subset",
            "(condition '",
            level,
            "'): ",
            paste(missing_rows, collapse = ", ")
        )
    }

    data_subset <- data_subset[common_rows, , drop = FALSE]

    pred_mat <- pred_mat[common_rows, , drop = FALSE]

    # Time values of samples
    sample_times <- meta$Time[sample_idx]

    # Match each sample time to nearest time grid index
    matched_indices <- vapply(
        sample_times,
        function(t) which.min(abs(t - time_grid)),
        integer(1)
    )

    # For each sample, extract the corresponding prediction column
    pred_mat_expanded <- pred_mat[, matched_indices, drop = FALSE]

    # Compute offset: empirical - predicted mean across matched samples
    offset <- rowMeans(data_subset - pred_mat_expanded, na.rm = TRUE)
    offset[is.na(offset)] <- 0 # fallback for all-NA rows

    # Apply offset to all predicted timepoints
    pred_mat <- pred_mat + offset

    return(pred_mat)
}


#' Safely convert object to tibble
#'
#' @noRd
#'
#' @description
#' Safely convert an input object to a tibble. Handles `NULL`, data
#' frames, and lists of data frames by coercing them to tibbles and
#' binding them together. Any other input type returns an empty tibble.
#'
#' @param x An object to be converted to a tibble. Can be `NULL`,
#'   a data frame, or a list of data frames.
#'
#' @return A tibble. If `x` is `NULL`, returns an empty tibble. If `x`
#'   is a data frame, returns it as a tibble. If `x` is a list of data
#'   frames, returns them bound into a single tibble.
#'
#' @importFrom tibble as_tibble tibble
#' @importFrom dplyr bind_rows
#'
stbl <- function(x) {
    if (is.null(x)) {
        return(tibble())
    }
    if (inherits(x, "data.frame")) {
        return(as_tibble(x))
    }
    if (is.list(x)) {
        xs <- lapply(x, function(y) {
            if (inherits(y, "data.frame")) as_tibble(y) else tibble()
        })
        return(bind_rows(xs))
    }
    tibble()
}


#' Normalize cluster dataframe
#'
#' @noRd
#'
#' @description
#' Normalizes a cluster assignment data frame by standardizing column
#' names, ensuring one row per `feature_nr`, and adding a specified
#' output column for the cluster. Handles optional `gene` and feature
#' name information from row names. Non-data-frame inputs are first
#' converted using \code{stbl()}.
#'
#' @param df A data frame or object convertible by \code{stbl()}
#'   containing at least a `cluster` column, and optionally `feature`
#'   and `gene` columns. Row names may store feature names.
#' @param outcol A character scalar giving the name for the cluster
#'   column in the returned tibble.
#'
#' @return A tibble with columns:
#'   * `feature_nr` - numeric feature identifier.
#'   * `outcol` - cluster assignment as character.
#'   * `gcl` - optional gene from the input if present.
#'   * `fnsrc` - feature name source from row names.
#'
#' @importFrom tibble tibble
#' @importFrom dplyr filter group_by slice_head ungroup
#' @importFrom rlang sym :=
#'
ncl <- function(
    df,
    outcol) {
    df <- stbl(df)
    if (nrow(df) == 0) {
        return(tibble(
            feature_nr = numeric(0),
            !!rlang::sym(outcol) := NA_character_,
            gcl = NA_character_,
            fnsrc = NA_character_
        ))
    }
    hf <- "feature" %in% names(df)
    rn <- rownames(df)
    fnsrc <- if (!is.null(rn)) rn else rep(NA_character_, nrow(df))
    feature_nr <- if (hf) df$feature else as.numeric(rn)
    tibble(
        feature_nr = feature_nr,
        !!outcol := as.character(df$cluster),
        gcl = if ("gene" %in% names(df)) {
            as.character(df$gene)
        } else {
            NA_character_
        },
        fnsrc = fnsrc
    ) |>
        filter(!is.na(feature_nr)) |>
        group_by(feature_nr) |>
        slice_head(n = 1) |>
        ungroup()
}


#' Extract feature names from toptable
#'
#' @noRd
#'
#' @description
#' Extracts `feature_nr` and corresponding feature names from a
#' toptable-like data frame. Accepts either `feature_names`,
#' `feature_name`, or falls back to converting `feature_nr` to a
#' character string. Input is first normalized with \code{stbl()}.
#'
#' @param df A toptable data frame or object convertible by
#'   \code{stbl()}, containing at least `feature_nr` and optionally
#'   `feature_names` or `feature_name`.
#'
#' @return A tibble with columns:
#'   * `feature_nr` - numeric feature identifier.
#'   * `fname_tbl` - character feature name from the table.
#'   Only non-missing, non-empty names are retained and the result
#'   contains distinct `feature_nr` entries.
#'
#' @importFrom tibble tibble
#' @importFrom dplyr filter distinct
#'
toptbl_to_fn <- function(df) {
    df <- stbl(df)
    if (nrow(df) == 0) {
        return(tibble())
    }
    cols <- names(df)
    fn <- if ("feature_names" %in% cols) {
        df[["feature_names"]]
    } else if ("feature_name" %in% cols) {
        df[["feature_name"]]
    } else {
        as.character(df[["feature_nr"]])
    }
    tibble(
        feature_nr = df[["feature_nr"]],
        fname_tbl = as.character(fn)
    ) |>
        filter(
            !is.na(.data$feature_nr),
            !is.na(.data$fname_tbl), .data$fname_tbl != ""
        ) |>
        distinct(.data$feature_nr, .keep_all = TRUE)
}


#' Normalize Category 3 hit tables to a named list
#'
#' @noRd
#'
#' @description
#' `category_2_and_3_hits$category_3_hits` may be provided either as a
#' single data frame/tibble (backward compatibility) or as a named list
#' of data frames/tibbles (one per contrast).
#'
#' This helper converts the input to a named list and returns a flag
#' indicating whether the original input was a single data frame, so
#' the caller can restore the original structure.
#'
#' If the input is a list without names, default names of the form
#' `contrast_<k>` are assigned.
#'
#' @param cat3
#'   Either a single data frame/tibble (one contrast) or a list of data
#'   frames/tibbles (multiple contrasts). May be `NULL`.
#'
#' @return
#'   A list with elements:
#'   - `list`: a named list of data frames/tibbles (or `NULL` if `cat3`
#'     was `NULL`).
#'   - `was_df`: logical; `TRUE` if the input was a single data frame.
#'   
normalize_cat3_hits <- function(cat3) {
    if (is.null(cat3)) {
        return(list(list = NULL, was_df = FALSE))
    }
    
    was_df <- is.data.frame(cat3)
    
    if (was_df) {
        cat3_list <- list(cat3)
        names(cat3_list) <- "contrast_1"
    } else {
        cat3_list <- cat3
        if (is.null(names(cat3_list))) {
            names(cat3_list) <- paste0("contrast_", seq_along(cat3_list))
        }
    }
    
    list(list = cat3_list, was_df = was_df)
}


#' Parse a contrast name into suffix and condition parts
#'
#' @noRd
#'
#' @description
#' Remove the optional `time_interaction_` prefix from `contrast_name`
#' and split the remainder on the literal delimiter `_vs_`.
#'
#' The function returns:
#' - `suffix`: the contrast suffix, typically `A_vs_B`
#' - `parts`: the vector of parts from splitting `suffix` on `_vs_`
#'
#' @param contrast_name
#'   A contrast identifier such as `time_interaction_A_vs_B` or
#'   `A_vs_B`.
#'
#' @return
#'   A list with elements:
#'   - `suffix`: character scalar (prefix-stripped name).
#'   - `parts`: character vector obtained by splitting `suffix`.
#'   
parse_contrast_conditions <- function(contrast_name) {
    suffix <- sub("^time_interaction_", "", contrast_name)
    parts <- strsplit(suffix, "_vs_", fixed = TRUE)[[1]]
    list(suffix = suffix, parts = parts)
}


#' Retrieve an interaction effect-size vector for a contrast
#'
#' @noRd
#'
#' @description
#' Select the appropriate interaction effect-size vector for a Category
#' 3 contrast. If `interaction_effect_size` is a single numeric vector,
#' it is returned directly (backward compatibility).
#'
#' If `interaction_effect_size` is a named list, the function attempts
#' to match the contrast by several candidate keys derived from
#' `suffix` and `contrast_name`, including:
#' - with and without the `time_interaction_` prefix, and
#' - both orientations of the contrast (e.g. `A_vs_B` and `B_vs_A`).
#'
#' The first matching element is returned; if no match is found, `NULL`
#' is returned.
#'
#' @param interaction_effect_size
#'   Either a numeric vector (used for all contrasts) or a named list of
#'   numeric vectors keyed by contrast identifiers such as `A_vs_B`.
#' @param suffix
#'   Contrast suffix, typically `A_vs_B`.
#' @param contrast_name
#'   Full contrast name, e.g. `time_interaction_A_vs_B` or `A_vs_B`.
#'
#' @return
#'   A numeric vector for the matched contrast, or `NULL` if no match
#'   exists and `interaction_effect_size` is a list.
#'   
get_interaction_es_vec <- function(
        interaction_effect_size,
        suffix,
        contrast_name
) {
    if (!is.list(interaction_effect_size)) {
        return(interaction_effect_size)
    }
    
    reverse_suffix <- function(s) {
        parts <- strsplit(s, "_vs_", fixed = TRUE)[[1]]
        if (length(parts) < 2L) return(NA_character_)
        paste0(parts[2], "_vs_", parts[1])
    }
    
    suffix2 <- sub("^time_interaction_", "", contrast_name)
    rev1 <- reverse_suffix(suffix)
    rev2 <- reverse_suffix(suffix2)
    
    candidates <- c(
        suffix,
        suffix2,
        contrast_name,
        paste0("time_interaction_", suffix),
        paste0("time_interaction_", suffix2),
        rev1,
        rev2,
        if (!is.na(rev1)) paste0("time_interaction_", rev1) else NA_character_,
        if (!is.na(rev2)) paste0("time_interaction_", rev2) else NA_character_
    )
    candidates <- candidates[!is.na(candidates)]
    candidates <- unique(candidates)
    
    for (key in candidates) {
        v <- interaction_effect_size[[key]]
        if (!is.null(v)) return(v)
    }
    
    NULL
}


#' Add per-condition time-effect columns to a Category 3 hit table
#'
#' @noRd
#'
#' @description
#' Add time-effect columns derived from `time_effect_effect_size` to a
#' Category 3 hit table `tbl`. Mapping is performed by matching the
#' table's `feature_names` against `names()` of the per-feature effect
#' size vectors (strict 1:1 match).
#'
#' For contrasts of the form `A_vs_B`, the function attempts to add
#' `cT_A` and `cT_B` (only for conditions that exist in
#' `time_effect_effect_size`).
#'
#' For a degenerate case where `time_effect_effect_size` contains only
#' one vector and fewer than two conditions can be parsed from `parts`,
#' the function adds a single `cT` column.
#'
#' If `tbl` is not a data frame/tibble or does not contain
#' `feature_names`, it is returned unchanged.
#'
#' @param tbl
#'   A data frame/tibble that should contain a character `feature_names`
#'   column.
#' @param time_effect_effect_size
#'   A named list of numeric vectors of per-feature time-effect sizes.
#'   Each vector must be named, and names must match `feature_names`
#'   in `tbl` 1:1. Names correspond to the short condition labels used
#'   in contrasts.
#' @param parts
#'   Character vector of condition parts produced by splitting a
#'   contrast suffix on `_vs_`.
#'
#' @return
#'   The input table with added `cT_<cond>` columns (or `cT` in the
#'   degenerate case).
#'
add_cat3_cT <- function(
        tbl,
        time_effect_effect_size,
        parts
) {
    if (!is.data.frame(tbl) || !("feature_names" %in% names(tbl))) {
        return(tbl)
    }
    
    feats <- tbl[["feature_names"]]
    
    if (length(time_effect_effect_size) == 1L && length(parts) < 2L) {
        vec <- time_effect_effect_size[[1L]]
        tbl[["cT"]] <- map_effect_by_feature_strict(
            effect_vec = vec,
            table_features = feats,
            context = "Category 3: cT"
        )
        return(tbl)
    }
    
    if (length(parts) >= 2L) {
        conds <- parts[seq_len(2)]
        for (cond_short in conds) {
            if (!cond_short %in% names(time_effect_effect_size)) next
            vec <- time_effect_effect_size[[cond_short]]
            col_nm <- paste0("cT_", cond_short)
            tbl[[col_nm]] <- map_effect_by_feature_strict(
                effect_vec = vec,
                table_features = feats,
                context = paste0("Category 3: ", col_nm)
            )
        }
    }
    
    tbl
}


#' Add a cDT interaction column to a Category 3 hit table
#'
#' @noRd
#'
#' @description
#' Add the `cDT` column to `tbl` using the interaction effect-size
#' vector `ies_vec`, mapped by matching the table's `feature_names`
#' against `names(ies_vec)` (strict 1:1 match).
#'
#' If `ies_vec` is `NULL`, the function errors because strict matching
#' cannot be performed.
#'
#' If `tbl` is not a data frame/tibble or does not contain
#' `feature_names`, it is returned unchanged.
#'
#' @param tbl
#'   A data frame/tibble that should contain a character `feature_names`
#'   column.
#' @param ies_vec
#'   Named numeric vector of per-feature interaction effect sizes for
#'   the relevant contrast. Names must match `feature_names` in `tbl`
#'   1:1. If `NULL`, an error is raised.
#' @param context
#'   Optional string used to annotate error messages (e.g. contrast
#'   name).
#'
#' @return
#'   The input table with a `cDT` numeric column added (or replaced).
#'
add_cat3_cDT <- function(
        tbl,
        ies_vec,
        context = ""
) {
    if (!is.data.frame(tbl) || !("feature_names" %in% names(tbl))) {
        return(tbl)
    }
    
    if (is.null(ies_vec)) {
        stop(
            "add_cat3_cDT(): `ies_vec` is NULL; cannot add `cDT` with ",
            "strict feature-name matching.",
            if (nzchar(context)) paste0(" (", context, ")") else "",
            call. = FALSE
        )
    }
    
    tbl[["cDT"]] <- map_effect_by_feature_strict(
        effect_vec = ies_vec,
        table_features = tbl[["feature_names"]],
        context = if (nzchar(context)) {
            paste0("Category 3: cDT (", context, ")")
        } else {
            "Category 3: cDT"
        }
    )
    
    tbl
}


#' Find the within-level top table name for a condition
#'
#' @noRd
#'
#' @description
#' Identify the element of `within_level_top_tables` that corresponds to
#' the short condition label `nm`.
#'
#' Matching follows a two-step strategy:
#' 1. Prefer the exact documented convention `Condition_<nm>`.
#' 2. For backward compatibility, strip the prefix up to the first
#'    underscore from each table name and match the remainder to `nm`.
#'
#' If no match is found, `NA_character_` is returned.
#'
#' @param within_level_top_tables
#'   A named list of tibbles/data frames, typically named
#'   `Condition_<cond>`.
#' @param nm
#'   Character scalar giving the short condition label to match.
#'
#' @return
#'   A character scalar giving the matched table name, or
#'   `NA_character_` if no match exists.
#'   
find_within_level_table_name <- function(
        within_level_top_tables,
        nm
        ) {
    tt_names <- names(within_level_top_tables)
    if (is.null(tt_names)) return(NA_character_)
    
    exact <- paste0("Condition_", nm)
    if (exact %in% tt_names) return(exact)
    
    suffixes <- sub("^[^_]*_", "", tt_names)
    idx <- match(nm, suffixes)
    if (!is.na(idx)) return(tt_names[[idx]])
    
    NA_character_
}


#' Map a named effect-size vector into a table by feature name (subset OK)
#'
#' @noRd
#'
#' @description
#' Transfer per-feature values from a named numeric effect-size vector
#' into a table by matching `table_features` (e.g. `tbl$feature_names`)
#' against `names(effect_vec)`.
#'
#' A strict requirement is enforced in one direction:
#' - Every feature in `table_features` must be present in
#'   `names(effect_vec)`.
#'
#' The effect vector may contain additional features not present in the
#' table (these are ignored).
#'
#' Duplicates are not allowed on either side.
#'
#' @param effect_vec
#'   A named numeric vector of effect sizes. Names must be non-empty and
#'   unique.
#' @param table_features
#'   A character vector of feature identifiers from the table (e.g.
#'   `tbl$feature_names`). Must be unique.
#' @param context
#'   A short string used to annotate error messages (e.g. column name,
#'   condition, or contrast).
#'
#' @return
#'   A numeric vector of effect sizes aligned to `table_features`.
#'
map_effect_by_feature_strict <- function(
        effect_vec,
        table_features,
        context = ""
        ) {
    checkmate::assert_numeric(effect_vec, any.missing = FALSE)
    checkmate::assert_character(table_features, any.missing = FALSE)
    checkmate::assert_string(context, null.ok = TRUE)
    
    nms <- names(effect_vec)
    if (is.null(nms)) {
        stop("Effect-size vector has no names.", call. = FALSE)
    }
    if (anyNA(nms) || any(nms == "")) {
        stop("Effect-size vector has missing/empty names.", call. = FALSE)
    }
    
    if (anyDuplicated(nms)) {
        dup <- unique(nms[duplicated(nms)])
        stop(
            "Effect-size vector has duplicated names: ",
            paste(utils::head(dup, 10), collapse = ", "),
            if (length(dup) > 10) " ..." else "",
            if (nzchar(context)) paste0(" (", context, ")") else "",
            call. = FALSE
        )
    }
    
    if (anyDuplicated(table_features)) {
        dup <- unique(table_features[duplicated(table_features)])
        stop(
            "Table has duplicated feature_names: ",
            paste(utils::head(dup, 10), collapse = ", "),
            if (length(dup) > 10) " ..." else "",
            if (nzchar(context)) paste0(" (", context, ")") else "",
            call. = FALSE
        )
    }
    
    # Only enforce: table_features must be present in the vector names.
    missing_in_vec <- setdiff(table_features, nms)
    if (length(missing_in_vec) > 0L) {
        stop(
            "Missing in effect vector (present in table)",
            if (nzchar(context)) paste0(" (", context, ")") else "",
            ": ",
            paste(utils::head(missing_in_vec, 10), collapse = ", "),
            if (length(missing_in_vec) > 10) " ..." else "",
            call. = FALSE
        )
    }
    
    # Reorder effect sizes to match table order
    effect_vec[match(table_features, nms)]
}


# Level 3 internal functions ---------------------------------------------------


#' Normalize Curve Values
#'
#' @noRd
#'
#' @description This function normalizes each row in a data frame or matrix
#' of curve values.
#' Normalization is performed so that each row's values range from 0
#' (corresponding to the
#' minimum value of the row) to 1
#' (corresponding to the maximum value of the row).
#'
#' @param curve_values A data frame or matrix of curve values where each row
#' represents
#'        a curve and each column a time point.
#' @return A data frame or matrix with the same dimensions as the input, where
#'  each row
#'         has been normalized.
#'
normalize_curves <- function(
        curve_values,
        epsilon = 1e-8
        ) {
    normalized_curves <- apply(curve_values, 1, function(row) {
        mu <- mean(row, na.rm = TRUE)
        sd_row <- stats::sd(row, na.rm = TRUE)
        if (is.na(sd_row) || sd_row < epsilon) {
            # flat or nearly-flat row: return zeros
            rep(0, length(row))
        } else {
            (row - mu) / sd_row
        }
    })

    normalized_curves <- t(normalized_curves)
    curve_values[, ] <- normalized_curves
    curve_values
}


#' K-means Clustering of Temporal Curves using MiniBatchKmeans
#'
#' @noRd
#'
#' @description
#' Performs MiniBatch K-means clustering on smoothed time-series (curve) data.
#' Automatically selects the best number of clusters using the Bayesian
#' Information Criterion (BIC).
#' Cluster assignments are added to the provided `top_table`, and the clustered
#'  data is returned.
#'
#' @param curve_values A numeric matrix of normalized time-series values
#' (rows = features, cols = timepoints).
#' @param k_range Integer vector specifying the range of cluster numbers to
#' evaluate (e.g., `2:8`).
#' @param smooth_timepoints Numeric vector of timepoints used as column names
#' in the output.
#' @param top_table Data frame with column `feature_nr` indicating feature
#'  indices. Will be updated with cluster assignments.
#' @param condition_level Character string indicating the current condition
#' level (used for error messages).
#' @param min_cluster_r2 `numeric(1)`: A value >=0 and <1
#' specifying the minimum allowed squared Pearson correlation (r2) of any
#' cluster member to the centroid of its assigned cluster.
#'
#' After k-means clustering, each cluster is iteratively pruned. Members whose
#' r2 to the current cluster centroid falls below `min_cluster_r2` are removed
#' from that cluster and reassigned to cluster `0` (the "other" cluster).
#'
#' Pruning is repeated until all remaining members satisfy the constraint, a
#' maximum of 10 iterations is reached, or the cluster would shrink below a
#' minimum size of 10 members. If a cluster cannot satisfy the constraint under
#' these conditions, all of its remaining members are reassigned to cluster `0`.
#'
#' Cluster `0` therefore contains all features that do not meet the minimum
#' centroid similarity criterion. These features are retained in the output but
#' are not considered part of any valid cluster.
#' @param verbose Boolean flag controlling the display of messages.
#'
#' @return A list with the following components:
#' \describe{
#'   \item{clustered_hits}{A data frame with `feature` and `cluster`
#'   assignments.}
#'   \item{hc}{The MiniBatchKmeans object for the best `k`.}
#'   \item{curve_values}{The input matrix with a `cluster` column added.}
#'   \item{top_table}{The input `top_table`, updated with cluster assignments.}
#'   \item{clusters}{The best number of clusters (`k_best`) selected via BIC.}
#' }
#'
#' @importFrom ClusterR MiniBatchKmeans predict_KMeans
#' @importFrom pbapply pblapply
#'
kmeans_clustering <- function(
    curve_values,
    k_range,
    smooth_timepoints,
    top_table,
    condition_level,
    min_cluster_r2,
    verbose
    ) {
    if (nrow(curve_values) <= max(k_range)) { # Clustering would fail
        stop_call_false(paste(
            "For condition_level '", condition_level, "':",
            "the number of requested clusters (", max(k_range), ")",
            "must be strictly less than",
            "the number of hits (", nrow(curve_values), ").",
            "Please choose fewer clusters to avoid failure during k-means."
        ))
    }

    if (length(k_range) == 1L && k_range[1L] == 1L) {
        # All series in one cluster, skip any computation
        k_best <- 1L
        cl <- NULL
        cluster_assignments <- rep(1L, nrow(curve_values))

        # Fallback defaults for similarity
        sim <- list(
            per_member        = rep(NA_real_, nrow(curve_values)),
            per_cluster_mean  = NA_real_,
            overall_mean      = NA_real_
        )
    } else {
        n_obs <- nrow(curve_values)
        apply_fun <- if (isTRUE(verbose)) pbapply::pblapply else lapply

        if (n_obs <= 1000) { # Small dataset: use full k-means
            fits <- apply_fun(k_range, function(k) {
                stats::kmeans(
                    curve_values,
                    centers  = k,
                    nstart   = 10,
                    iter.max = 300
                )
            })

            tot_within <- vapply(
                fits,
                function(f) {
                    f$tot.withinss
                },
                numeric(1)
            )
            cluster_assignments_list <- lapply(fits, `[[`, "cluster")
        } else { # Large dataset: use MiniBatchKmeans
            batch_size <- min( # never larger than the data
                n_obs,
                max(20L, 2L * max(k_range), floor(0.05 * n_obs))
            )

            fits <- apply_fun(k_range, function(k) {
                ClusterR::MiniBatchKmeans(
                    data            = curve_values,
                    clusters        = k,
                    batch_size      = batch_size,
                    num_init        = 10,
                    max_iters       = 300,
                    init_fraction   = 1.0,
                    early_stop_iter = 10,
                    tol             = 1e-4,
                    verbose         = FALSE,
                    seed            = 42
                )
            })

            tot_within <- vapply(
                fits,
                function(f) sum(f$WCSS_per_cluster),
                numeric(1)
            )
            cluster_assignments_list <- lapply(
                fits,
                function(f) {
                    ClusterR::predict_KMeans(
                        curve_values,
                        f$centroids
                    )
                }
            )
        }
        p <- ncol(curve_values)
        # Bayesian Information Criterion (BIC).
        bic <- n_obs * log(tot_within / n_obs) + k_range * log(n_obs) * p
        best_idx <- which.min(bic)

        k_best <- k_range[best_idx]
        cl <- fits[[best_idx]]
        cluster_assignments <- cluster_assignments_list[[best_idx]]

        curve_mat_num <- as.matrix(curve_values)
        storage.mode(curve_mat_num) <- "double"
        
        pr <- prune_clusters_by_min_r2(
            curves_mat      = curve_mat_num,
            clusters        = cluster_assignments,
            min_cluster_r2  = min_cluster_r2
        )
        cluster_assignments <- pr$clusters
        
        time_num <- as.numeric(gsub("^.*\\|", "", smooth_timepoints))
        if (!all(is.finite(time_num))) time_num <- NULL

        sim <- compute_cluster_fits(
            curves_mat = curve_mat_num,
            clusters   = cluster_assignments
        )
    }
    
    clustered_hits <- data.frame(
        feature = top_table$feature_nr,
        cluster = cluster_assignments
    )
    clustered_hits <- clustered_hits[, c("feature", "cluster")]
    
    colnames(curve_values) <- smooth_timepoints
    curve_values <- as.data.frame(curve_values)
    curve_values$cluster <- cluster_assignments

    top_table$cluster <- NA
    top_table$cluster[seq_len(nrow(clustered_hits))] <-
        as.integer(clustered_hits$cluster)

    group_clustering <- list(
        clustered_hits = clustered_hits,
        hc = cl,
        curve_values = curve_values,
        top_table = top_table,
        clusters = k_best,
        cluster_quality = list(
            per_member        = sim$per_member,
            per_cluster_mean  = sim$per_cluster_mean,
            overall_mean      = sim$overall_mean
        )
    )
}


#' Select balanced features across two hit tables
#'
#' @noRd
#'
#' @description
#' Internal helper to select approximately equal numbers of hits from
#' `avrg_diff_conditions` and `interaction_condition_time` when a
#' global cap (`max_n`) is applied. This prevents one category from
#' dominating the limited number of plots when its hit count is much larger.
#'
#' The function attempts to select hits in a ~50:50 ratio:
#' - If both categories have sufficient hits, each supplies half.
#' - If one category has too few hits, the other fills the remainder.
#' - Features are ranked within each category by adjusted p-value
#'   (`adj.P.Val`) if available, otherwise by their current order.
#' - Duplicate features (appearing in both categories) are only counted once.
#' - If fewer than `max_n` unique features exist overall, all available
#'   features are returned.
#'
#' @param avrg_df A data frame of hits from average-difference tests,
#'   must contain at least `feature_nr` and `feature_names`. Optionally,
#'   it may also contain `adj.P.Val` for ranking.
#' @param inter_df A data frame of hits from interaction tests,
#'   must contain at least `feature_nr` and `feature_names`. Optionally,
#'   it may also contain `adj.P.Val` for ranking.
#' @param max_n Integer scalar. Maximum number of features to return.
#'   If `NULL` or `Inf`, all unique features from both inputs are returned.
#' @param adj_pthresh_avrg_diff_conditions `numeric(1)`: adj. p-value threshold
#' for the limma average difference between conditions results (category 2).
#' @param adj_pthresh_interaction_condition_time `numeric(1)`: adj. p-value 
#' threshold for the limma interaction of condition and time results
#' (category 3).
#'
#' @return A data frame with up to `max_n` rows and columns
#'   `feature_nr` and `feature_names`, containing the selected features.
#'
#' @importFrom dplyr bind_rows select distinct slice_head arrange anti_join
#'                   any_of
#' @importFrom rlang .data
#'
select_balanced_hits <- function(
        avrg_df,
        inter_df,
        max_n,
        adj_pthresh_avrg_diff_conditions,
        adj_pthresh_interaction
) {
    # keep only significant hits in each category (if adj.P.Val is present)
    if (!is.null(adj_pthresh_avrg_diff_conditions) &&
        "adj.P.Val" %in% names(avrg_df)) {
        avrg_df <- avrg_df |>
            dplyr::filter(.data$adj.P.Val <= adj_pthresh_avrg_diff_conditions)
    }
    
    if (!is.null(adj_pthresh_interaction) &&
        "adj.P.Val" %in% names(inter_df)) {
        inter_df <- inter_df |>
            dplyr::filter(.data$adj.P.Val <= adj_pthresh_interaction)
    }
    
    # rank each category by adj.P.Val (smaller first), fallback to feature_names
    rank_tbl <- function(tbl) {
        if ("adj.P.Val" %in% names(tbl)) {
            dplyr::arrange(tbl, .data$adj.P.Val, .data$feature_names)
        } else {
            dplyr::arrange(tbl, .data$feature_names)
        }
    }
    
    avrg_ranked <- avrg_df |>
        rank_tbl() |>
        dplyr::select(
            dplyr::all_of(c("feature_nr", "feature_names"))
        )
    
    inter_ranked <- inter_df |>
        rank_tbl() |>
        dplyr::select(
            dplyr::all_of(c("feature_nr", "feature_names"))
        )
    
    # Union of significant features
    union_tbl <- dplyr::bind_rows(avrg_ranked, inter_ranked) |>
        dplyr::distinct(.data$feature_names, .keep_all = TRUE)
    
    if (nrow(union_tbl) == 0L) {
        return(union_tbl)
    }
    
    if (is.null(max_n) || is.infinite(max_n)) {
        return(union_tbl)
    }
    
    # Prepare round-robin pools
    pool2 <- avrg_ranked
    pool3 <- inter_ranked
    
    selected <- dplyr::tibble(
        feature_nr = integer(),
        feature_names = character()
    )
    
    # alternate between cat2 and cat3
    turn <- 2  # start with category 2
    
    while (nrow(selected) < max_n && (nrow(pool2) > 0 || nrow(pool3) > 0)) {
        
        if (turn == 2 && nrow(pool2) > 0) {
            chosen <- pool2[1, ]
            selected <- dplyr::bind_rows(selected, chosen)
            # remove from both pools to avoid duplication
            pool2 <- pool2[-1, , drop = FALSE]
            pool3 <- dplyr::filter(
                pool3,
                .data$feature_names != chosen$feature_names
            )
            turn <- 3
            
        } else if (turn == 3 && nrow(pool3) > 0) {
            chosen <- pool3[1, ]
            selected <- dplyr::bind_rows(selected, chosen)
            # remove from both pools
            pool3 <- pool3[-1, , drop = FALSE]
            pool2 <- dplyr::filter(
                pool2,
                .data$feature_names != chosen$feature_names
            )
            turn <- 2
            
        } else {
            # current category empty -> switch to the other and continue
            turn <- ifelse(turn == 2, 3, 2)
        }
    }
    
    selected |> dplyr::slice_head(n = max_n)
}


# Level 4 internal functions ---------------------------------------------------


#' Compute per-curve centroid shape fit (signed r^2 to cluster centroid)
#'
#' @noRd
#'
#' @description
#' For each curve, computes the \emph{signed} coefficient of determination
#' (\code{signed r^2 = sign(r) * r^2}) between the curve and its cluster
#' centroid (pointwise mean profile). The magnitude reflects variance
#' explained by the centroid's shape; the sign indicates in-phase
#' (\code{> 0}) vs. inverted (\code{< 0}) shape. Singleton clusters yield
#' \code{NA}.
#'
#' @param curves_mat Numeric matrix (\code{n x T}) with rows = curves and
#'   columns = timepoints.
#' @param clusters Integer or factor vector of length \code{n} giving the
#'   cluster label for each row of \code{curves_mat}.
#'
#' @return A named list with:
#' \describe{
#'   \item{\code{per_cluster_mean}}{Named numeric vector: mean \emph{signed}
#'     \code{r^2} to the centroid for each cluster (names are cluster IDs).
#'     Higher (closer to \code{1}) indicates better centroid
#'     representativeness; negative values indicate inverted shapes.
#'     Singleton clusters are \code{NA}.}
#'   \item{\code{per_member}}{Numeric vector (length \code{n}): per-curve
#'     \emph{signed} \code{r^2} to its cluster centroid. Values in
#'     \code{[-1, 1]}; \code{NA} for singletons or undefined correlations.}
#'   \item{\code{overall_mean}}{Single numeric value: mean of
#'     \code{per_member} excluding \code{NA}s.}
#' }
#'
#' @details
#' Centroids are columnwise means within each cluster (\code{na.rm = TRUE}).
#' Correlations use \code{stats::cor(..., use = "pairwise.complete.obs",
#' method = "pearson")}; they are converted to signed \code{r^2} via
#' \code{sign(r) * r^2}.
#'
#' @importFrom stats cor setNames
#'
compute_cluster_fits <- function(
    curves_mat,
    clusters
    ) {
    n <- nrow(curves_mat)
    X <- curves_mat

    # signed r^2 to the cluster centroid (shape fit with sign)
    per_member <- rep(NA_real_, n)
    k_vals <- sort(unique(clusters))
    per_cluster_mean <- stats::setNames(numeric(length(k_vals)), k_vals)

    for (k in k_vals) {
        idx <- which(clusters == k)

        # singleton clusters -> undefined/uninformative
        if (length(idx) <= 1L) {
            per_member[idx] <- NA_real_
            per_cluster_mean[as.character(k)] <- NA_real_
            next
        }

        # centroid as mean curve (pointwise)
        cent <- colMeans(X[idx, , drop = FALSE], na.rm = TRUE)

        # correlation of each member with centroid (pairwise complete obs)
        cors <- apply(
            X[idx, , drop = FALSE], 1,
            function(row) {
                stats::cor(
                    row,
                    cent,
                    use = "pairwise.complete.obs",
                    method = "pearson"
                )
            }
        )

        # signed r^2
        sr2 <- sign(cors) * (cors^2)

        per_member[idx] <- as.numeric(sr2)
        per_cluster_mean[as.character(k)] <- mean(per_member[idx], na.rm = TRUE)
    }

    overall_mean <- mean(per_member, na.rm = TRUE)

    list(
        per_cluster_mean = per_cluster_mean,
        per_member       = per_member,
        overall_mean     = overall_mean
    )
}


#' Prune cluster assignments by a minimum r-squared to centroid constraint
#'
#' @noRd
#'
#' @description
#' Iteratively prunes each cluster so that every retained member achieves at
#' least `min_cluster_r2` (squared Pearson correlation, r2) to the cluster
#' centroid (mean curve). Members failing the constraint are reassigned to
#' cluster `0` ("other").
#'
#' Pruning stops when the constraint is satisfied, after 10 iterations, or if
#' the cluster would shrink below 10 members. If the constraint cannot be met
#' under these rules, the entire cluster is reassigned to `0`.
#'
#' @param curves_mat `matrix`: Numeric matrix with rows as features/trajectories
#'   and columns as timepoints.
#' @param clusters `integer` or `numeric`: Cluster assignments of length
#'   `nrow(curves_mat)`. Cluster `0` is reserved for "other". `NA` values are
#'   treated as `0`.
#' @param min_cluster_r2 `numeric(1)`: A value >=0 and <1
#' specifying the minimum allowed squared Pearson correlation (r2) of any
#' cluster member to the centroid of its assigned cluster.
#'
#' After k-means clustering, each cluster is iteratively pruned. Members whose
#' r2 to the current cluster centroid falls below `min_cluster_r2` are removed
#' from that cluster and reassigned to cluster `0` (the "other" cluster).
#'
#' Pruning is repeated until all remaining members satisfy the constraint, a
#' maximum of 10 iterations is reached, or the cluster would shrink below a
#' minimum size of 10 members. If a cluster cannot satisfy the constraint under
#' these conditions, all of its remaining members are reassigned to cluster `0`.
#'
#' Cluster `0` therefore contains all features that do not meet the minimum
#' centroid similarity criterion. These features are retained in the output but
#' are not considered part of any valid cluster.
#'
#' @return A `list` with:
#' \describe{
#'   \item{clusters}{`integer`: Possibly pruned cluster assignments. Members in
#'   "other" are labeled `0`.}
#'   \item{kept}{`integer`: Sorted vector of retained cluster ids (> 0).}
#'   \item{dropped}{`integer`: Sorted vector of cluster ids that were fully
#'   reassigned to `0`.}
#' }
#'
prune_clusters_by_min_r2 <- function(
        curves_mat,
        clusters,
        min_cluster_r2
) {
    is_valid_r2 <- !is.null(min_cluster_r2) &&
        is.finite(min_cluster_r2) &&
        min_cluster_r2 > 0 &&
        min_cluster_r2 < 1
    
    if (!is_valid_r2) {
        cl <- as.integer(clusters)
        cl[is.na(cl)] <- 0L
        
        return(list(
            clusters = cl,
            kept = sort(unique(cl[cl > 0L])),
            dropped = integer()
        ))
    }
    
    min_cluster_size <- 10L
    max_iter <- 10L
    
    n <- nrow(curves_mat)
    if (n == 0L) {
        return(list(
            clusters = integer(),
            kept = integer(),
            dropped = integer()
        ))
    }
    
    cl <- as.integer(clusters)
    cl[is.na(cl)] <- 0L
    
    uniq <- sort(unique(cl[cl > 0L]))
    dropped_clusters <- integer(0)
    
    r2_to_vector <- function(
        M,
        v
    ) {
        p <- ncol(M)
        
        mu <- rowMeans(M)
        Mc <- M - mu
        ss <- rowSums(Mc * Mc)
        sd <- sqrt(ss / (p - 1))
        ok <- is.finite(sd) & sd > 0
        
        v_mu <- mean(v)
        vc <- v - v_mu
        v_sd <- sqrt(sum(vc * vc) / (p - 1))
        
        if (!is.finite(v_sd) || v_sd == 0) {
            return(rep(0, nrow(M)))
        }
        
        cov <- as.numeric(Mc %*% vc) / (p - 1)
        
        r <- rep(0, nrow(M))
        r[ok] <- cov[ok] / (sd[ok] * v_sd)
        r <- pmin(pmax(r, -1), 1)
        
        r * r
    }
    
    for (k in uniq) {
        members <- which(cl == k)
        
        if (length(members) < min_cluster_size) {
            cl[members] <- 0L
            dropped_clusters <- c(dropped_clusters, k)
            next
        }
        
        converged <- FALSE
        
        for (it in seq_len(max_iter)) {
            centroid <- colMeans(curves_mat[members, , drop = FALSE])
            
            r2 <- r2_to_vector(
                M = curves_mat[members, , drop = FALSE],
                v = centroid
            )
            
            keep <- r2 >= min_cluster_r2
            
            if (all(keep)) {
                converged <- TRUE
                break
            }
            
            kept_members <- members[keep]
            
            if (length(kept_members) < min_cluster_size) {
                cl[members] <- 0L
                dropped_clusters <- c(dropped_clusters, k)
                converged <- TRUE
                members <- integer(0)
                break
            }
            
            removed <- members[!keep]
            cl[removed] <- 0L
            
            members <- kept_members
        }
        
        if (!converged && length(members) > 0L) {
            cl[members] <- 0L
            dropped_clusters <- c(dropped_clusters, k)
        }
    }
    
    list(
        clusters = cl,
        kept = sort(unique(cl[cl > 0L])),
        dropped = sort(unique(dropped_clusters))
    )
}